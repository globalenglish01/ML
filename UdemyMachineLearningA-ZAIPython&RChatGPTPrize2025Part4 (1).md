### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p01 8. Deep Learning Fundamentals Training Neural Networks Step-by-Step.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p01 8. Deep Learning Fundamentals Training Neural Networks Step-by-Step

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎回来参加深度学习的课程，今天
我们将完成反向传播
我们已经知道了神经网络发生的几乎所有事情
我们了解有一个过程叫做前向传播
信息被输入到输入层
然后它被传播到获取我们的y hat
我们的输出值
然后我们将它们与训练集中的实际值进行比较
然后我们计算误差
然后误差通过网络反向传播
这允许我们通过调整权重来训练网络
这里一个关键重要的是反向传播是一个高级算法
由非常有趣和复杂的数学驱动
这允许我们调整权重
所有同时
所有权重同时调整
如果我们手动做
或者如果我们想出一个不同的算法
那么我们即使计算了误差
然后我们试图理解每个权重对误差的影响
我们必须以某种方式独立或单独调整每个权重
反向传播的巨大优势
记住的关键是，在反向传播过程中
仅仅因为算法的结构方式
你知道你可以同时调整所有权重
所以基本上你知道哪个部分的误差 每个神经网络的权重负责
这就是反向传播的关键基本原理
这在1980年代迅速普及
这是一个重大突破
如果你想了解更多关于这一点和背景数学如何工作
那么一个好文章我们已经提到过是迈克尔尼尔森的神经网络
和深度学习实际上是一本书
你会发现数学被写出来
这将帮助你理解这是如何可能的
但对于我们的目的
如果你从直觉角度来看
重要的是记住反向传播
它同时调整所有权重
现在我们将把所有内容都整理成一个步骤
神经网络的训练
好的
第一步
我们随机初始化权重到接近零的小数
但我们没有特别关注权重的初始化 在直觉教程中
权重必须从某个地方开始
但我们没有特别关注权重的初始化
在直觉教程中
但权重必须从某个地方开始
它们被初始化为接近零的随机值
从那里通过前向传播的过程
反向传播 这些权重被调整，直到误差被最小化
直到成本函数被最小化
然后第二步，将输入数据集的第一个观察值输入
输入到数据集的第一个行
每个特征是一个输入节点
所以基本上取列并将它们放入输入节点
第三步
前向传播从左到右
神经元以一种方式被激活
每个神经元的激活的影响被限制
所以权重基本上决定了
每个神经元的激活的重要性
然后传播激活，直到得到预测结果y hat
在这个情况下，所以基本上你从左到右传播
你直到最后
你得到你的y hat
然后比较预测结果和实际结果
测量生成的误差
然后从右到左进行反向传播
区域被反向传播
根据误差更新权重
你能够计算出
由于反向传播算法的结构
学习率决定了我们更新权重的程度
学习率是你可以在神经网络中控制的参数
第六步
重复第一步到第五步
并且在每个观察值后更新权重，这叫做强化学习
在我们的情况下，那就是随机梯度下降或重复第一步到第五步
但是只在一批观察值后更新权重
这就是批学习
它要么是全梯度下降，要么是批梯度下降
或者是小批量梯度下降
第七步 当整个训练集通过人工神经网络，那就是一个时期
重做 更多的时期
所以基本上你只是不断地做，不断地做，不断地做
为了允许你的神经网络越来越好，越来越好，越来越好
并且不断地调整自己
嗯 随着你最小化成本函数
所以，就是这样
这些都是你需要采取的步骤来构建你的人工神经网络并训练它
而这些就是你将在实际教程中与环一起采取的步骤
祝你好运
我期待着下次见到你，直到那时 享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p02 9. Bank Customer Churn Prediction Machine Learning Model with TensorFlow.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p02 9. Bank Customer Churn Prediction Machine Learning Model with TensorFlow

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                好的，开始 我们有这个数据集
它有几列
它有行号
客户ID，姓氏
我们正在查看的是银行的一个数据集
嗯 当然这都是虚构的
这不是一个真实的银行 但它非常真实
这里是一份数据快照
如果你向下滚动到底部
将有一万名客户
所以这个数据集中有一万行
银行所做的是
他们测量了关于这些客户的一些信息
为什么他们进行所有这些工作
这里的挑战是什么 嗯
银行一直在看到异常的流失率
So churn is when people leave the company
And they've seen customers leaving at unusually high rates
And they want to understand what the problem is
And they want to assess and address that problem
And that's why they've hired you to look into this data set for them
And give them some insights
And how did this data set come to be well
Six months ago the bank said all right
There's a big problem
We got to take a sample about customers by the way
这是一个示例 对于这家银行来说，十万是一个微不足道的数字
这家银行有数百万客户
它经营这个
这家虚构的银行在欧洲三个国家经营
法国 西班牙和德国
他们有很多很多客户
所以他们做了 他们取了这一万名顾客的样本
并测量了六个月前
他们所知道的一切
他们的客户ID 他们的姓氏
他们的信用分数
他们的地理信息
他们的性别
他们的年龄 他们的入职时间
所以他们在这家银行的时间有多长
在那个时间点客户的余额
在那个时间点他们拥有的产品数量
所以产品的数量包括
他们拥有多少产品
他们有一个储蓄账户 他们有信用卡吗
他们有贷款吗
这个客户是否有信用卡
所以有一个是 没有标志的客户
一个活跃会员
另一个是 没有标志
活跃会员可以根据不同的组织有不同的衡量标准
这可能是客户在过去一个月登录了他们的在线银行
或者是他们在过去两个月进行了交易或其他类似的衡量标准
所以银行不知道客户的工资
但是基于其他信息
他们可以估计出客户的工资
而且他们也给了你这些信息
所以六个月前他们测量了所有这些事情并说
所以对于这一万个随机选择的客户
我们是否会只是
观察他们 所以我们只是等待六个月，六个月后
我们将检查那些客户中谁离开了谁没有离开
这就是这个列退出所代表的
它告诉你在这六个月内客户是否离开了银行
所以这里的这个人
在这六个月内的某个时间他离开了银行
几天前他已经不再是银行的客户了
这里的这个人
另一方面，他还是银行的客户
所以这里有一个零 这个人离开了银行
这个人留下来了
如果你看到一个一，这意味着这个人不再属于银行
一个零，这个人 仍然在银行
你的目标是创建一个地理细分模型
告诉银行哪些客户离开银行的风险最高
我今天想说的是
对于很多以客户为中心的组织
这将很有价值
我自己做过这个
我做过很多次
这对任何以客户为中心的组织都有很大的价值
所以每当一个组织处理客户时
这将是一个很大的价值
然后你会学到的技能非常通用
不一定非得是银行
也不一定非得是流失率
地理人口细分模型可以应用于数百万个场景
例如
在银行 同样的场景也可以适用
比如，这个人是否应该获得贷款
这个人是否应该获得信用 再次，你有一个二元结果
基于以往的经验
你会知道
这个人是否可靠
然后你建一个模型
说哪些人更有可能可靠 哪些人更有可能违约
这将影响银行是否批准贷款的决定
这不仅适用于银行
在其他金融机构
你可以找出哪些交易更有可能欺诈
哪些交易更不可能
有很多场景你可以应用地理人口细分模型
甚至不一定是地理人口细分
当你有一个二元结果 你有很多独立变量时
你可以建立一个坚固的模型
这将告诉你哪些因素影响了结果
所以你学到的知识可以应用于任何场景
你有一个二元结果和许多独立变量
你将学到的知识
将告诉你哪些因素影响了结果 你将学到的知识可以应用于任何场景
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p03 10. Step 1 ANN in Python Predicting Customer Churn with TensorFlow.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p03 10. Step 1 ANN in Python Predicting Customer Churn with TensorFlow

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们
我非常兴奋地开始
我们期待已久的课程部分
我正在谈论 当然关于深度学习
你刚刚获得了阿瑞尔的直觉讲座
所以现在你理解深度学习所包含的构建一个人工大脑
所以，你去了 我的朋友们
现在我们即将构建一个人工大脑
使用全新的tensorflow
两点零 这将非常令人兴奋
我们将真正构建一个深度神经网络，其中包含神经元和完全连接的层，这些层连接这些神经元
我们将一如既往地将这一切应用到一个商业问题中
现在我们已经 你知道
在课程中相当先进
我们将要处理的数据集看起来更像是一个真实的世界数据集
许多数据和特征的观察
你会发现我们不仅需要使用我们的数据预处理模板
还需要使用我们数据预处理工具包的一些工具
你准备好了吗
你准备好进入下一个级别了吗
确实 现在我们要做一些更先进的机器学习
所以我非常兴奋
你甚至正在进一步推动你在机器学习方面的专业知识
好的 那么我们开始吧
但首先让我们确保这里的每个人都在同一页面上
这就是整个机器学习的文件夹，包含所有代码和数据集
我已经将文件夹链接发给了你
在这段教程之前
确保你连接到它
现在我们继续
让我们进入第八部分，深度学习，从经典的人工神经网络开始
这意味着完全连接的神经网络，只包含完全连接的层
你知道的，没有卷积层或其他类型的层
这里我们将有一个包含不同特征的输入向量
我们将预测一个结果，这是一个二进制变量
因为你必须知道，实际上人工神经网络可以用于回归或分类
在这里我们将进行分类
但是请注意，我们有一门免费的人工神经网络课程
在这门课程中，我们为回归构建了一个人工神经网络
所以请确保查看一下
我会考虑在某个地方包括链接
这样你就可以得到它
但它真的很好 你将同时拥有两种情况
你知道 有讨论的分类案例和有自由课程的回归案例
好的 所以现在像往常一样
我们将从python开始
我们开始吧
这个文件夹包含实现
人工神经网络，我将
P Y和b 你可以用jupyter
笔记本或google collaboratory打开
当然我们有 我们的数据集
我将现在解释
好的 正如你所见
正如我所说 这确实更像一个真实的数据集，第一次
我们的数据集在这里占据全屏
因为确实这次我们有很多特征
你知道 从这里到那里
和依赖变量在这里
好的 让我来解释这是关于什么的
这是银行的数据集
他们收集了他们客户的一些信息
这些信息是
行号 那只是一个无关的特征
我们将摆脱它
然后客户ID
那只是每个客户的识别键
姓氏
信用评分
地理
意思是国家 客户性别
年龄 任期
意思是 他们在银行的年数
余额
意思是他们账户上的金额
他们使用的银行产品的数量
你知道 如信用卡
或支票簿
或者万事达卡
或者甚至是贷款或房屋贷款
你知道 任何银行产品
好的 这就是每个客户拥有的优惠数量
是或不是 这意味着这个变量等于1
如果客户有信用卡
否则是活跃会员
他是否活跃
你知道 与账户连接
或者使用信用卡
或者其他任何卡 你知道
假设他们有一个测量系统来衡量
如果客户是活跃的
1意味着 当然客户是活跃的
0意味着
好的 然后估计的薪水
你知道客户的薪水
这就是最后一项
然后最后一列这里展示的是因变量
它告诉我们是或不是
嗯 客户是否留在银行或离开银行
1意味着离开银行
是的，0意味着客户留在银行
实际上，这个银行确实观察了他们的客户一段时间
例如 六个月，他们观察
在这六个月内，他们是否离开银行或留在银行
并将这些结果收集在最后一个依赖变量中
同时，你知道，他们得到了所有这些特征
为了猜测
理解这些特征与客户是否留在银行或离开银行之间的相关性
这是有道理的，对吧
因为银行希望有最多的客户，对吧
这是他们赚钱的方式 客户越多
他们在银行里的钱就越多
他们从为客户提供的多样化产品中赚的钱就越多
所以他们当然有兴趣保持最多的客户
因此，他们制作了这个数据集来理解原因
为什么一些客户会离开银行
并且一旦他们能够构建出一个可以预测的模型来预测
如果任何新客户离开银行
你知道 训练好的模型
当然 基于这个数据集
他们将会在新客户上部署这个模型
对于所有模型预测客户会离开银行的客户
他们会做好准备
他们可能会向客户提供一些特别的优惠，以便客户留在银行
你看 所以这一切都是为了防止最忠实的客户离开银行
为什么这叫流失模型
因为顾客流失意味着一些顾客离开
你知道 不再成为顾客
当然，银行已经要求你
最顶尖的数据科学家制作这个预测模型
首先在这个数据集上训练它，以理解这些特征的所有相关性
以及因变量
然后将这个模型部署到未来的顾客上
你将会看到在实施过程中
我们将实际部署未来的机器学习模型，它将应用于不同的客户
你知道，这不是这个数据集的一部分
以便预测这个新客户是否会留在银行还是离开银行
甚至更好
我们将实际预测这个客户离开银行的概率
所以我们还有很多工作要做
但我非常兴奋
因为深度学习是机器学习的一个迷人分支
所以让我们立即开始
让我们打开我们的实现
人工神经网络点
我 P y b
你可以自由地打开它
用我正要做的谷歌协作
或者你喜欢的jupyter笔记本
只要确保你在最喜欢的ide上感到舒适
所以现在实现正在打开
展示它 笔记本完美
这是再次在只读模式下的实现
所以现在我们会点击文件这里来复制这个实现
像往常一样，我们会从头开始重新实现这一切
这样我们就可以通过做来真正学习
这就是副本
让我们删除所有单元格
好的 这个不是文本单元格
当然因为我们想保留这个实现的良好高亮结构
但是让我们肯定移除代码单元格
所以有很多它们
所以你实际上会有一些时间做它
但你知道这不太长
没关系 有一个很长的数据预处理阶段
然后是构建神经网络的很长阶段
我真的详细给出了实现细节
所以你实际上会看到很多步骤，好的
有这么多步骤，我实际上添加了一层结构
因为，正如你所看到的，完整的实现分为三个部分
对了，作业在最后
解决方案，所以让我不要给你看
那几乎就是结束
混淆矩阵和完美
好的
正如你所见，这是一段很长的实现
这将是一段很长的部分
但这绝对值得
深度学习是机器学习的最强大的分支之一
好的 所以让我们开始，首先像往常一样导入库
然后进入第一部分，数据预处理
这就是整个实现的第一部分，它结构化为四个部分
它们是以下部分：第一部分，数据处理
第二部分，构建ann
第三部分，训练ann
第四部分，做出预测并评估模型
然后在每个部分，我们在不同步骤中，第一部分，数据预处理中
我们首先导入数据集
当然 然后我们会有一些数据预处理要做
你知道的 不仅仅是模板中的经典步骤
还有一些额外的工具
我们将一起看到这些
然后在第二部分，我们将首先初始化ann
我们将为我们的人工大脑添加输入层和第一个隐藏层
然后添加第二个隐藏层
然后输出层
然后在下一部分，第三部分，训练ann
我们将首先通过编译ann来开始，你知道的
一个优化器和损失函数
然后我们将在训练集上训练ann
然后在第四部分，我们将把我们的模型部署到生产中
以预测新观察结果的结果
意思是预测一个新客户是否会留在银行还是离开
然后我们将预测测试集的结果
所以你知道 得到那个广泛的向量，最终与混淆矩阵一起计算准确率，好的
所以，再次如你所见，这个实现相当长
所以，确保你有足够的精力和动力
因为我们有一个漫长但令人兴奋的旅程在我们面前
一旦你准备好了
我们将在下一个教程中见面，完成这个实现 直到那时，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p04 11. Step 2 - TensorFlow 2.0 Tutorial Preprocessing Data for Customer Churn Model.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p04 11. Step 2 - TensorFlow 2.0 Tutorial Preprocessing Data for Customer Churn Model

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们 好的
你准备好开始实施你的第一个人工大脑了吗
嗯 我肯定准备好了
那么我们开始吧
让我们把它放在一起
我们将从数据预处理阶段开始
因为我们想尽快进入有趣的部分
让我们高效地做这件事
得益于我们的数据预处理模板
以及我们的数据预处理工具包
因此，我们将在这里做的第一件事是导入库
我们将创建一个新的kotel
我们将进入我们的数据预处理模板，偷取我们想要的单元格
我们将其带回到我们的实现中
第一个单元格，好的
这就是第一件事 然而，我只想给你们展示一些额外的东西
这是关于Google Collab的美妙之处
我想向你们展示这一点，确实
TensorFlow 2.0已经在Google Collab中预安装
你知道，在任何Google Collab笔记本中，你都会打开它
所以，我想向你们展示的是
首先导入TensorFlow，因为，好吧
它在笔记本内部已经预安装了作为库
但我们仍然需要导入它
实际上，在这里，因为我们实际上不会使用Matplotlib
我们将删除这个库的导入
然后只需在这里添加第三个库
嗯 导入TensorFlow的方式已经处理了
确实导入
然后库的名称是TensorFlow
当然 然后添加一个快捷方式
简单的一个 像tf这样的
好的 我将创建一个新的代码单元格
在里面我将输入以下内容：tf双下划线版本
双下划线再次
这将简单地打印我们正在使用的TensorFlow版本
我只想向你们展示，这确实是TensorFlow 2，对吧
全新的TensorFlow
让我们这样做吧
我们需要执行这个单元格和这个单元格
但请记住，如果我们现在执行这个单元格
这将需要一些时间
因为实际上笔记本还没有运行
运行它的方法是点击这里的文件夹
现在是它将连接到一个运行环境以启用文件浏览
主要是让你知道
开始运行笔记本
好的 同时让我们利用这段时间上传数据集
请前往你的机器学习
这是代码和数据集的文件夹
你必须下载它 要么是在上一个教程中，要么是在每个实践活动中的开始
在那里我们进去
然后部分深度学习
几乎接近尾声
顺便说一句你一定很兴奋
几乎看到隧道的尽头
让我们转到人工神经网络这一部分
让我们去Python并选择这个数据集
流失建模csv打开
好的
现在我们有了一切
我们有数据集 顺便说一下，我们的笔记本已经运行
正如你所看到的，它比平时花费的时间要多一点
因为你知道这个数据集这次更接近现实，而且更大
好的，好的
让我们这样做 让我们运行这个单元格以导入库
这次是numpy、pandas和tensorflow
现在让我们运行这个单元格以
确实确认我们自己
我们将使用的tensorflow版本是2.2.0
基本上tensorflow2
这比tensorflow1好多了
我对他们的新版本感到非常高兴
好的 所以确认是好的
现在让我们处理这一部分
一 数据预处理
我们将高效地处理这一点
感谢我们的数据预处理模板和工具包
所以让我们首先创建一个新的单元格以导入数据集
我们已经在完美笔记本中有了它
所以让我们去数据预处理模板
现在我们偷取这个单元格的第二个单元格以导入数据集，好的
让我们回到这里并将它粘贴进去
现在当然问题是我们需要替换什么，嗯
我们需要进行的第一个明显更改是数据集的名称
这次不是data.csv
但是 churn _ underscore _ modeling. csv 很好
然后我们逐行查看
这一行没问题
现在 这一行怎么样
这行代码创建了特征矩阵 x 并且它这样做的方式是
它取所有列除了最后一列
但让我们再次看一下我们的数据集
正确 我们注意到当我向你描述时
这个数据集第一个列实际上是无关紧要的
也就是说它们不会帮助预测因变量的结果
这些列是
你知道这些无关的列显然是这一行
这一行只是给出这个数据集的行号
我们显然不想包括它
然后客户ID
正确 客户ID只是每个客户的唯一标识符
因为你知道每一行对应于不同的客户
所以当然客户ID对因变量退出没有任何影响
所以我们也会排除这个列
我们没有 所以 你知道神经网络自然会处理
但我们就让未来的神经网络学习过程轻松点吧
我们都在同一条船上
好的 然后 姓氏怎么样
姓氏对客户是否会留在银行还是离开银行有影响吗
绝对没有
姓氏 当然
对客户的决定没有影响是否留在银行还是离开银行
所以我们也会排除这个列
然后所有其他
你知道 这里所有其他特征看起来不错
它们可能对因变量有影响
这意味着它们可能帮助预测每个客户是否会留在银行还是离开银行
好的 所以我们肯定会保留所有其他
意思是从这一行开始的所有特征
信用分数
所以在我们的实现中
而不是取所有列除了最后一列
我们将从这一行开始的所有列除了最后一列
意思是从信用分数到预计工资的所有列
这样做的方式仍然是保持范围上限
你知道 在最后一个列的前一个列完成
你知道那就是确切的上限
那就是范围
但是在这个范围的左边我们不会指定任何东西
这意味着第一列
第一索引
但是我们会指定列的索引
我们希望开始的
那就是信用分数
对 我们知道我们希望从这里开始
因此现在问题是那个列的索引是什么
嗯 在python中索引从零开始
所以这有索引零
然后这有一
这有二
这有一个x射线
因此这里我们不会像以前一样在这里指定范围的下限
嗯我们会指定索引三
因此我们可以取所有列
从索引三开始的列到前一个列的所有行
取这个数据集的所有值
这将创建一个相关的特征矩阵完美
所以这行代码已经完成
下一个呢
显然下一个是完美的
它将只取这个数据集的最后一列
这正是我们想要的因变量
退出 所以这里
没有改变
我们可以运行这个单元并得到数据集
我们的特征矩阵和因变量向量
让我们检查一下 实际上让我们创建两个新的单元格
对 一个我们将打印特征矩阵x
一个我们将打印因变量向量y完美
让我们这样做 实际上我们先运行这个单元打印特征矩阵x，好了
我们确实有了所有特征从信用分数开始
这是一个信用分数
然后你知道居民国家
然后是性别和其他你知道的，你有信用卡
是或否是活跃的
最后是估计的薪水
好的 所以我们有了所有这些特征，完美
当然我们没有依赖变量的值
因为它们就在这里，y就在这里，好了
这些都是客户决定留在银行还是离开的决定
所以当然这里对应的是这个客户
这个客户显然决定离开银行
这实际上是这里同一个
退出1
然后，第二个客户决定留在银行，对应于这里
这正是这里
好的 这个客户
所以都挺好 到目前为止
数据预处理阶段的第一步成功完成
现在让我们继续进行数据预处理阶段的更复杂步骤
这是关于编码分类数据
是的 当然，我们发现有两个分类变量
第一个是提供客户居住国的变量
第二个是提供客户性别的变量
我们必须做一些编码工作来编码这些分类数据
在简单的标签中
你知道，性别的零和一
或者对这类变量进行one hot编码
确实，这些值之间没有顺序关系
你知道，这些类别之间
法国 西班牙和德国
好的 让我们这样做
让我们首先对性别列进行标签编码
所以让我们创建一个新代码单元
当然，为了高效地做这件事
我们将进入我们的数据处理工具包
我们将向下滚动来找到
顺便说一下，数据集中没有空白数据
我检查了它们 实际上，你也必须检查它们
但一切都好 我们不必处理任何空白数据
我们可以直接转到编码分类数据
现在我们正在处理标签编码
性别列
嗯 我们将使用此
这正是我们需要进行标签编码的工具
所以我偷了这个代码单元
现在我把它添加到我们的笔记本中
这是我们的实现
但请记住，在我们的数据预处理工具包中
我们对因变量向量进行了处理
但现在我们想在特征矩阵x的特定列上进行操作
因此我们只需要在这里替换y
用特征矩阵x的特定列
我们想对其应用标签编码
因此我们现在的问题是
我们如何得到这一列
嗯 我们需要获取索引
然后使用该索引调用x
好的，就是这样
这是x的第一列
它有索引0
这是x的第二列
它有索引1
这是x的第三列，它有索引2
因此，在这里我们只需将y替换为我们的特征矩阵x
我们取所有行
并且我取这一列
你知道的 在python中这是一个范围
然后取我们需要的列
即性别列，它有索引2
我只需要在这里添加索引2
这样它将取所有行
但只取索引2的列
现在当然我们需要将这个放入fit transform方法中
从我们的对象调用
这是一个标签编码类的实例，工作完成
对x的特征矩阵中的性别列进行了标签编码
让我们确保这是正确的，创建一个新代码单元
并打印特征矩阵x的新打印
运行单元格
你知道的
好的
现在打印x并确保我们不再看到女性
男性 女性 但无论何种编码
可能女性会被编码为1
或者女性男性会被编码为0或1
让我们看看它们做了什么
好的，就是这样
这是标签编码后的新列
因此女性被编码为0，男性被编码为1
这当然是机器随机选择的整数关联
现在没问题了
这列数据已经成功标签编码
现在我们将进行地理列的独热编码
这次我们需要进行独热编码
因为法国、西班牙和德国之间没有顺序关系
所以我们不能 你知道的
将法国编码为0，然后西班牙编码为1，德国编码为3
我们需要进行独热编码
而不是顺序编码
那么我们就开始吧
让我们回到数据预处理工具包
这次让我们来处理销售数据
这正是一个执行独热编码的单元格
让我们将其粘贴到一个新的代码单元格中
现在问题是
当然，为什么我们要替换或更改那个单元格
确实，我们需要在地理学列上执行独热编码
记住，你在这个代码中唯一需要更改的是列的索引
你想在地理学列上应用独热编码
记住在我们的数据csv文件中，第一部分数据处理部分，well
类别变量有三个不同状态在第一列
这就是为什么我们在这里有索引零
但这次，这一列实际上是第二列
因此它有索引一
因此，我们只需要非常简单地这里将零替换为一
好的 就是这样了
其余的会自动完成
让我给你展示
让我们运行那个单元，现在我们创建一个新的代码单元再次打印
好的
现在运行那个单元，看看x变成了什么
确实，记得当我们进行独热编码时
虚拟变量实际上位于特征矩阵的第一列
它们就在这里
你知道，在前三列
让我们看看
看看如何进行独热编码
这是虚拟变量的第一组合，对应于法国
你知道这里的行是一样的
因此，朋友被编码为100
现在，西班牙被编码为010
最后，德国被编码为1010
好的 这就是我们的独热编码
我们再也看不到性别列了
但没关系 它还在这里
所以完美 成功的热编码不仅完成
但也高效地完成了
多亏了我们的数据预处理工具包和模板，现在一切都好。
让我们继续进行下一步
将数据集分为训练集和测试集
再次，我们将以如此高效地完成它
多亏了这个时间我们的数据预处理模板
确实我们现在必须偷了
这个单元将数据集分为训练集和测试集
让我们把这个粘贴回我们的实现，在新的代码单元格这里
现在我们可以完全信任这个
百分之百 我们可以直接使用这个模型
我们不需要再对这些四个实体进行打印
我们完全理解它们的工作原理
你可以自由地进行操作
如果你愿意，你可以对这个副本进行任何修改
当然，笔记本的复制
最后，我们有数据预处理阶段的最终步骤
这是特征缩放
现在我想说一些非常非常重要的事情
特征缩放对于深度学习来说是绝对必要的
每当你构建一个人工神经网络
你必须应用特征缩放，这在根本上是必要的
这是如此基础，以至于我们会对所有特征应用特征缩放
你知道 无论它们是否已经具有零和一的值
你知道，就像这些虚拟变量一样
我们会对所有内容进行缩放
这是因为对于深度学习来说这样做是非常重要的
所以这里的特征缩放步骤会非常简单
我们将只使用我们的数据处理工具包
我们将直接放在最后
因为我认为这是我们最后一个工具
是的，我们在这里
我们将取那个完整的单元格，并将其粘贴回一个新的代码单元格
就在下面特征缩放下面
我们将将其粘贴在这里，而不是选择一些特定的索引在这里
我们将只取所有内容
所以我在这里删除了我们的所有索引选择
这样我们就可以放大所有内容
这就是神经网络的正确方式
你知道，为了构建和训练神经网络
完美 这将对所有特征进行特征缩放
对训练集和测试集所有特征进行缩放
但当然，我们的标量对象只适合训练集
记住，避免信息泄露
但这不会改变
但你看，现在我们已经有了执行特征缩放的代码
那么让我们开始吧
让我们进行这次最后的促销活动
然后数据预处理阶段将结束
那么恭喜你
我希望我们做得足够高效
这就是它应该的样子
顺便说一下，我想提醒你
数据预处理阶段占数据科学家工作的70％
这就是为什么对我来说给你一些非常高效的数据非常重要
预处理模板和工具包
正如你所见
我们可以在20分钟内高效完成
在我解释的情况下，可以在20分钟内完成
在没有解释的情况下
甚至在10分钟内
我希望你能理解并重视其重要性
现在，我的朋友们
是时候进行令人兴奋的步骤了
这个实施的令人兴奋的部分
我说的 当然关于第二部分
构建人工神经网络
所以我们开始，通过好的能量来充电
当你准备好
让我们一起解决第二部分
我们将首次构建
利用人工智能技术tensorflow2.0构建一个人工大脑
我迫不及待地想在下一个教程中见到你 在那之前享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p05 12. Step 3 - Designing ANN Sequential Model & Dense Layers for Deep Learning.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p05 12. Step 3 - Designing ANN Sequential Model & Dense Layers for Deep Learning

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们
欢迎来到本项目的第二部分
我们将一起构建人工神经网络
我非常兴奋开始
我们将分四步进行
第一步我们将初始化ann为一个层的序列
然后我们将添加输入层和第一个隐藏层，由一定数量的神经元组成
我们将一起选择
然后我们将添加第二个隐藏层
你知道 为了确实构建深度学习模型，而不是浅层学习模型
然后最后我们将添加输出层
它将包含我们想要预测的内容，好的
让我们这样做 我们将在这同一个教程中解决这四个步骤
所以让我们这样做，从初始化ann为一个层的序列开始
所以我们将创建一个新的代码单元
现在让我来解释我们需要如何进行
首先我们必须做的就是显然地创建一个变量
它将不是其他，正是人工神经网络本身
并且猜猜这个人工神经网络变量将以某个类的对象形式创建
并且那个特定类是sequential类
它确实允许构建人工神经网络，作为层的序列
而不是计算图
你知道
正如你在直觉讲座中所看到的，人工神经网络实际上是一个层的序列 你知道
从输入层开始 然后依次我们有全连接层，直到最终的输出层
这就是我所说的一个层的序列
然后另一种类型的神经网络确实是一个计算图
它们是，你知道
神经元以任何方式连接 不是按层的顺序 一个例子是boltzman machines
你知道
受限boltzmann machines或深度boltzmann machines是计算图的伟大例子
当然它们不在这个课程中涵盖 因为这是真正的高级深度学习
但它们在我们的深度学习课程中涵盖
如果你真的对深度学习感兴趣，想要更深入地了解这个分支
那么我将非常高兴地欢迎你进入深度学习
它是一门课程 但现在让我们只获得对完全连接神经网络的正确介绍
并且 这就是为什么我们将创建一个新变量
它将是我们的新神经网络 但现在让我们得到正确的深度学习介绍，只有完全连接的神经网络
就是这样
我们将其称为ann
并且它将不会比我们即将构建的人工神经网络更少
我们将创建一个变量，它是一个顺序类的对象
好的 但是当然，顺序类并不是凭空而来的
实际上，它来自keras库的模型模块
自从 TensorFlow 2.0 之后，TensorFlow 成为了 TensorFlow 的一部分。
在我们将 TensorFlow 和 Keras 分开之前
但是自从新的tensorflow
新版本的 tensorflow 2.0 很好地将 keras 集成到了 tensorflow 中
因此，在这里调用顺序类的方式是调用第一个tensorflow
它有一个快捷方式tf
我们从中调用keras库
然后我们从keras库中调用models模块
然后我们确实调用了那个顺序类
所以这一切你都知道
创建这个a n变量
它代表了我们的人工神经网络，作为那个顺序类的一个实例
它初始化了我们的人工神经网络作为一个层的序列
这是我们的第一步
恭喜你，现在
你真的迈出了如何构建人工神经网络的第一步
所以让我们继续前进
那就是添加输入层和第一个隐藏层
这就是我们将开始使用著名的tensorflow中的dense类
甚至在pytorch中
这是另一个伟大的库来构建神经网络
无论你在构建人工神经网络的哪个阶段
你知道 无论你的人工神经网络的状态如何，添加全连接层的方式是使用dense类
我们使用它的方式非常简单，就是通过我们的人工神经网络对象
你知道 那个序列类的实例
我们从中调用序列类的一个方法
那个方法是add
你知道 我们当然希望序列类中有一个add方法
这就是我们现在需要的方法，来添加任何我们想要的东西
无论是隐藏层还是dropout层
你知道，这允许防止过拟合
或者你知道，我们可以通过卷积神经网络看到
我们也可以在d层添加一个卷积
这是一个卷积层
我们可以添加任何东西
但现在我们想要添加的是一个简单的全连接层
添加它的方法是进入这些括号
因为这是一种方法
好吧，它就是要添加一个完全连接的层
这将是一个新的物体
你知道，它将是一个新的实例，一个新的类
并且这个新的课程当然是舞蹈课
所以我们即将构建的全连接层
将作为dense类的一个对象被创建
因此现在我们唯一要做的就是调用这个dense类
这将创建一个全连接层的对象
同时它会自动在输入层上运行
所以我们调用这个dense类
再次强调，这个dense类并不是凭空出现的
它属于某个库的路径
当然，这个库的根是我们的tensorflow库
然后，我们将再次调用keras库
这就是我们这次不再称之为模型模块的地方
但实际上，你知道这是列表的顶部层
那就是我们需要在这里添加的东西
这是包含不同工具的模块，通过这些工具
我指的是要很好地添加课程
在你人工神经网络中你想要的任何一层
所以这里有层，说到这些类
好吧 那就是来自这个层模块，我们将称之为时态类
哪个 因为任何类可以接受多个参数
在这里我们必须确实输入这些参数
最重要的一个是这个units
它正好对应于神经元的数量
你知道的，对应于你想要在第一个隐藏层拥有的隐藏神经元的数量
你知道的，不是在输入层
我们将会自动有不同的特征
你知道的，在输入层
输入神经元将只是所有这些特征
从信用评分开始
这将是一个神经元
然后另一个输入神经元
然后另一个 你知道一直到这个
所有这些都将是输入层中的输入神经元
但当我们创建第一个隐藏层时
我们将有一些隐藏神经元
并且在这个密集函数中
我们可以指定
当然，我们想要拥有多少隐藏神经元
现在，深度学习中最常被问到的问题出现了
那个非常著名的问题
我们如何知道我们想要多少神经元
有没有一个经验法则
或者我们应该只是实验
不幸的是，没有经验法则
这完全基于实验
或者你知道的，我们称之为艺术家的工作
你必须尝试不同的超参数
你知道我们称它们为超参数
意思是这些参数在训练过程中不会被训练
所以不幸的是没有规则可循
因此我们不得不在这里选择一个数字
这个数字听起来不会无关紧要或夸张
这个数字将是6
我实际上尝试了几个数字
最后我得到了差不多的准确性
所以没问题
你可以尝试不同的数字 如果你想
但是六是完全可以的
所以这里在这个密集的课程中，我们将输入第一个参数
这是单位
单位等于六，完美
好的 现在，下一个重要的参数
你知道在这个庞大的参数列表中
你可以看到很多它们 但是不要担心
我们将保留所有默认值
除了这个，它对应于
当然，这是对应于激活函数
你在直觉讲座中看到的游击队
全连接神经网络的隐藏层中的激活函数
必须是修正线性激活函数
因此，这就是我们必须在这里指定的
当然，我们不想要没有激活函数
所以我们必须在这里指定我们希望使用修正线性激活函数
指定这一点的方式是在这里的激活参数中输入
激活函数的代号是直连器
也就是我们所说的
Relu 这就是激活函数的代号
这就是你需要在这里输入的
以便构建一个完全工作的第一个完全连接的隐藏层
恭喜你
你现在知道如何构建 实际上
你知道一个浅层的神经网络
你会在几秒钟内知道如何构建一个深度神经网络
因为实际上在这里添加第二个隐藏层的方法不能再简单
你需要做的就是复制这一行代码
然后在这里新的代码行中添加第二个隐藏层
你需要粘贴它
这就是我的意思
通过这种方法，你可以在任何阶段添加任何新的层
在你神经网络的构建过程中
无论你处于哪个阶段
你都可以使用这个添加方法来添加任何东西
添加第二个隐藏层的方式与添加第一个隐藏层相同
除非你确定想要改变隐藏神经元的数量
但你知道在第一个隐藏层中有六个隐藏神经元
而在第二个隐藏层中有另外六个
这完全没问题 但是再次强调，你可以改变这里的超参数值
也许最终你会得到更高的准确率
如果这样的话
请通过评论或私信分享给我
好的
现在要添加输出层
你需要做一些特别的事情
这与我们之前做的不同
让我们一起做
创建一个新的输出层
让我们再次粘贴我们之前复制的内容
但这次我们需要改变两件事
这与这两个参数的值相对应
但首先让我来解释为什么其余部分保持不变
当然，因为我们正在添加一个新层
并且add方法可以添加任何你想要的层
当然包括输出层
所以我们仍然使用add方法添加这个最终输出层
当然我们希望输出层与第二个隐藏层完全连接
因此我们再次使用dense类
所以这里没问题
但接下来这两个参数需要改变
如果你遵循了直觉讲座
你应该知道这两个变化是什么
好的
让我们从第一个开始 根据你
我们需要替换这里的什么 当然，这个值需要替换
根据你，六需要替换成什么值 为了得到答案
我们需要查看我们的因变量
也就是这个
因为记住，输出层包含输出的维度
你知道，你想要预测的输出
而我们实际上想要预测一个二元变量，它可以取一或零
而维度实际上是一
因为我们只需要一个神经元来得到最终预测零或一
然而 如果我们进行分类，有一个非二元因变量
比如一个有三个类别的因变量
让我们说abc
我们需要三个维度
你知道，三个输出神经元来再次
编码这个因变量
因为 当然 再次强调，a、b、c这三类之间没有先后顺序的关系
例如，a
必须用100编码
然后b必须用010编码
c必须用001编码
因此，你需要三个神经元来获取这些值
用0和1来编码你的三类a、b、c
但是，在这里，因为我们实际上有一个二进制变量
一个二进制结果
您只需要一个神经元将这些结果编码为1或0
因此，我们现在需要替换的这个单元参数的值实际上是1
好的 一个输出神经元编码因变量
然后第二项更改对应
当然，到那个激活函数
并且更具体地，到激活函数的值
再一次 记住在直觉讲座中，输出层的激活函数的激活函数
你不想要有一个归化激活函数
但sigmoid激活函数
为什么那样是因为有一个sigmoid激活函数可以让你得到
不仅最终预测
更好的是它会给你二进制结果的概率
所以我们不仅会得到客户是否选择离开银行
或不银行的预测
但我们也会为每个客户得到客户离开银行的概率
这一切都要归功于sigmoid激活函数
所以你肯定只想在输出层使用sigmoid激活函数
你知道所有其他层
你知道其他全连接层将确实使用Rectifier激活函数
现在我真的要说恭喜你
因为我们实际上已经完成了创建这个非常第一的人工神经网络
所以你可以为自己感到骄傲
你刚刚构建了一个人工大脑
这很难吗 这令人震惊吗
我不这么认为
这就是TensorFlow 2.0的魅力所在
这就是TensorFlow 2.0 我希望你们喜欢这个
我希望你们喜欢构建你们的第一个人工大脑
但这还没有结束
我们目前只有大脑
你知道 但这是完全愚蠢的
实际上，因为它还没有在数据集上训练过
我们将让它变得聪明，我们将让它变得聪明
在第三部分
训练我们的神经网络，我们将首先使用优化器和损失函数编译神经网络
然后，我们将在我们的整个训练集上训练我们的人工神经网络，训练一定数量的轮次
你将看到，训练过程非常有趣，值得可视化
我迫不及待地想向你展示
让我们在下一个教程中一起攻克第三部分
在此之前，享受机器学习
In part three 在第三部分
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p06 13. Step 4 - Train Neural Network Compile & Fit for Customer Churn Prediction.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p06 13. Step 4 - Train Neural Network Compile & Fit for Customer Churn Prediction

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们 欢迎回来
我相信你刚刚构建了你的第一个人工神经网络后感觉棒极了
但请记住，这仅仅完成了工作的一半
另一半当然就是训练它在整个训练集上
我们将分两步来完成这个任务
第一步是使用优化器、损失函数和指标来编译ANN
当然，指标将是准确率
Which will be of course the accuracy
因为我们在进行一些分类
然后第二步当然就是训练ann在训练集上
在若干个epoch上
你准备好了吗 让我们开始
从第一步开始
编译ann
所以再一次，这会超级简单
多亏了tensorflow库集成的keras
因为确实要编译我们的ann
我们需要从我们的对象开始
我提醒过，这个对象是顺序类的一个实例
然后我们从这个对象中调用一个新的方法
但这次当然不会是add方法
但你能猜出这个方法会是什么吗
你知道在tensorflow中没有陷阱，也没有混淆
嗯 编译人工神经网络的方法是编译方法
就是这么简单，对吧
我们甚至都不用查看tensorflow的文档
哪一个 顺便说一下，我仍然建议您看一下
因为这样你会得到关于你在tensorflow库中拥有的多种工具的大量信息
但这里非常直观
这非常容易
所以现在我有一个下一个问题要问你
根据您的说法 我们在这个复合方法中作为参数输入什么
实际上我已经说过了
我们需要输入三个参数
第一个是优化器，选择优化器
第二个是损失函数，选择损失
第三个是带s参数的指标
因为注意，你可以同时选择多个指标来评估你的ann
但我们只会选择一个
我们选择准确率
就这样 这些是三个参数
我建议我们开始输入它们
然后我们输入它们的值
好的 那么我们从第一个开始，优化器等于所有正确，逗号
下一个是损失，损失函数
最后第三个是指标参数
好的 对于优化器
你想要哪一个呢，在直觉讲座中
Kio提到了
最好的优化器可以执行随机梯度下降
你知道最好的那些
我推荐的默认优化器是原子优化器
这是一个非常高效的优化器，可以进行随机梯度下降
让我提醒一下，随机梯度下降可以做得很好
它会更新权重
以减少预测值与真实结果之间的损失误差
你知道 当我们在训练集上训练ANN时
在每个迭代中
我们会将批次中的预测结果与同一批次中的真实结果进行比较
这里的优化器会通过随机梯度下降更新权重
因为我们将要选择原子优化器
在下一次迭代中选择两个
希望减少损失
好的 这就是为什么在这里我们必须选择一个优化器
但也要选择损失函数
这是计算预测值与实际结果之间差异的方式
然后是准确率
当然 因为这是我们的最终评估指标
好的 正如我们所说
我们将选择Adam优化器，它的代码名仅仅是
但没大写字母atom
好的 恭喜你
现在 你知道如何使用优化器编译人工神经网络
但我们也必须用损失函数编译它
现在你必须知道一个非常重要的事情，当你在做二分类时
你知道分类
当你需要预测一个二元结果时
嗯 损失函数必须总是如下所示，输入引号中
当然 这是对分数的二元
交叉熵就像那样
现在让我告诉你，如果你在做非二元分类，你将不得不输入什么
你知道，比如 例如
预测三个不同的类别
在这里，你需要输入多分类交叉熵损失
对于二分类问题
损失必须是二分类交叉熵
对于非二分类问题
损失必须是称为交叉熵的损失
在做非二分类问题时
当预测多于两个类别时
当激活函数不是sigmoid时
但是softmax
正确 我借此机会也向你介绍其他分类案例
你可能会遇到
好的 现在你已经知道一切
然后记住对于回归
因为我们也可以用神经网络进行回归
嗯 我们有这门免费的课程
我给你链接
你可以免费参加这个课程
你将获得完整实现一个回归案例研究的人工神经网络
你真的可以做所有有关人工神经网络的事情
好的，太好了
现在让我们进入最后的参数
如我所说，我们可以选择同时使用多个指标
因此为了正确输入这个参数的值
我们必须在方括号内输入它们
我们得在方括号内输入它们的值
这应该是
你知道评估你神经网络训练期间的不同指标的列表
但你只会选择主要的一个
你知道最重要的一个
那就是准确率
你需要输入所有的正确
所以准确率
就像经典的拼写
现在恭喜你
你知道如何对你的神经网络进行完整的编译并使用优化器
一次损失和一些指标完美
所以现在我们继续进行最终的步骤
这意味着我们将在整个数据集训练上训练ann
所以让我们创建一个新的代码单元
而现在根据你
我们需要如何开始这个训练呢，嗯，再一次
你知道这总是一样的事情
我们需要获取我们的ann对象
然后调用一个新的方法来执行训练
然后输入一些参数
那么我们开始吧
我们先从ann开始或者对象
然后根据你
训练你的人工神经网络的方法会是什么
嗯 这里什么也没有改变
实际上我认为我在课程早期说过
它是fit方法
fit方法并将总是使用相同的参数
第一个是x训练
你知道训练集的特征矩阵
然后是y训练，训练集的因变量向量
实际上我们需要输入两个更多的参数
首先是批量大小
这意味着而不是一个接一个地将你预测与实际结果进行比较
你知道计算并减少损失
你将用多个预测来做这件事
与多个真实结果进行批量比较，这里的批量大小参数
您知道 批量大小参数将给出恰好的预测数量
您希望在批量中要比较的那个相同数量的真实结果
经典的批量大小值通常选择的是32
正确 如果您不想花费太多时间来调整这个超参数
我推荐选择默认值32
但是不管怎样，我想强调这里的超参数
因为确实它非常重要，我们需要记住我们在进行批量学习
好的 所以批次大小等于三二
最后我肯定你知道我们必须在这里输入的最终参数
当然，这是课程数量
你知道 神经网络必须在一定数量的课程中被训练
以便随着时间的推移提高准确性
所以我们将清楚地看到一旦我们执行了这个单元格
课程数量的参数名称仅仅是课程
好吧，你会看到它会非常快
所以我们可以只取100个时期
但是再次强调，你可以选择另一个数字
只要它不是太小
因为你知道，你的神经网络需要一定的时期数量
以便能够正确学习
你知道 学习相关性以获得最佳预测
好的，太好了
所以我们现在完成了第三部分
所以我建议我们不再等待
并且我们执行到目前为止尚未执行的所有销售
我想你知道
从第二部分开始
是的，没错 这是数据处理阶段的最后一笔销售
它被正确执行
所以我们实际上一个接一个地运行每个单元格
看看训练结束时我们会得到什么
所以我们从这个初始化ann开始
现在，添加输入层和第一个隐藏层，好
现在添加了第二个隐藏层，一切良好
现在加上输出层，一切都很好
现在，我们进入第三部分
执行第一个
这个单元格正在编译所有内容都很好
现在准备好了吗
我的朋友们 我们即将对人工神经网络进行训练
训练集超过一百个时期
我们开始了 训练即将开始
正如我所说，进展得很快
但看看这个 看看准确率如何随着轮次的变化
我们可以看到它实际上正在迅速增加
我们主要可以看到它实际上正在收敛
你知道它很快收敛
你知道我们在第八十六轮时收敛
你知道在大约第二十轮时
实际上我们不需要
那就是一百个时期
但二十个很好
但不管怎样 你知道它进展得很快
我相信很快就会结束
因为确实 是的
我们完成了 训练在大约二十秒内完成
在训练集上的最终准确度
我们需要在测试集上检查一下，平均值大约为零点八六
八十六 这真的很好
这意味着在一百次观察中，您有八十六次正确的预测
祝贺你
你制作了一个非常好的第一个深度学习模型
你可以为自己感到骄傲
现在，你可以稍微休息一下
因为我们将进入第四部分
我们不仅将进入第四部分
但是你也会看到，你将会有一个小作业要做
作业内容是预测一个单一观察结果的结果
这意味着一个单一客户
你将要预测这个客户是否会留在银行还是离开
你将在这里输入你的解决方案，并在下一节课中我们一起实现这个解决方案
所以确保你要做
请至少尝试去做
你实际上知道如何去做
因为我们已经学会了如何做一个单一的预测
在你知道一个单一观察的预测之前
所以你已经拥有了一切
也许再检查一下
第三部分分类
如果你有疑问
但是就这样
那就是你的作业 你必须使用我们的a和n模型来预测
如果这个客户具有以下信息是否会离开银行
是或否 并且这些以下信息是一个法国客户，信用分数为600
他是一个男性 他今年44岁
他在银行已经工作了3年
他在账户中有60000美元
他在银行有两个产品
他确实有一张信用卡
他也是一个活跃的成员
他估计的年薪为50000美元
问题是
我们是否应该和这个客户说再见
嗯 请找出答案 并在下一节课中我们看看你是否正确，直到那时享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p07 14. Step 5 - Implementing ANN for Churn Prediction From Model to Confusion Matri.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p07 14. Step 5 - Implementing ANN for Churn Prediction From Model to Confusion Matri

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们 欢迎回来
并且主要是欢迎来到第四部分，预测模型并评估模型
在上一个教程的结尾
我实际上要求你做一些家庭作业
就在这里
这包括使用你的ann模型来预测
根据以下信息，客户是否会离开
是或否，银行
我希望你做得很好
实际上你已经有了所有必要的工具
并且这是我们之前做的
在第三部分分类中
我相信你会做得很好
让我们看看
让我们一起实现解决方案
所以我在这里留下了这个代码单元格来输入解决方案
但这只是一个示例
所以让我们删除它
那么我们如何成功完成家庭作业呢
当然，我们需要首先获取我们的ann模型
我们将调用一个新方法
你知道，不同于add方法或fit方法，对吧
当然，我们需要调用这个predict方法，对吧
绝对没有陷阱
我们调用这个predict方法来预测
是或否 根据以下信息，客户是否会离开银行
而且，既然这是一个方法
我将添加一些运行
在这里 让我实际上滚动一下
你知道，以防你对底部边框感到不舒服
好的 所以预测
然后好的 所以你有预测方法的所有信息
但我们确切地知道要预测什么
这在家庭作业的指示中给出了
我们需要输入这些信息
但是有几件事需要注意
实际上有三件事，这就是我为什么真的很想给你这个家庭作业
因为我想看看
你是否能注意预测方法中的三个重要事项
让我们从最重要的开始
那就是双方括号，对吧
这是非常重要的记住
预测方法的任何输入都必须是二维数组
无论是用于预测的测试集
结果的象征
对于观察的结果的象征
或者它是否是一个单一的预测
好的 任何东西都必须放在一个双方括号内
这使得它成为一个二维数组
基本上，砖块方法期望的格式总是一个二维数组
好的 那就是第一件事
然后在这个数组内部，我们将输入好的
这里的不同信息
这引导我提到第二个重要事项，你必须注意
这是关于这里的变量
地理朋友们
根据你的说法，我们是否必须输入
如你所知 这里的地理变量第一信息
我们是否必须输入字符串法国
或者我们是否必须输入其他东西呢
当然我们必须输入其他东西
那就是另外的变量值
对了，这就是你第二件事要做正确的事情
因此现在我们需要检查法国使用的编码是什么
嗯 记得如果我们看一下我们的特征矩阵x，就像在上面
你知道在第一部分中，我们会看到
这就是特征矩阵x
包含所有用户的整个矩阵
为了知道法国对应什么
你知道 在编码方面
在我们进行独热编码之前，我们需要看一下第一个观察结果
因为确实第一个观察结果对应于朋友
因此现在我们只需要将朋友与独热编码进行比较
结果是我们之前所做的
我们可以看到第一行包含一个零零作为虚变量的值
因此朋友确实被编码为111
因此，法国国家的虚变量值
以及地理变量确实是111
这正是我们所需要的
并且这里是第一个参数
那么我们来做这个 让我们输入一零零零
基本上这就输入了第一个参数的第一个值
地理
然后其余的都很简单为信用分数
我们将输入六百
然后我们看看性别男性
所以记住男性被编码为一
女性被编码为零
所以，为了进入男性性别
我们需要输入一
好的 然后40岁
我们简单地输入40
然后10年3年
我们输入3
然后余额6万美元
我们输入6万美元
然后看看产品数量
2所以2
然后这位顾客有信用卡吗
是的 所以1因为1对应是，0对应否
这位顾客是活跃会员吗
是的，所以又是一
预计工资
最后5万美元
所以我们在这里的最后一个参数值是5万美元
好的 是的
很好，优秀
现在我有一个问题要问你
你认为我们已经完成了这个预测
你知道，使用这些信息进行预测
而答案是否定的
这引导我注意第三件事
记住，预测方法应该调用观察值
这些观察值与训练中应用的相同缩放
因为我们用缩放的特征值训练了我们的人工神经网络
你知道，特征值的缩放值
嗯 预测方法必须调用这些观察值
这些观察值应用了相同的缩放
而这是你必须记住的第三件事
你必须应用这个sse对象来缩放这个单个观察值
对 这非常重要
确保注意这一点
如果在训练中有些缩放
是的 就是这样
而且总是这样，对神经网络来说
因此，在预测方法中，嗯
我们需要缩放这个单个观察值
而方法就是
当然，通过调用我们的sse对象
是的 这个，小心
不是fit transform
因为拟合变换被用来记住
获取训练集中的均值和标准差
以便拟合你的标量
到训练集 但是，对于测试集
我们只需要调用变换方法
因为如果我们再次拟合它
标量将很好
这将导致一些信息泄露
你知道我在第一部分数据预处理中解释了这一点
再检查一下 如果你需要
但请记住，在测试集或在你将模型部署在生产的新观察中
你只能应用变换方法
这就是我们在这里要称呼的
变换，就是这样
它必须作为输入
整个观察，在这对方括号中
好的 完美，很好很好
所以基本上就是这样现在我们可以运行那个单元格
现在我们可以得到我们的预测
但是要记住当我们编译我们的ann时
你知道 一个优化器
一个损失函数和一个指标
记住在我们的人工神经网络输出中
显示一个sigmoid激活函数
因此它将以概率的形式返回这个预测
这意味着我们将得到一个最终的结果一或零
这个客户是否离开或留在银行
嗯 我们计算这个客户离开银行的概率
但你会看到得到最终预测一或零非常容易
但首先让我给你展示这个预测的结果
所以我们要把这些都放到一个打印语句中
好的 所有这些都放在第三对括号中
现在让我运行这一行
我们得到的结果是这个客户离开银行的预测概率是0.04
你知道零点零三八
零点零四
因此预测这位客户离开银行的可能性非常低
如果你不想以概率的形式得到结果
将结果转换为最终预测的技巧非常简单
您只需要在这里添加
您知道在最后一对圆括号之前
更大的符号
然后 哦
0.5
为什么那是因为你知道所有这些
你知道一个预测和nc转换
以及所有客户的信息到这里返回的恰好是预测的概率
在这里我们选择0.5的阈值
以说如果预测的概率大于0.5
我们将认为最终的结果是1
因为预测的概率结果是1大于0.5
这意味着预测的结果是1的可能性大于50%
所以我们将认为它是1
然而预测的客户离开银行的概率低于0.5
那么 我们将认为它是0
当然你可以选择一个不同的阈值
特别是在你有关键结果时
你知道对于关键决策
那么在这种情况下你可以
例如 增加阈值
但这里让我们只选择默认值0.5
这对我们的案例研究完全有意义
因此现在我们重新执行单元格
我们将当然得到最终的结果
这将当然是0或false
你知道false
我们不应该和那个客户说再见
或false 你知道客户不会离开银行
换句话说它将留在银行
很好 对银行是好消息
但是不管怎样 我只是想向你展示如何使用人工神经网络
预测单个观察结果的结果
这意味着单个客户
记住三件事
你必须将你的信息输入到一个二维数组中，双方括号配对
然后你需要在这里小心处理虚拟变量的值
而不是为该分类变量输入字符串
第三件事记住要应用你的sse对象的缩放
因为你的人工神经网络是用缩放值训练的
好的
所以现在让我们完成这个实现
你知道最后两个单元格我们有
顺便说一下我给你了一些重要的注释在这里
所以你可以记住这基本上就是我解释的
但是不管怎样现在我们有两个单元格要去
第一个是
你知道那个单元格
你知道得很清楚 我们在预测测试集结果时，将预测向量和真实结果向量并排放置
预测向量广泛分布
和真实结果向量广泛测试集
我们将通过使用我们的工具包进行最有效的操作
最后，我们将制作混淆矩阵，以获得测试集的最终准确率
好的 让我们高效地做这件事
所以我们将回到我们的机器学习文件夹
你知道，使用我们的工具包进行操作
所以我点击这里的快捷方式
以获取机器学习文件夹的原始基础
z
然后我只是去
你知道，进入分类三部分以获取任何模型
让我们取
你知道，逻辑回归 例如
然后python 然后我可以打开这个实现
它确实包含了很多工具
你知道，我们可以用它进行分类，就像我们现在正在做的ANN一样
现在我只是滚动并获取
你知道，最终的销售
它将确切地执行我们现在对ANN所做的操作
首先，将预测向量和真实结果向量并排放置
所以获取那个单元
让我们将那个单元粘贴到新代码单元这里
但请记住，现在我们的分类器
不再称为分类器
但ANN返回预测的概率形式
嗯
我们只需在这里做一点小改动
当然将我们的预测概率转换为二进制结果
零或一 窍门与这里相同
当然将我们的预测概率转换为二进制结果，零或一 窍门与这里相同
当然将我们的预测概率转换为二进制结果，零或一
窍门与这里相同
当然将我们的预测概率转换为二进制结果，零或一
窍门与这里相同
当然将我们的预测概率转换为二进制结果，零或一
窍门与这里相同
当然将我们的预测概率转换为二进制结果，零或一
窍门与这里相同
当然将我们的预测概率转换为二进制结果，零或一
窍门与这里相同
当然将我们的预测概率转换为二进制结果，零或一 窍门与这里相同
零或一，然后其余部分相同
这一切都很好
那么我们来玩那个单元格
然后我们确实会显示彼此相邻
首先在左边是一个预测向量
为什么散布 然后在右边是一个真实结果的向量
为什么测试
现在我们没有显示所有成果
那是因为我们有很多观察结果
但你知道我们可以看到预测看起来相当不错
那个测试集的第一个客户要小心
那是测试集的所有客户
而那个第一个客户在现实中留在银行，并被预测确实留在银行
然而第二个客户实际上在现实中离开了银行
但被预测没有，预测到留在银行
然后第三个客户在现实中留在银行，并被预测留在银行
然后对于测试集的最后三个客户，嗯
他们在现实中留在银行，并被预测留在银行
所以结果看起来真的很好
但真正的检查方法是使用我们的混淆矩阵
因此，在这里在我们的逻辑回归工具中
你知道代码模板很好
我们只需往下滚动一点，找到混淆矩阵的代码
以及准确性的计算
让我们得到这个
让我们将其粘贴到新代码中
Sa 让我们粘贴
现在准备好获取你的第一个人工神经网络的最终准确性，对吗
在测试集上，意味着在新客户上，模型没有训练
嗯
让我们检查一下 让我们运行那个单元格，很好
我们得到一个超过86%的准确性
这真的很好，因为它意味着一百个客户中
86个被正确预测为留在或离开银行
我们可以在这里实际上看到这些预测的详细信息 我们有1520个正确的预测，即客户留在银行
然后我们有203个正确的预测，即客户离开银行
然后我们有75个错误的预测，即客户离开银行
和202个错误的预测，即客户留在银行
不管怎样，看起来还不错
86%的准确性是一个很不错的准确性
当然我挑战你至少提高1到2个百分点的准确性
但我自己实验过
我挑战你至少提高1到2个百分点的准确性
但我自己实验过
我挑战你至少提高1到2个百分点的准确性
但我自己实验过
这将很难被打破
所以不要浪费太多时间
我更鼓励你
你知道 查看我们提供的免费课程，关于回归的人工神经网络
因为我希望你能够利用人工神经网络做任何你想要做的事情
无论是二分类还是非二分类，无论是分类还是回归
通过这门课程
再加上另一门免费课程，你将知道如何利用人工神经网络做任何事情
所以这是我的推荐
现在当然，我想说最后的祝贺
你完成了机器学习的预高级分支
所以你可以为你的进步感到骄傲
如果你还没有被压垮，那么
是时候达到卷积神经网络的更高水平了
只要你觉得准备好了
我们将在kira和我在下一节中迎接卷积神经网络 在那之前，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p08 15. Step 1 - How to Preprocess Data for Artificial Neural Networks in R.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p08 15. Step 1 - How to Preprocess Data for Artificial Neural Networks in R

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这个艺术教程
我非常兴奋能进入深度学习的部分
这是机器学习的一个最迷人和最令人兴奋的分支
而且，它是在接下来的教程中最强大的之一
我们将解决凯勒在本节开始时描述的商业问题
你会看到我们将得到强大的结果
多亏了我们即将构建的这个人工神经网络
所以，像往常一样 我们将以非常高效的方式构建这个人工神经网络模型
我们将使用最佳的包来实现这一点
我会让你在下一个教程中找出这个包的
所以，让我们开始，我们的旅程的第一步是枯燥的数据预处理
但我们会非常高效地完成，因为我们有我们的模板
我已经在这里准备好了这个分类模板
为什么我们可以使用这个分类模板呢
那是因为商业问题的性质，正如你在商业问题描述中所看到的
你有一些自变量
并且，你有这些自变量，你需要预测一个因变量，它有一个二元结果
由于因变量的结果是二元的
这意味着它是一个类别变量
这意味着我们需要预测类别0和1
因此，我们的问题成为了一个分类问题
因此，我们将构建一个深度学习模型
但这个深度学习模型只不过是一个分类模型
这就是为什么我们将使用我们这里的分类模板 这将节省我们大量时间来构建我们的人工神经网络
并且，我们还想专注于深度学习模型本身
因此，我们将非常快速地到达那里
感谢这个模板
所以，让我们从这个模板的顶部到这里取走一切
因为我们不能使用这里的部分
因为你知道
这部分是用于可视化训练集结果和测试集结果的
但只有在你有两个自变量时
因为单个自变量对应于一个维度 而现在，商业问题的数据集中，我们有大约10或11个自变量
那么，在11个维度上表示某物就有些困难了
因此，我们不会使用这部分
但我们肯定会使用上面的所有内容
所以我要复制这个
让我们回到我们的ann模型，并将这个分类模板粘贴到这里 好的
现在我们将更改这个模板中的几件事
当然，我们将在这里构建我们的人工神经网络
在这里创建你的分类器
好的
我们将更改这个模板中的几件事
当然，我们将在这里构建我们的人工神经网络
在这里创建你的分类器
我们已经可以替换分类器在这里，然后用n构建模型，好的
当然，我们需要确保所有数据预处理步骤都是正确的
这就是我们现在要做的，好的
让我们开始 让我们从基本步骤开始
设置正确的文件夹作为工作目录
我现在在我的桌面上
我去到我的机器学习文件夹
然后我们在部分八深度学习和现在部分四十人工神经网络这里
确保你有流失建模点csv文件
如果是这样的话
你可以点击这里的更多按钮，然后设置为工作目录，好的
现在让我们改变几件事
首先，让我们开始这个部分
导入数据集
数据集的名称不是
社交网络添加
现在是流失建模，好的
我们现在准备好导入数据集
让我们现在来做
我将选择这条线并执行所有，好的
数据集导入得很好
实际上我们有14个变量
但让我们看看是否包括所有这些变量在实际数据集中
你知道我们想要构建我们的深度学习模型的那一个
让我们看看 我将点击这个数据集以查看哪些独立变量包括在模型中，好的
所以这只是一个快速的提醒
这个数据集包含一万个观察值
包含银行进行的一些客户信息
如姓氏
信用分数
地理 性别，年龄和其他信息在这里，并在六个月期间
银行查看了每个客户
如果客户在六个月期间留在了银行或者离开了银行
并且这个结果
是否客户留在了银行或者离开了银行在这里给出了这个最后一列退出 一意味着客户在六个月期间离开了银行
零意味着客户在六个月期间留在了银行
所以重要的是现在要理解的是所有这些变量在这里
从行号到估计的薪水是独立变量
并且这里最后一列退出是因变量
所以现在我们的目标是创建一个模型，我们可以从这个信息中预测这个结果退出这里
客户是否留在了银行或者离开了银行
所有这些独立变量这里
但是在这些独立变量中，肯定有一些对退出这个因变量没有影响
所以现在我们必须做的是只取那些可能有影响和相关性的独立变量
所以 我们现在要做的就是只取那些可能有影响和相关性的独立变量
客户决定留在银行还是离开
这就是我们现在要做的
让我们逐一查看这些独立变量
看看哪一个我们会保留在我们的模型中
好的 让我们从行号开始
行号对依赖变量exited肯定没有影响
当然我们不会包括它
然后客户ID
客户ID也是一样
那只是一个识别号码
这 当然不会对客户留在银行还是离开的决定产生影响
所以我们也不会包括它
然后姓氏
那也是一样的
不是因为你的名字是安德鲁斯 你就比名字是罗密欧的客户更有可能离开银行
好的
所以我们也不会包括姓氏 然后我们有信用分数
可能会对客户留在银行还是离开的决定产生影响
确实 我们可以假设信用分数低的客户更有可能离开银行
比信用分数高的客户更有可能离开银行
所以，我们肯定会将我们的模型包括信用分数
好的 然后我们有地理
嗯 也许某些客户在某个国家更有可能离开银行
这可能是由于国家的经济或其他外部因素
但是 确实
可能会有国家与留在银行还是离开的决定之间的相关性
所以我们也会包括这一点
然后性别 那也是一样的
也许男人或女人有可能比另一方更有可能留在银行
所以我们需要检查一下
然后年龄
那也是一样的 这甚至相当直观
我们可能会期望年轻人更有可能离开银行
因为老年人有更多平衡和稳定性
所以我们也会包括年龄
然后任期 任期是客户在银行停留的时间
那也是一样的
我们可能会期望长期客户更有可能留在银行
更有可能留在银行而不是新客户
所以是的
那么我们就保持良好的平衡
当然 我们可能会期望这个高余额的客户
比这个零余额的客户有更多的机会留在银行
好的 然后是产品的数量
那是客户在银行拥有的银行产品的数量
当然 也许银行产品多的客户比产品少的客户更有可能留下来
例如 银行里只有一个产品的客户
所以我们需要检查一下
这只是假设
我们需要更详细地找出这些相关性
但你知道 肯定从我们的直觉来看
我们需要包括产品的数量
然后网格卡会做得很好
这跟这个变量差不多
有信用卡的客户可能更有可能留在银行
而没有信用卡的客户
所以是的，活跃会员
如果客户是活跃的
那么这个客户比不活跃的客户更有可能留在银行
所以是的 这可能是一个重要的独立变量
那么估计的薪水很好
这是银行估计的客户薪水
而且，客户估计收入高的人离开银行的可能性比收入低的人高，这是有道理的
所以，估计收入高的客户比估计收入低的客户更有可能离开银行，这是合理的
好的 这就是这个数据集的最后一个独立变量
现在我们知道我们要在数据集中包括哪些独立变量
这就是我们现在要指定的
通过更新我们的数据集
只取我们要在模型中包括的独立变量的索引
让我们看看这些索引是什么
我们的索引从1开始
所以我们正在将所有独立变量从信用分数到估计的工资
让我们看看索引一
索引二 索引三
索引四 我们正在取索引四
五 六 七
八 九 十一
十二和十三
好的 所以我们正在从四到十四的索引中取值
因为你知道在R中，这不像Python
当我们将特征矩阵和依赖变量向量分开时
我们将所有变量包含在一个数据框中
所以我们包括依赖变量great
所以我们输入这些索引
我们刚刚说，我们要从四开始取索引
这是独立变量的第一个索引，到十四，那是依赖变量的索引
这很好
现在我们可以更新我们的数据集，选择这条线并执行great
现在，正如你所见，如果我回到数据集这里
我们有所有可能对依赖变量有影响的独立变量
统计上显著，已经提取出来
所以现在，数据预处理的第一步已经完成
我们正确地导入了数据集，选择了所有相关的独立变量
好的
现在我们进入第二步 第二步是将目标特征编码为因子
我们不需要这样做
因为我们的数据集的依赖变量是一个分类变量，二元结果
一或零
我们需要理解的是，我们将要使用的包会识别它
作为一个分类变量，二元结果
所以我们实际上不需要将目标特征编码为向量
所以我要删除这条线
我们不需要它
然而，我们需要对一些分类变量做一些事情 当然，我说的是我们数据集中的两个分类独立变量
这两个变量当然是地理和性别
所以我们有两个问题
所以我们需要对这些变量做两件事
首先，我们需要将它们转换为向量
然后我们需要做一些比编码我们的分类变量更多的事情
是将它们设置为数值
我们将使用as.numeric函数来做到这一点
我们为什么要这样做，尤其是这里
那是因为我们将要使用的深度学习包需要它
这就是原因，它期望因素
但设置为数值数值因素
所以我们这样做
我回到ann模型
首先，我们将更改此行
所以我们将更改此行
现在，我们将更改此行
所以，我们将更改此行
为了说我们正在将分类变量编码为向量
好的 现在我们将处理这些分类数据
我们在第一部分数据预处理中创建的文件
因为你知道我们有准备好的编码任何分类数据的代码
所以我将选择所有并粘贴到这里
在数据预处理的第二步，将分类变量编码为向量
好的 让我们这样做
我们需要替换变量的名称
然后添加这个作为点数值函数
将因素设置为数值
让我们从替换所有名称开始这里
嗯 第一个分类变量给出了国家
但它不叫国家
它叫做地理
所以我们在这里替换
国家由地理替换
这里也一样和
好消息是现在我们不需要更改这里的类别名称
法国 西班牙和德国
因为那是相同的名称
那太好了
我们将保留标签123
很好 现在我们添加这个作为点数值函数来将因素设置为数值
我将所有这些因素函数放在这里的作为数值函数的圆括号中
现在我只需要对齐所有事情
这里搞定了，同样在这里
好的，太好了，现在我们对第二个分类变量做同样的事情
所以我们需要替换购买的这里为性别
所以我们这样做，购买了替换为性别
好的，同样这里性别，现在我们替换两个类别
不是和是的为女性和这里我们可以给出我们想要的标签
所以
让我们例如给女性标签1，男性标签2 好的，别忘了添加作为点数值函数
我提醒我们只是为即将使用的深度学习包做这件事
我在这里放圆括号，这里是这里，现在我们对齐所有事情
搞定了，太好了
所以现在所有事情都准备好了
这部分准备好了
现在所有事情都准备好了
这部分准备好了，编码了深度学习包所需的分类自变量
我将选择这部分并执行
执行了，正确
现在 让我们看一下数据集，看看变量是如何变得完美的
地理信息编码在一中
二和三类别是数值类别
性别一为女，二为男
很好，再次作为数值因子完美
这个部分现在完成
让我们继续下一个
我们可以看到我们对此非常高效
下一个是关于将数据集分为训练集和测试集
我们需要这样做
因为我们将在训练集上训练我们的人工神经网络
并在测试集上测试其性能
所以我们会这样做 但我们不要执行得太快
我们需要将这里的purchased替换为依赖变量的名称
这是exit
也许我们可以更改it比率
你知道 将80%设置为训练集
这样我们有8000个观察值来训练我们的人工神经网络
并有2000个观察值来测试其在新观察值上的性能
那就是测试集中的新观察值
所以现在准备好了
这里我们不需要做更多的事情
最重要的是不要忘记将purchased替换为exited
现在我将选择所有这一部分并执行完美
现在我们有了我们的训练集和测试集，太好了
这就是整个数据集
这是我们的训练集，有8000个观察值
这是我们的测试集，有2000个观察值，完美，现在让我们回到我们的ann
我们终于来到了数据预处理的最后一步
那就是特征缩放
所以现在问题是
答案是肯定的
绝对是100%必要的
因此会有大量的计算
除了并行计算
所以肯定我们需要应用特征缩放
此外，这是包的要求
所以我们将执行这个
但在此之前，不要忘记更改索引
这里的索引3是依赖变量的索引，部分一数据预处理
所以现在我们需要将这里的索引3替换为我们的新依赖变量的索引
那么这个索引是什么
那就是exited列的索引
我们可以直接看到这一点，这个数据集有11个变量
这意味着这里的exited列有索引11
所以将这里的3替换为11
然后这里也是一样
十一点十一点和十一点很好
现在特征缩放部分已经准备好
所以让我们选择整个部分并执行
现在如果我们看一下我们的训练集，嗯
是的 当然一切都被缩放，我们的测试集也一样
一切都肯定被缩放
我们很高兴 我们准备好构建我们的人工神经网络
这就是我们在下一个教程中要做的
所以我非常兴奋开始 我期待见到你们在那里，直到那时享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p09 16. Step 2 - How to Install and Initialize H2O for Efficient Deep Learning in R.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p09 16. Step 2 - How to Install and Initialize H2O for Efficient Deep Learning in R

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这个艺术教程
所以我们有一个非常令人兴奋的教程在前面
因为在这个教程中，我们将构建ANN并将其拟合到训练集
所以现在是行动的时候
让我们构建我们的第一个人工神经网络
正如我所告诉你的 在前一个教程中，我们将使用最适合的那个包
那是最有效的一个，提供了最多的选项
还有一个包，可以非常高效地运行你的模式
这确实非常重要
因为我们要构建的模型很复杂
而且你知道它们可能需要多次迭代
所以我们需要一个高效的包来处理这些计算密集型任务
这些任务是不可避免的
当我们构建深度学习模型时
在这一节中，我们不会构建一个非常复杂的深度学习模型
我们将确实有两个隐藏层
但如果你需要处理更深的人工神经网络
当然，如果你有最好的包，那更好
所以R中有几个深度学习包
我们有神经网络来构建深度学习模型
它们是回归模型而不是分类模型
所以我们不能用这个
然后我们有一个网络可以构建深度学习分类模型
但只有一个隐藏层
然后我们有深度网络
另一个非常好的深度学习包，可以构建多个隐藏层的深度学习模型
但这还不是我们要使用的
所以现在我要告诉你
我们将要使用的那个叫做h two o包
为什么我认为它是构建深度学习模型最好的包呢
有三个原因
第一个原因
也是最重要的原因
h two o是一个开源软件平台
允许你连接到一个计算机系统的实例
因此允许你非常高效地运行你的模式
由于与这个计算机系统的连接
我们将能够非常高效地训练一个深度学习模型
对于那些跟随Python教程的人来说，就像几秒钟后
就像连接到GPU一样
你知道，这允许你运行高度计算密集的并行计算
所以这是效率的第一个原因
现在第二个原因是这个包提供了很多选项来构建你的深度学习模型
所以你知道选择不同数量的隐藏层会很容易
以及选择隐藏层中不同数量的神经元
以及开发你模型的其他选项，说到选项，这引导我进入第三个原因
对我来说，为什么深度学习包是最好的
嗯 第三个原因是这个h two o包的一个选项是
它包含一个参数调整的论据
这允许你选择一些最佳数字来构建你的神经网络模型
所以我们将通过构建模型来看到这一点
所以让我们开始创建它
所以我们首先要做的就是
当然要安装h two o包
让我们这样做
我们将使用install dot packages命令
命令在这里我们开始，记住在这个install中packages函数
我们需要在引号中输入包名，即h two o
这就是简单的h two o写法
只需选择这条命令并执行以安装包
我已经在我的our studio中安装了它
它已经导入了
当然，这个包会无问题安装
当然，如果你有任何问题
你可以在问答环节问我问题
我会帮助你解决
我将在评论中提到
现在我们继续下一行
这是导入这个包的意思
如果我们需要自动化脚本
所以我们像往常一样导入它
我们使用library并在括号内，而不是引号中
包名称为h two o，很好
现在我们需要做一些特别的事情
这不是我们整个课程中一直在使用的普通包
这是一个全新的包
因为它是一个我们从开源平台获取的包
因此需要连接到h2o实例
因此在我们开始创建模型之前，我们需要建立这种连接
别担心
这很简单 我们需要获取我们的h2o包，然后点
然后 如您在这里看到的
它包含许多函数，而我们感兴趣的函数是建立这种连接
实际上初始化一个h2o实例
我们需要获取init函数，好的
正如你在这个函数中看到的
我们有几个参数，允许你连接到特定的服务器
例如，这里第一个参数是IP地址
你可以用它来指定你想要连接到的服务器的IP地址
在你H2实例运行的服务器上
但如果你已经知道你想要连接到的服务器，
但在我们的情况下，我们将连接到某种默认可用的服务器
因此，我们希望使用这里的这些参数
然而，我们将使用一个参数
那就是这里的end threads参数
那么这个论点是什么
嗯 这个论点是您连接到的系统中的核心数量
这将用于构建深度学习模型
因为你知道构建深度学习模型需要大量的计算
高度计算密集型的计算
因此我们需要许多的核心来运行这些计算
再次，这就是我们为什么偏好GPU或CPU的原因
因为简单地说，GPU拥有更多的核心
我们将在这里取这个论点和线程
现在关键是输入-1的值
因为指定这个-1的值
将使用您连接到的系统中所有可用的核心
甚至都不用思考
我强烈建议在这里使用-1
因为这将优化使用的核心数量
因此未来的计算将非常出色
实际上这就是在这里初始化函数中我们需要输入的唯一论点
所以我们已经准备好执行它来连接系统
让我们执行h2o-jvm和连接
我们开始
所有连接都已建立
现在我们正在处理另一个系统
更强大
因为我们优化了核心的数量
因此我们准备好构建任何复杂的深度学习模型
所以现在我们有我们需要的一切
我们有一个强大的工具
所以我们肯定准备好开始构建深度学习模型
这就是我们将要做的 从下一课开始，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p10 17. Step 3 Building Deep Learning Model - H2O Neural Network Layer Config.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p10 17. Step 3 Building Deep Learning Model - H2O Neural Network Layer Config

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这个艺术教程
我们刚刚连接到我们的h two o实例
现在事情会变得容易
这也是为什么这个h two o包伟大的原因之一
因为几行代码
我们将能够构建一个复杂的深度学习模型
这将非常简单
我们将只使用一个函数
然后输入不同参数
我将首先定义我的分类器，我叫它classifier
然后等于 然后这就是我们使用h two o函数的地方
所以，为了取这个函数
我们需要首先取h two o包
然后我们将要使用的函数是这里的一个函数
你们会喜欢这个函数的名称的
因为它被称为深度学习
所以点这里，然后d d，这里是深度学习
这就是我们用来构建我们的深度学习模型的函数
按回车
现在我们开始
我们需要输入不同的参数
我现在要做的是
在这里按f1
以便更好地查看h2o深度学习函数的所有参数
让我们看看，在这里滚动来找到参数
现在我们开始
第一个参数是x，一个包含模型中预测变量名称的向量
这不是一个必填参数
我们不需要输入它
所以我们继续下一个
所以下一个是为什么模型中的回归变量名称
所以我们必须使用这个
因为实际上下一个参数是训练框架
而这个训练框架参数基本上就是训练集
这意味着对于训练框架参数
我们将在这里输入我们的训练集
由于训练集包含自变量和因变量
我们需要在这里指定这个y参数
在这个训练框架中，什么是因变量
这是我们的训练集
有了这两条信息，训练框架和y，模型就会理解
什么是训练集
什么是自变量，什么是因变量
那么我们首先输入这两个参数
首先 y等于
正如你所见
它只是询问响应变量的名称
这就是因变量
所以我们只需要在引号中输入
因变量的名称
这是正确的
第一个参数完成，逗号
然后继续第二个参数
第二个参数是训练下划线框架
这就是我们的训练集
因此我们在这里输入训练集，好的
但现在要小心
因为正如训练框架论中所说的信息在这里
这是一个h2o框架对象
而现在我们的训练集不是一个h2o框架对象
它只是一个数据框训练集
但这不是一个h2o框架
因此我们需要将这个数据框训练集转换为h2o框架
要做到这一点 有一个非常简单的方法
那就是使用as.h2o函数
这是一个将输入转换为h2o框架的函数
训练集，目前是一个数据框转换为h two o框
因此，这个训练框参数接收到它期望的第二个参数
继续第三个参数
所以第三个参数现在是什么
好吧，我们有其他参数，如模型ID
但我们不会使用它
用最佳模型覆盖
那是其他选项
但现在我们不要关注那个
那不是最重要的
然后验证帧也是一样的
检查点 气味编码器
预训练的自动编码器
所以这不是最重要的
但接下来最重要的是
我们进入激活
当然对应于你想要为你的网络使用的激活函数
所以这个参数非常重要
因为你在ki的直觉教程中看到一些激活函数比其他激活函数更好
实际上 正如Kiel解释的
就是这里显示的这个函数
这就是我们现在用于人工神经网络的函数
好的 所以让我们输入激活等于
然后引号归化
确保类型是大写的R，所以完美
这是我们在人工神经网络中选择的最佳激活函数之一
好的，很好 然后，逗号，接着第四个参数
所以第四个参数实际上是隐藏层下面的那一个
那就是隐藏层大小
那就是 这是一个双参数
因为指定这个参数可以让你同时指定你网络的两个参数
同时
第一个参数是隐藏层的数量
第二个参数是每个隐藏层中的节点数
那么我们如何将这些两个参数输入到这个只有一个的参数中呢
我们在做这的时候使用向量
向量的元素数量就是隐藏层的数量
向量中的每个元素的值就是隐藏层中的节点数
例如这里我们有c
你知道c是定义向量在r中的方式
然后向量的第一个元素是100，然后是向量的第二个元素100
这意味着我们有一个两个元素的向量
因此我们将有两个隐藏层
在第一个隐藏层中我们将有100个神经元
在第二个隐藏层中我们将有100个神经元
现在是时候问自己一个大问题了
这是一个在构建深度学习模型时经常出现的问题
我们想要选择多少层
也就是说这个向量中的元素数量
然后我们在每个层中想要放多少个神经元
不幸的是
坏消息是没有选择最佳隐藏层的数量
和这些最佳隐藏层中神经元数量的规则
但是有一个提示我们可以使用
这个提示并不是基于研究
而是基于实验
我们观察到一个方便的选择隐藏节点数量
不是最佳选择
而是更多 一个方便的选择是输入节点数量和输出节点数量的平均值
正如你在ki的直觉教程中所看到的
输入层的节点数是独立变量的数量
所以输入层中的节点数是10
因为我们有10个独立变量
输出层中的节点数是1
因为正如你在ki的直觉教程中所看到的
当我们的因变量有一个二进制结果时 输出层中只有一个输出节点
那就是当我们的因变量有一个二进制结果时
输出层中只有一个输出节点
这意味着我们在隐藏层中选择的节点数将是10
加上1除以2
那就是5.5
当然我们需要一个整数
所以我们在隐藏层中会使用6个神经元
现在说实话
我们不是在处理复杂的数据集
例如
比如从像素中寻找图像的模式
这里 我们有一个简单的数据集，包含一些自变量和一个因变量
这个数据集中没有空间结构
就像图像那样
说实话 我们不需要很多隐藏层
实际上我很确定我们的神经网络模型只需要一个隐藏层就能很好地工作
但是嘿 既然我们已经到了深度学习的部分
让我们使用两个隐藏层
这不会是深度学习模型的那种深度
但这将是一个好的开始
所以让我们将这些层输入到内部的神经元中
所以我要在这里添加一个隐藏的参数，就这样
所以你已经明白了
我们需要指定这些层的数量
以及这些层中神经元的数量，用一个向量
所以c括号
然后，这个向量的第一个元素是第一个隐藏层的神经元数量
我们说了6
然后，逗号 然后，这个向量的第二个元素是第二个隐藏层的神经元数量
让我们也选择6
记住，在第十部分，我们将能够通过k折交叉验证等参数调整技术来改进这些参数的选择
感谢k折交叉验证
但是现在让我们专注于深度学习
好的 这就是关于隐藏参数的所有内容
现在我们继续下一个参数
下一个参数是隐藏下面的一个，即epoch
那就是 当然，随机梯度下降算法中的epoch数量
我们这里有一个很好的描述
epoch的数量表示数据集应该被迭代多少次
如果我们回到关于随机梯度下降算法的直觉幻灯片
好吧，我们可以在这里看到第七步的epochs数量
当整个训练集完成时
从一到六的所有步骤通过一个ann，那么这就构成了一个epochs
然后我们会重复进行更多的epochs
所以这里的epochs数量，就是指我们重复了整个训练集的步骤一到六的次数
我们重复了整个过程的所有步骤，包括一到六，直到训练集完成
要么是在每次观察后更新权重
要么是在每次批次观察后更新权重
例如 十次观察
那么我们在这里添加一个epochs参数，这就去
就像在Python中，我们将输入100个时期，太好了
现在我们有一个最后的参数要输入
那就是实际上再次在下面
训练样本每次迭代
那么那是什么你可能已经猜到了它是什么，嗯
首先 描述说这是训练样本的数量每map减少迭代
但更简单地说，那就是你的批处理大小
这就是你想要更新权重的观察次数
所以这个数字可以是1
如果你想在每次观察通过ann后更新权重
那么在这种情况下被称为强化学习
正如我们在第六部分看到的那样，强化学习
或者这个数字可以是大于1
那就是 例如 当权重在每批10次观察通过ann后更新
那么在这种情况下被称为批量学习
好的 那么我们输入这个迭代的符号
这里按回车
现在好消息是我们甚至不需要选择批量大小
因为你可以看到我们有这三个参数
零到一和负二
正如你所见
这个负二值非常有用
因为通过在这里指定负二
这将自动调整你的人工神经网络
这与第三个原因相对应
为什么h2对我来说是最好的
这是因为一个最好的包
因为它给你一个选项，已经应用了一些参数调整
参数调整可能更加复杂
但我们有一个伟大的工具，可以帮助我们提高模型
所以让我们肯定输入-2
实际上现在人工神经网络已经准备好了
这是我们建立人工神经网络所需的所有参数
甚至我们有一些参数调整
所以我们有我们需要的一切，甚至更多
因此让我们开始
我将选择这些行
这将创建分类器
现在我只想对那些中的你们说一些重要的事情
那些跟随Python教程的人
你们看到训练
ANN花了相当长的时间
大约花了一分钟
如果我没有记错的话
那是因为我们在使用我们系统的cpu
但现在我们是连接到一个服务器上
因此我们可以使用h2实例访问一个强大的系统
因此你会看到模型将更快地训练
我们现在将看到，我将执行它
准备 321开始
就是这样，已经准备好了
这大约花了五秒钟
所以与如此强大的工具合作令人兴奋
我很高兴能向你展示这个
我希望现在你相信，有了这个h2o包
你处于良好的状态
太好了 现在我们的模型已经训练好了
是时候进行下一步了
在测试集上进行预测
这将非常有趣，我们可以看到在新的观察中，模型的准确性
模型没有训练过的观察
所以我们将在下一节课中看到 And until then enjoy machine learning
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p11 18. Step 4 - H2O Deep Learning Making Predictions and Evaluating Model Accuracy.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p11 18. Step 4 - H2O Deep Learning Making Predictions and Evaluating Model Accuracy

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这个艺术教程
我们刚刚在我们的训练集上训练了我们的人工神经网络
现在是时候在测试集上做预测了
幸运的是
我们已经在这里准备好了一切
多亏了我们在第一个教程中粘贴的分类模板
实际上这个部分预测了测试集的结果
而这个部分制作了混淆矩阵
通过它可以获得测试集的准确率
这是对新观察的准确率，人工智能模型没有在这个集上训练过，所以首先
我们来处理这个部分
让我们看看为什么我们需要改变
首先，这第一条线获取预测概率
多亏了这个预测函数
但那是我们用于构建我们包的函数
但这里因为我们正在使用h2o包，那是有点特殊的
实际上，这里有一些我们需要改变的事情
但只有几件事，所以首先，我们对h2o包的所有函数使用
你注意到当我们使用函数时
我们首先导入h2o包
然后是一个点，然后函数的名称
在这里我们需要为预测函数做同样的事情
在这里我们需要添加水平2点预测
好的 这是我们需要改变的第一件事
然后让我们看看
让我们进入函数
第一个参数是分类器
让我们在这里按
F1获取有关h2o模型预测函数的一些信息
那么我们往下滚动看看论据
让我们看看它们是什么
正如我们所见，我们只有两个主要论据和一些附加论据
但我们不会关注那些
相反，我们将关注这里的两个主要论据
它们是对象和新数据
我们可以看到的第一件事是，没有类型论据
所以这里我们简单地删除这种类型
因为实际上我们不需要响应论据和输入
好的
现在我们剩下两个需要输入的参数
这就是对象
这是我们的分类器
这就是我们在训练集上构建的模型
我们刚刚在训练集上构建的模型
第二个参数是新数据
新数据参数期望的当然是我们需要做出预测的观测值
这就是我们的测试集
当然我们要移除的是我们的因变量列
这就是我们的测试集，需要移除的是我们的因变量列
多亏了这里的负三
但我们需要将这个三替换掉
因为这里的数字三对应着我们在第三部分分类中使用的数据集的因变量的索引
就是我们在第三部分分类中使用的数据集
在这里 当然，我们的因变量的索引不是3
而是11
记得我们在特征缩放部分已经将这里的索引三替换掉了
所以我们需要替换掉四个索引
这里的三个索引被替换成了11
所以我们在这里需要做同样的事情
我们将用11号索引替换这里的三号索引，好的
所以现在这是将测试集的观察值作为新数据
这意味着它将为测试集中的观察值预测因变量等于1的概率
并且它将为测试集中的每个客户预测
每个客户离开银行的概率
因此它将为测试集中的每个客户预测
因为我们有测试集中的客户的真实结果
是否离开或留在银行
那么我们将把我们的预测与这些真实结果进行比较
这些实际结果
这就是我们通过计算正确预测的数量来获取准确性的方法
除以测试集中的总观测数量，即2000
如果我们得到一个好的结果
那么我们可能会得到一个好且强大的模型
如果情况是这样的
我们将把它直接交给银行，并告诉银行
好的 现在你可以按概率对所有客户进行排名
银行中所有客户按照他们离开银行的概率
这对您每位客户都适用
您可以以良好的准确性进行预测
我们将能够精确地告诉他们这种准确性
您可以以良好的准确性进行预测
客户离开银行的概率
然后你可以添加
因此我可以给您所有客户的排名，按照他们离开银行的概率进行排名
从最高概率到最低概率
因此您可以进行一些客户细分并考虑
例如，前10%的客户离开银行的概率
在这个部分中
您可以更深入地分析导致客户离开银行的因素
通过使用一些数据挖掘技术，如
例如 进行卡方检验
或在您的自变量上应用统计摘要函数
以了解哪些自变量对因变量的影响最大
即哪个自变量最能解释客户为何离开银行的原因
您知道如何做
这正是我们在第二和第三部分所做的
当我们使用总结函数来获取p值和统计显著性水平
以查看哪些自变量在统计上最为显著
因此最好地解释了因变量，即为什么客户会离开
这就是在测试集上进行这些预测的目的
只是为了在新观察中获得准确性以验证模型
这样我们就可以将这个模型交给银行了
所以现在让我们来做预测
我们几乎完成了
我们只需要添加一件事
这与我们使用h two o包有关
正如你在这个新的数据参数中看到的
嗯 这个新数据是
当然，这个测试集
但这个测试集应该被期望是一个h two o框架
现在它是一个标准的数据框架
但我们的h two o c函数期望的是一个h two o框架
那么我们如何将这个测试集数据框架转换为h to a框架呢？
通过做我们之前做训练集数据框架转换时做的事情
将这个数据框架转换为h two o框架
这是在测试集上应用的
使用as dot h two o函数
所以我像这样将测试集放入函数中
现在我们开始
我认为一切都准备好了
我们准备好做出预测了
到目前为止，这是预测的概率，即类别等于1
这是客户离开银行的概率
所以让我们选择这个并获取预测的概率
现在我们开始
我们现在有了一个包含所有预测概率的概率向量
以环境的形式
这很好 但我们无法查看这些预测的概率
但我们需要将其转换回标准向量
但在我们做那之前
将其转换为向量
嗯 我们也需要应用这个命令
这将 你知道
将概率转换为以1或0的形式进行预测
这正是对因变量的预测
要做到这一点 我们使用这个
if else函数 我们基本上选择一个阈值
如果预测的概率高于阈值
那么我们预测1
如果预测的概率低于阈值
然后我们预测为零
所以这是一个自然的阈值
当我们以概率的形式获得预测时
知道它并不总是百分之五十或0.5
这就是情况 例如，在医学上
当我们必须预测一些敏感信息时
例如
预测肿瘤是否恶性
这更敏感
那么在这种情况下，我们最好对我们的预测有把握
因此，我们将选择一个更高的阈值
例如 80%
但我们在这里预测
如果客户离开银行
所以我们对50%的阈值满意
这没问题
顺便说一句，有一种更简单的方法将这些预测转换为零和一的形式
而不使用if else函数
这是通过删除这里的1和0，删除这个if else来实现的
通过使用prop red大于0.5的属性来实现
因为这将返回一个布尔值
这将在prop red大于0.5时为真，小于0.5时为假
当prop red小于0.5时为假
为什么这些布尔值以这种形式表示
真和假 会被接受到这个混淆矩阵中
这更简单
现在让我们把这个预测转换为布尔值
所以我要选择这条线并执行所有
所以现在我们有我们的白面包作为布尔值
但它仍然是一个h2对象
因为它最初是h2点predict函数的结果
所以它仍然是一个h2对象
因此现在我们必须将这个h2对象转换回向量
因为稳定的函数这里只会接受一个向量
一个标准的向量
当然我们不会接受这个h2o对象
所以让我们将这个h2对象转换回向量
这就是真实和简单的
实际上这与将数据框转换为h two框相同
但是，而不是使用h two
我们将使用向量
这里我们只需要输入white bread等于as. vector ( )
当然，white bread
让我们检查一下
我将选择这一行并执行
现在，正如你所看到的
white bread变成了包含2000个元素的整数向量
这就是我们一直工作的标准向量r
我们可以实际查看测试集的预测观察结果
在控制台中输入
为什么在这里预
这是对测试观察的所有预测
2000个预测
根据模型，这里是
第一个客户留在银行
第二个客户留在银行
第三个客户离开银行
第四个留下了
第五个留下了
等等 所以如果你想
你可以实际上比较这些预测与测试集最后一列的真实结果
这里这一列
例如 零零一
零零是前五个客户的真实结果
如果我们将此与预测进行比较
我们可以看到预测非常准确
因为这里我们也得到
零零一
零零零
所以前五个预测是正确的
这为我们的准确性提供了很好的证据
因为我们即将计算的准确性
因为我们看到这些最初的观察结果
我们只能看到这些正确的预测
所以我现在真的很期待看到准确性
所以我们现在来计算它，我们将从制作混淆矩阵开始
当然，在这里我们需要替换这个索引
这里的3变成11
因为这对应于因变量的索引
所以现在我们准备好制作这个混淆矩阵了
所以我要选择这条线并执行，好了，混淆矩阵创建了
所以现在我们看看
我在控制台输入cm并按回车
这是我们的混淆矩阵
我们可以看到很多正确的预测
这是好事 一千五百三十六名在银行住宿的客户的正确预测
和一百九十五名离开银行的客户的正确预测
然后我们有两百一十二
加上五七十名客户，无论是离开还是留在银行的错误预测
这看起来相当不错
现在让我们不再等待
让我们计算准确率
所以准确率是正确预测的总数
一百零五万三千六百
加上一百九十五除以测试集的总观测数
这就是实际预测的总数
总共两千
让我们检查一下
让我们看看我们是否能将这个模型提供给银行
让我们看看是否能拿到奖金
让我们查看一下三三的准确率
二一去
86.5%
这实际上一点也不坏
86.5%嗯
87%意味着在一百次观察中
87次预测应该是正确的
这相当不错
此外，我们还没有进行任何参数调整
你会看到通过使用一些技术进行参数调整
比如k折交叉验证
我们可以获得更高的准确率
别担心 我们将在部分十中进行
你可以实际上练习来提高这个准确率
请让我知道如果你得到一个很棒的
现在只剩下最后一件事
因为我们已经连接到这个h2实例
现在最好断开连接，要做这个
我们只需要应用一个最后的h2o函数
这是h2o点
关闭这里
它没有需要输入的参数
你需要选择这个
这会断开你与服务器的连接
让我们执行
你确定要关闭在这个地址运行的h2实例吗
然后你只需要在这里输入
大写的y 然后回车
现在我们已经断开连接
true意味着 是的
我们已经断开连接
所以恭喜你
你已经建立了你的第一个人工神经网络在R使用h2o包
我很高兴能和你一起构建这个第一个深度学习模型
我们已经接近这个部分的结束
下一部分是关于卷积神经网络的
这是另一种专门用于计算机视觉的机器学习分支
因为它会考虑数据中的空间结构
就像对于图像来说，像素的位置很重要
所以我们将在下一节看到 在那之前享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p12 1. Understanding CNN Layers Convolution, ReLU, Pooling, and Flattening Explained.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p12 1. Understanding CNN Layers Convolution, ReLU, Pooling, and Flattening Explained

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到卷积神经网络的部分
非常兴奋你能加入我们
今天我们将讨论攻击计划
我们将学习如何在本节中学习一切
有很多要学习
让我们看看如何接近这一切
我们在本节中学到的东西
首先 我们将讨论卷积网络实际上是什么，非常重要
为了理解你正在努力实现的最终目标
你真的开始朝着那个方向努力
所以我们来谈谈特征
我们会看几个简单的例子
我们将比较人类大脑与在图像识别方面的人工神经网络
这将是一个轻松愉快的教程，让我们开始这个整个部分的学习
然后我们会讨论第一步，直接进入主题
卷积操作
所以 这门课程的这一部分包含我们需要通过的几个步骤
以便构建卷积神经网络
这就是这些教程将被拆分的方式
所以这一个将是步骤一
卷积操作将学习特征检测器关于所有事情
我们将讨论这些也称为滤波器
我们将讨论特征图
并且你知道如何什么不同参数
它们意味着什么 并且看一下一些视觉示例
然后我们将讨论步骤一部分b的relu层或relu层
这是修正线性单元
我们将讨论为什么线性不好
以及如何在我们的网络中为图像识别获得更多的非线性
然后我们将讨论第二步池化
我们将理解
嗯 池化是如何工作的
我们将特别讨论最大池化
我们还将提到一些关于平均池化或其他池化方法的事情
或者你可以采取的其他方法来进行池化过程
此外，在这次讲座中，我们将有一个非常酷的例子
所以我们会有一个非常直观的交互工具，我们将会查看它
所以请确保在讲座结束时留下
因为这将大大提高你的学习过程
我们将在讲座结束时讨论的内容
步骤三：展平
在这里我们将
这将是一个快速教程
关于如何从您的池化层转换到您的展平层
然后我们将讨论全连接
所以这是一个非常全面的教程，将所有内容放在一起并放在一个视角
实际上在最后向你展示一切是如何运作的
以及这些最终神经元如何理解如何对图像进行分类
一个非常非常重要的教程
希望这将总结或整理一切为你
最后我们将有一个总结，总结我们所讨论的一切
并且作为一个额外的小功能
我包括了一个关于softmax和交叉熵的教程
所以你不必再参加这个教程
但我认为这是一个很好的补充
嗯知识的补充
因为这些是你在与卷积神经网络打交道时会遇到的术语
所以也许你可以立即学习
也许嗯 当你遇到这些术语时
你将总是知道你可以回到这个课程并参加这个教程以更好地理解
softmax和交叉熵是什么
并且像往常一样
在这些教程中
说到这里，我迫不及待地想看到你在第一个教程中的表现
这将是一个非常有趣和令人兴奋的部分 直到下次再见，享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p13 2. Introduction to CNNs Understanding Deep Learning for Computer Vision.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p13 2. Introduction to CNNs Understanding Deep Learning for Computer Vision

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎回来参加深度学习的课程，今天
我们将开始 卷积神经网络将会很令人兴奋
让我们直接进入主题
我们将从一个图像开始
当你看这张图片时，你看到了什么
你看到一个人正在看你
或者你看到一个人向右看
你可以看到你的大脑在挣扎
嗯 调整 如果你看图像的右边
只看图像的右边边框
你会看到一个人向右看
如果你看图像的左边边框
你会看到一个人正在看你
这仅仅证明了我们的大脑在看东西时寻找的特征
当我们看到事物时，大脑寻找的特征
取决于它看到的特征
取决于你处理的特征
你将事物分类成特定的方式
当你看图像的右侧时
你看到一个人向右看的某些特征
因为他们离你的关注中心更近
因此，你的大脑将其分类为一个向右看的人
当你看图像的左侧时
你看到一个向你看的人更多的特征
因此，你的大脑将其分类为这样
所以让我们看看另一个
这是一个非常著名的图像
你可能已经见过它
但你在这里看到了什么
所以有些人会说他们看到一个年轻女子穿着裙子，背对着你
有些人会说他们看到一个老妇人戴着围巾，低头看
我将指出这些特征
你会发现这非常明显
这是年轻女子背对着你的脸
她正在看着远方，她的外套
那是她的头发 那就是她头发上的那根羽毛
另一方面
这是那位老妇人的头，向下看
那是她的鼻子 那是她的嘴
那是她的下巴
那是她头上的围巾
她在向下看
所以你可以看到二合一
根据特征的不同
你的大脑捕捉到
它会将每个图像分类为这一边或那一边
这些错觉中最古老的一个
记录在印刷作品中
这个
这是鸭子还是兔子
这是鸭子吗 还是这是兔子
另一个例子
现在我将向你展示一张图像
只看一眼就能看到
什么情感
或者什么样的体验
视觉体验
你看到了什么
你觉得有点眩晕
但是有点有点有点炫目
就像你的大脑试图理解它是什么
它是什么样子的 它正在尝试
它在她的眼睛之间上下跳跃
这是一个经典的例子，当某些特征存在时
它可以是这样
它也可以是那样 但你的大脑无法决定
因为两者似乎都合理
嗯 是的
所以这些例子基本上向我们展示了大脑是如何工作的
它处理图像中的特定特征
或者在现实生活中你看到的任何东西
并将它们分类
你可能在快速回头看的时候遇到过这种情况
你看到某样东西，你认为它是
我不知道它是否像一个球
但结果是一只猫
或者你认为它是
一辆车 但事实证明这是一个阴影
像这样的东西，那是因为你没有足够的时间来处理这些特征
或者你没有足够的特征来将这些事物分类
对我来说，这就是
这很有趣，因为我们将要用神经网络做的事情
卷积神经网络非常相似
你会发现计算机处理图像的方式
将与我们处理图像的方式非常相似
所以理解并记住这些事情是非常有价值的
这就是我们这样做的方式 我将把这个女士从你的屏幕上移除
因为她可能现在已经让你感到恐慌了
所以这里有些不同的东西
这里有一个实验 在计算机上做的卷积神经网络的实验
所以我们现在正在慢慢移动
从人类到计算机
这个幻灯片来自杰弗里·辛顿的一次演讲
嗯 这就是你所拥有的
基本上它描述了一个他在做的实验
嗯 一些卷积神经网络
所以他这里展示了三张图片
我们将从左到右依次查看它们并看看您会如何分类它们
然后看看电脑是如何分类它们的
在左边 您认为
这可能您会说
猎豹并且您会正确
这就是电脑说的
马上
立刻 我们要学习如何读取这些图像
因为你如果想深入研究卷积神经网络
没有讽刺的意思
如果你想开始学习更多关于它们的知识并使用它们
你会看到很多这些
而且我实际上看到有人读它们读错了
所以这里在上面
猎豹就是它的实际状态
这就是这张图片的实际正确标签，这就是
嗯 图片的标签，无论任何处理
和嗯
计算机视觉 嗯
然后是这些猜测
前四或五个
有时算法的猜测
他们被赋予了概率
所以电脑说
或者神经网络说
猎豹
雪豹或埃及猫可能是四种之一
并且猎豹得票最高
在整个课程的这一部分
你将理解这些投票意味着什么以及它们是如何得出的
但现在这相当直观，对吧
实际上它是一只猎豹
神经网络猜对了
它以超过95%的准确率
99%的准确率 判断它是猎豹
嗯 然后是第二个
你认为它是什么
那是一列子弹头列车
神经网络能够区分子弹头列车
乘客车厢
地铁列车 电力机车
如果这些是最佳选择
当然它还有很多其他选择
这些神经网络
能够学习区分
不仅仅是四个类别
而是同时区分几十个，甚至几千个类别
所以这是它选择的四个选项
这是子弹头列车
它是子弹头列车 那么最后一个你认为是什么
嗯 非常
有几种选择
不是很清楚它是什么
可能是一个煎锅
可能是一个放大镜
甚至可能是一把剪刀
有人可能会说
神经网络说它是剪刀
但你可以看到这里可能会出错
首先图像不是很清晰
而且你可以看到概率不是很明确
所以神经网络有点困惑
有点犹豫
就像我们一样 所以它说
剪刀是最有可能的
但然后是手镜
实际上它是
不是那么远
在第二位
煎锅，听诊器
所以基本上
这里你可以看到剪刀是第一个猜测
但正确答案是第二个
这就是为什么它被标为红色
那么我们完成了 那些是神经网络已经能够做到的事情
这是一张相当老的幻灯片
这是多年前的事情
现在他们甚至更好
你将会在与huddle一起编码的实际应用中看到这一点
但现在让我们试着更好地理解
卷积神经网络实际上是什么
以及它们为什么如此受欢迎
它们确实非常受欢迎
你可以在这里看到谷歌趋势的比较
我是昨天做的
你可以在这里看到
嗯 卷积神经网络甚至超过了人工神经网络
有一个巨大的增长
它们只会继续这样发展
因为这是一个非常重要的领域
那就是所有事情发生的地方
比如像自动驾驶汽车
它们如何识别
嗯
路上的人
如何识别停止标志之类的东西
如何啊
facebook如何 如何能够标记图像
或者在图像中标注人
不仅仅是像几年前那样你必须自己标记人
然后它会识别面孔
你必须在名字中添加名字
然后添加名字
现在它同时识别面孔并添加名字 嗯
这就是卷积神经网络能够做到的，说到facebook 嗯
如果jeffrey hinton是人工神经网络和深度学习的教父 那么jan lekun就是卷积神经网络的祖父
lekun是hinton的学生
事实上，你可以在这里看到他们一起
hinton现在在谷歌推动深度学习
lekun是facebook人工智能研究的主任，同时也是纽约大学的教授
所以，慢慢地，我喜欢这门课程的这一部分
慢慢地，我们正在构建这个人物
这些人物，或者
嗯
这种推动这个领域的人物的形象
然后啊 在接下来的几部分中，我们将了解一些更多的人物
然后啊
接下来
我们将拥有这个他们所自称的黑手党
或者Kun称之为黑手党或深度学习的阴谋
你将会了解更多关于这个整个领域是如何发展的
嗯 是的
这些人只是些伟大的人
所以年轻的Kun在八十年代和九十年代
对卷积神经网络领域做出了重大贡献
正如我们在这门课程中看到的
已经能够开发或帮助世界开发某种极其强大的东西
接下来我们讨论卷积神经网络是如何工作的
您的输入非常简单
非常直接 所以您有一个输入图像
它通过卷积神经网络
您有一个输出标签
所以它将该图像分类为某种东西，比如猎豹或子弹列车
或者其他什么东西，现在让我们深入探讨一下
嗯 细节
例如 你可以得到一个神经网络在模糊图像上训练后的结果
在确定的图像上
分类或分类的图像之前
然后您可以给它
例如 训练一个神经网络以识别面部表情
情绪 你可以给它一张脸
一个微笑的人脸
这不仅仅是一个像这幅画一样的人脸
这是一个真实的笑脸，它会告诉你这个人是快乐的
你可以给它一个皱眉的脸
它会告诉你这个人是悲伤的
你看 它能识别这些情绪
正如你所看到的，这在许多不同的应用中已经非常强大
仅仅这一个例子，你就可以立即想到
在两种情况下，它都会给你一个概率
所以不会显示 你知道
以百分之一百的人的
嗯 快乐或悲伤
它会是百分之九十九或百分之九十八
嗯 或者在不清楚发生了什么的时候，可能是百分之八十
就像我们现在一样
有时候我们会把一些事情误认为是它们不是
或者有时候我们可以
有时候它是 不清楚这个人是微笑还是皱眉
或者它是 嗯
它是狗还是猫
或者它是火车还是子弹头列车
有时候我们并没有
我们没有看到足够的特征
一切都归结于特征
因为这是我们处理视觉信息的方式
正如我们从这个教程的开始看到的
所以 但是神经网络是如何
神经网络是如何能够识别这些特征的
嗯 一切都从最基本的层面开始，你有
假设你有一张图片
你有两张图片 一张是两张两张像素的黑白图片
另一张是两张两张像素的彩色图片
嗯，神经网络利用的事实是
黑白图片是一种二维数组
所以我们现在看到的方式
在左边只是视觉表示
是的 所以它是某种图片
为了简化起见
它只是一个两张两张的图片
但在计算机术语中，它是一个二维数组
每个这些
每个像素都有一个从0到255的值
所以这是8位的信息
2的8次方是256
所以值是从0到255
这就是颜色的强度
在这情况下是白色
所以0会是一个完全黑色的像素
255会是一个完全白色的像素
在这之间你有灰度的可能的选项
基于这些信息
电脑能够处理图片
这就是任何图片的起点，实际上有一个数字的表示
有一个数字形式
这些只是基本的1和0
形成0到255的数字
这就是电脑处理的
它实际上并不处理
你知道的 颜色或者其他东西，最终处理的是1和0
那就是这一切的基础
嗯，在彩色图像中
实际上是一个三维数组
你有
嗯 蓝色像素
你有一个蓝色层 一个绿色层和一个红色层
并且它代表RGB红色，绿色，蓝色
并且每个颜色都有自己的强度
所以基本上一个像素有三个
嗯 三个值分配给它
每个值都在零和255之间
255
嗯 因此你可以
嗯，找出这个图像
这个像素确切的颜色，通过组合这三个值
并且计算机将处理这些
那就是这一切的基础
那就是红色通道 绿色通道
蓝色通道
最后让我们看一下
嗯 例如
一个例子 一个非常简单的例子，一个微笑的脸在嗯
在计算机术语中 如果我们真的简化事情，而不是从零到255
而不是那些值
只是为了我们能更好地理解事情，真正抓住概念，我们将说
零是嗯
是白色
一是黑色
对吧 所以我们将事情简化到极端
你会看到那个图像可以这样表示
所以 我们之所以提起这个，是因为
因为我们去我们所有直觉教程
我们将结构化像这样的图像
它们非常简单 但同时
嗯 然后所有那些概念可以翻译回0
到255的范围值
并且所有应用都是同样的方式
并且我们将要经过的步骤
这些图像是第一步卷积
第二步池化
第三步展平和第四步全连接
我可以想象，现在这些词对你们来说可能意义不大
但到课程这一节的末尾
你将对它们有深入的理解和它们正在做什么
我们将在下一课开始
你可能想要查看的额外阅读是lecun的原始论文
它引发了卷积神经网络的兴起
它的名字是基于梯度的学习应用于文档识别
你可能在互联网上看到过这张图片
它是来自那篇论文
如果你想回到所有发生的源头
它来自哪里
这就是你要查看的论文 我期待下次教程见到你，在此之前享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p14 3. Step 1 - Understanding Convolution in CNNs Feature Detection and Feature Maps.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p14 3. Step 1 - Understanding Convolution in CNNs Feature Detection and Feature Maps

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎回来学习深度学习课程
在上一课中
我们发现了卷积神经网络的所有内容
今天我们将深入第一步卷积
这就是卷积函数
我知道我们尽量避开数学，保持直观
但我忍不住分享这个公式视图
因为它如此简单
卷积基本上是两个函数的结合积分
它显示了一个函数如何修改另一个
或者修改另一个的形状
如果你做过任何信号处理或电气工程，或一个需要信号处理的职业
你一定不可避免地会遇到卷积函数
它现在非常流行
再次我们将保持数学轻或将它们分开
如果你想了解卷积神经网络背后的数学
一个很好的补充阅读是江新武的《卷积神经网络介绍》
他是中国南京大学的教授
这篇论文几天前发表
就像五天或六天前
它特别针对刚开始学习的人
谁正在熟悉卷积神经网络
那里的数学应该是可访问的
我实际上发邮件
呃
教授新武
他说他的目标是分解复杂的事情
以便新到这个领域的人能理解
而且他提到他在主页上有一些材料
如果你在URL
如果你只删除最后两部分
然后你就去像斜杠w jx那一部分
那是他的主页
你会找到更多额外的教程和材料
他没有作为论文发表
但他在教程中使用它们
所以你可能会发现这些有用
所以四处浏览
如果你想了解卷积神经网络背后的数学
并在那个领域建立一个坚实的基础
但我们将继续前进
然后我们将讨论卷积
那么卷积在直观意义上是什么
在这里左边我们有一个输入图像
正如我们所讨论的
这就是我们看待图像的方式
只是为了简化事情，就是一和零 你可以看到那里的笑脸
我们尽量简化事情
并且你可以看到那里的笑脸
然后我们有一个特征检测器
所以特征检测器是一个3x3的矩阵
它必须为3x3吗
不必 嗯
AlexNet 我认为使用了
7x7 嗯
然后一些其他的那些著名的人使用像五乘五的特征检测器
它们可以是不同的 但你通常会看到它们有三乘三
并且有知道原因使它们三乘三
所以我们将坚持传统的方式
有一个三乘三的特征检测器
嗯，特征检测器被称为
嗯 这些是重要的术语
因为你可能会遇到它们
它们有很多不同的特征检测术语
但最常见的是特征检测
或者你可能会听到它被称为核
或者你可能会听到它被称为滤波器
所以，在这门课程中，我们将使用滤波器或特征检测器交替使用
但请记住，它们有其他名字
卷积操作由一个圆圈中的叉表示
嗯 就像你在公式之前看到的那样
在直觉层面上发生了什么
所有的，还是仅仅想想这在背景中实际发生的是什么，而不是数学
而是背景中实际发生的
好吧，你把这个特征检测器
嗯或者滤波器
放在你的图像上
就像左边看到的那样
所以你覆盖了
例如 在这个例子中，左上角
左上角有九个像素
而且你基本上
每个值每个值
所以相应的值 所以顶部零
由顶部左值
然后基本上位置一号一号
一个位置一个零
一零一 零二零二
所以这只是这些矩阵的元素乘法
然后你把结果加起来
所以在这个案例中，什么都没有匹配上
所以总是总是要么零乘零
零乘一 所以结果是零
在这里你可以看到其中一个匹配上了
左边的那个匹配上了
因此我们这里有一个一
什么都没有匹配上
然后我们继续向下一行
所以移动的步骤
我们正在移动的步骤
这个整个滤波器被称为步幅
所以这里我们有一个像素的步幅 所以这里你又可以看到
某些东西匹配上了
步幅 但是底部中间的一个匹配上了
嗯，中间顶部的一个匹配上了
然后什么都没有匹配上 步幅是1
嗯 你可以改变步幅
嗯，你可以让它变成2
嗯 你可以让它变成3
你喜欢什么就是什么
通常使用的步幅是2
这就是人们通常使用的
我们将在最后讨论步幅
所以这里我们有
我们正在匹配 所以我们就放在这里
你可以看到 我们有一个2 因为两个匹配上了，等等
等等等等
就这样 又有一个匹配上了
就这样，我们做完了
我们创造了什么
一些重要的事情
右边的图像被称为特征图
它也有几个术语
它也被称为有时卷积特征
当你对一个东西应用卷积操作时，它不会变乱
它会变得卷积
是的
我用它 有时
我喜欢用错误的方式思考
但这是
这是正确的术语 它是卷积的
它是卷积特征
它也可以被称为激活图
但在这门课程中，我们将称其为特征图
所以它可以被称为任何这些
我们在这里做了什么，嗯
如你所见 我们减小了图像的大小
这是第1点 这是我想提到的关于输入图像和特征图的重要事情
嗯 以及步幅
是的 如果你有步幅1，你可以看到图像减小了一点
但如果你有步幅2，图像会减小更多
因此特征图会更小
这是特征检测器以及整个卷积步骤的一个重要功能，就是要减小图像的大小
因为这样处理图像会更容易
而且会更快
嗯
它会更快，而且会更容易处理
嗯，而且 你会更快
因为想象一下这里
我们有一个7x7的图像 但如果你有一张真正的照片，想象一下
嗯
或者你有一个256x256像素的图像
那就是一个非常大的像素数量
256
嗯，或者让我们说，你有一个300x300像素的图像 这样我们不会混淆RGB 256
让我们只说你有一个300x300的图像
以像素大小计算
那么你就有300的平方个像素 那是一个巨大的数字
300x300
像素
所以，我们有300x300的图像
像素数量为300x300
这是一个巨大的数字
因此特征检测器
会减少图像的大小
因此步长为2实际上有益
但问题是我们是否丢失信息
当我们应用特征检测器时
嗯 我们确实丢失了一些信息
当然因为我们的结果矩阵中有更少的值
但同时特征检测器的目的是检测某些特征
图像中某些关键部分
因此 例如
如果你这样想
就像特征检测器上有某种模式
在你特征图中的最高数字是当该模式匹配时
实际上，你可以得到的最高分数在我们简化的例子中是当特征完全匹配时
你可以看到数字四
在我们的特征图中正好是这样
如果你看这里
这正是这个特征检测的地方
因为它里面只有四个匹配得非常完美
所以你可以看到这个
这里这一部分
所以特征在这里被检测到
正如我们在这一节开始时讨论的
这就是特征我们看东西的方式
这是我们识别事物的方式
我们不看每一个单个的
嗯像素
换句话说
我们在图像上看到的
或者在现实生活中我们不会关注每一只猪
我们关注特征 我们关注鼻子
帽子 羽毛
嗯 眼睛下面的
或者猎豹眼睛下面的小黑点
为了区分狮子和老虎
或者火车的形状
我们不需区分子弹列车
普通列车等等
所以我们不关注所有细节
我们关注特征 这就是我们要保存的
这就是特征图帮助我们保存的
实际上这就是它
它允许我们突出
并且去除掉所有不必要的东西
即使是作为人类我们也不会处理的信息这么多信息进入你的眼睛
嗯 在任何给定的时间
像吉字节的信息
如果你看每个点
如果不是太字节的信息进入你的眼睛每秒
并且我们还是能够处理那个
因为我们去除掉什么不必要的
我们只关注重要的特征
特征对我们来说是重要的
这就是特征映射所做的
所以现在继续这是我们的输入图像
并且我们创建一个特征映射
所以最前面的一个
让我们说最前面的一个是我们刚刚创建的
但是然后为什么有这么多但是我们创建多个特征映射
嗯因为我们使用不同的滤波器对吧
并且那是我们保存很多信息的另一种方式
所以我们不只有一个特征映射
我们寻找特定的特征
并且嗯或者基本上网络通过它的训练决定
并且这是我们将在本节末尾讨论的
通过它的训练它决定哪些特征对于某些类型或某些类别是重要的
并且它寻找它们
并且因此你会有不同的滤波器和我们将讨论滤波器现在
但是基本上它应用这种滤波器所以来获取这个特征映射
它应用一个滤波器像我们看到的那样
但是然后获取这个特征映射来应用一个不同的滤波器获取这个特征映射
应用一个不同的滤波器然后等等
嗯并且基本上它只是创建这些特征映射
并且实际上那是我个人认为
我认为特征检测的术语比滤波器更好
所以记住在这里我们有这个滤波器
我们也可以称之为特征检测器
实际上特征检测器的术语我认为更适合
并且那是原因
我们想要检测特征对吧
我们不想要只是过滤我们的图像
但是尽管那是整个
那正是目的
但是基本上我们想要检测特征
在这个在这个层中我们将在在这个特征映射中
我们已经检测到在图像中某些特征的位置
在这个特征映射中我们已经检测到在图像中某些其他特征的位置
某个特定特征的位置
并且这个特征映射我们检测
某个其他特征在图像中的位置
所以那是
嗯 这就是我们在做的
让我们看几个例子
所以这里嗯
我们使用 这是嗯
来自gimp点
org在他们的文档中
这是一个免费的 嗯
一种像画一样的工具
你可以用它来调整图像或处理图像
但他们在他们的文档中有一些有价值的例子
这里有泰姬陵的图片
你可以选择你想要应用的滤镜
如果你下载了这个程序并将照片上传到其中
你可以开始卷积矩阵并应用滤镜
你会发现这些
这些卷积矩阵实际上在图像处理和设计中被应用
让我们看看结果
如果我们应用这个滤镜
中间是5 -1 -1 -1 -1
你可以看到它增强了图像
嗯
是的 所以这
这相当直观
如果你这样想 5是中间的像素
主要像素
然后-1 -1 -1
你知道的 它减少了周围的像素
在直观的意义上
然后模糊所以基本上它给所有像素平等的重视
给中心像素周围的所有像素平等的重视
因此它们结合在一起
你得到一个模糊
边缘手
在这里你可以看到-1和1
然后你得到零
所以你删除
移除中心像素周围的像素
只保留中间的-1 你得到一个边缘
这个更难理解它是如何工作的
嗯可能更难
只是直观地想
边缘检测对吧
正确 你取中间的那个
你减少中间的那个
嗯，可能在中间像素的强度上
然后你寻找那些
你寻找 嗯
这些 你增加周围像素的强度
所以你有那些像素在那里
嗯，是的
所以这给你带来边缘检测
你可以看到结果，再来一个
所以嗯
关键在于它是不对称的
你可以看到图像也变得不对称
所以你有那种
嗯
感觉它向你突出
这就是当你有负值在这里和正值在这里时得到的结果
这是非常 这现在开始有点技术性了
但至少我们可以获得一些直观的理解
让我们快速过一遍
这是锐化
这是模糊
这是边缘检测
这是浮雕
所以你可以看到
这些都是同一张图片的不同例子
我们得到特征图
我们用不同的特征检测器得到同一张图片的不同特征图
因此现在我们有了这张图片的很多版本
嗯，
在每个版本中我们试图检测某些东西
这些术语对我们来说不适用
如我所说 如浮雕
可能对我们来说并不适用，就像卷积神经网络
但边缘检测很重要
我们希望检测边缘
边缘检测可能不适用，模糊也不适用
锐化 所以像边缘文本这样的东西对我们来说可能最重要
在理解方面
就像电脑 它们会自己决定
它们的神经网络会自己决定
什么是重要的，什么是不重要的
而且它可能连人眼都无法识别
你将无法理解那些特征的含义
但电脑会做出决定
这就是神经网络的美丽之处
它们可以处理如此多的不同事物并理解
即使没有直觉
即使没有解释
为什么他们会理解哪些特征对他们重要
无论我们是否给它们命名
那就是全部
这对人工神经网络来说是一个无关紧要的问题
这是我最喜欢的
嗯 这是一张杰弗里·辛顿的照片
嗯 杰弗里·辛顿的照片通过一个这样的滤镜
好的 所以今天我们的教程就到此结束
我希望你们喜欢学习卷积
关键点是卷积
The primary purpose of a convolution is to find features in your image
It's using the feature detector
Put them into a feature map
And by having them in a feature map
It still preserves the spatial relationships between pixels
Which is very important for us to
You know Because if they're completely jumbled up
Then we've 嗯 我们失去了模式
同时重要的是要理解
大多数时候
神经网络会检测和使用的特征
对人类来说意味着什么
但它们仍然有效
这就是卷积
我期待着在下一个教程中见到你 直到那时享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p15 4. Step 1b - Applying ReLU to Convolutional Layers Breaking Up Image Linearity.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p15 4. Step 1b - Applying ReLU to Convolutional Layers Breaking Up Image Linearity

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎回来参加深度学习的课程，今天
我们要谈论的是relu
这是修正线性单元
这是在卷积步骤之上的一个附加步骤
它不是一个独立的大步骤
它是一个小步骤 它是步骤一b
基本上，在这里发生了什么
嗯 我们有我们的输入图像
我们有我们的卷积层
我们已经讨论过
然后在那上面我们将应用
等着瞧
我们的最喜欢的激活函数
你已经熟悉了额外的激活函数
来自前一节关于人工神经网络的内容
在我们的例子中，有时
作者或讲师将卷积和激活分开为两个独立的步骤
在我们的例子中
我们将它们视为第二卷积的一个单一大步骤来考虑
然后整流器
我们之所以应用整流器，是因为我们希望增加非线性。
在我们的图像或网络中线性性
在我们条件中
一个神经网络和激活函数（如ReLU）可以视为...
过滤或访问那个功能
打破了线性
我们想要增加非
在我们的网络中，线性是因为图像本身高度非线性
尤其是如果你能识别出不同的物体
嗯，相邻的物体
或者在背景中
就像图片会有很多非线性元素
像素之间的过渡
相邻的像素通常是非线性的
那就是 你知道的 因为有边界
有不同的颜色 这是不同的
这些不同元素在你的图像中
同时当我们应用数学运算，比如卷积时
嗯 你知道
运行特征检测来创建我们的特征图
我们可能会创建线性的东西
因此我们需要打破线性
让我们看一个例子
这是一张图像
一张原始图像
现在 当我们将特征检测算法应用于此图像时
我们得到类似这样的结果
你可以看到，黑色表示负值
白色表示正值 嗯
当你将
嗯 特征检测算法应用于
一张正常的图像
而不仅仅是零和一
而是有许多不同的值
然后
如我们之前看到的
特征点可以有负值
有时你会得到负值
在这里，黑色表示负值
白色表示正值 而线性整流单元
函数所做的是移除所有黑色
任何低于零的值变成零
因此，它将其转换为这样
因此，很难看出
在打破线性方面
对于 在打破线性方面有什么好处
嗯，我会尝试解释
我会尝试
展示一个例子
但这是一个非常数学的概念
我们需要深入研究数学才能真正解释发生了什么
让我们看看
嗯
例如 让我们看看这个
这个建筑物本身
嗯 你可以看到这片阴影
这片黑色
这片阴影
你可以看到它是白色的
光的反射
然后是灰色
然后变得更暗
好的，当我们移除
移除那片黑色
这样想想线性
对 当你从白色过渡到灰色
下一步将是黑色
对，下一步将是黑色
这是一个从亮到暗的线性进展
因此这有点像线性情况
当你去掉黑色 你打破了线性
让我们尝试另一个
让我们看看这里
同时它还是同一栋建筑
对 它不是像你
你是像
它不是像 你在融合两栋建筑
但那是次要的
重点是打破线性
所以让我们看看这里
同样的事情 所以你看到白色灰色黑色灰色白色
当你打破它
你再也不会有那种了
对 你没有那种进展
那种渐进进展
你只有有一个突然的变化
这有助于在你的图像中引入非线性
这是一个非常粗略的解释
非常像手指的解释而不是技术
但希望这能帮助你更好地理解我们在谈论什么
在这里你又可以看到白色灰色是一个更好的例子
甚至看到亮暗
更暗更暗更暗更暗更暗
所以这部分看起来像线性
然后你打破它像这样
嗯再次
所以这是一个非常粗略的解释并不完美
但至少它给你一些想法发生了什么
但如果你想了解更多
总是有一个好论文
总是有一篇论文
这篇是由加州大学ccj ko写的
它叫做理解卷积神经网络与一个数学模型
基本上他在回答两个问题
你需要只看第一个
问题是为什么 非线性激活函数在所有中间层的滤波器输出是必要的
这就是更详细的解释
从直觉上讲
主要是从数学上讲
这是一个有趣的论文
你可以在这里获得更多关于这个话题的信息
如果你真的想深入挖掘并探索一些有趣的东西
你可能对另一篇论文感兴趣
名为深入探索归一化
在图像网分类中超过人类水平性能
作者是kaiming以及其他来自微软研究的人
他们提出了一种不同的修正线性单元函数
他们提出了参数修正线性单元函数
如图所示
他们认为这能带来更好的结果，而不牺牲性能
非常有趣的阅读
如果你想更深入地了解这个话题
今天就到这里
真实数据层非常简单
只需简单地应用修正函数 我期待下次见到你，在此之前享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p16 5. Step 2 - Max Pooling in CNNs Enhancing Spatial Invariance for Image Recogniti.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p16 5. Step 2 - Max Pooling in CNNs Enhancing Spatial Invariance for Image Recogniti

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎回来参加深度学习的课程，今天我们要讨论的主题是max pooling
我们今天要讨论的主题是max pooling
我们即将迎来一些非常激动人心的幻灯片
甚至在教程的结尾有一个特别的惊喜
让我们开始吧
第一个问题是什么是池化
以及我们为什么需要它，为了回答这个问题
让我们看这些图片
在这三张图片上
我们有一只猎豹
实际上，第一张图里的猎豹和第二张图里的是同一只
图片位置正确，猎豹直视着你
第二张图
稍微有点旋转
第三张图稍微有点变形
问题是
我们希望神经网络能够识别出猎豹
在这所有的图片中
实际上这只是一只猎豹
如果我们有很多不同的猎豹怎么办
这里有一只猎豹
这里有另一只猎豹
这里有一只骗子
这里有一只猎豹
我们希望神经网络能够识别出所有这些猎豹都是猎豹
那么它们是如何做到的
如果他们都在不同的方向看
它们在图片的不同部分
他们就像他们的脸在图像的不同部位定位
有人出现在右边
有人出现在左上角 有人出现在中间
他们都有点不同
纹理有点不同
光线有点不同
有很多小的不同
所以如果神经网络寻找特定的特征
例如 猎豹的一个显著特征是它的泪痕
嗯 在它的脸上
从眼睛流出
或者看起来像泪痕的影子
纹理 从它的眼睛下方延伸的图案
它嗯 在它鼻子的大小上
看起来像泪痕 那是猎豹的一个显著特征
但如果它在寻找那个特征
它是从特定地点或特定形状、形式或纹理的猎豹中学到的
它将永远找不到这些其他骗子
所以我们必须确保我们的神经网络具有称为空间不变性的特性
这意味着它不关心特征在哪里
不是不在图像的哪一部分
因为我们已经在我们的映射中考虑到了这一点
与我们的卷积层
与我们的卷积层
但它不需要关心特征稍微倾斜
特征稍微不同在纹理
特征稍微更近
特征稍微更远
如果特征本身稍微扭曲
我们的神经网络必须有一定的灵活性
以便仍然能找到那个特征
这就是池化的全部内容
让我们看看池化是如何工作的
这是我们的特征图
我们已经完成了卷积
我们已经完成了那一部分
现在我们正在工作于卷积层
现在我们将应用池化
它是如何工作的 我们将应用最大池化
你可以应用一种或多种池化
平均池化 最大池化
一些池化 我们将在教程结束时讨论这些
但现在我们只应用最大池化
我们取一个2x2像素的框
像这样，不一定是2x2
你可以选择任何大小的框
我们将在教程结束时讨论这一点
你将其放在左上角
然后在框中找到最大值
然后你只记录那个值
然后你忽略其他三个
在你的框里有四个值
你只忽略三个
你只保留一个，最大值
在这个例子中是1
然后你将框向右移动一个步幅
你选择步幅
在这里我们选择了步幅2
这是你通常选择的
你也可以选择步幅1
你可以选择 所以有重叠的盒子
你可以选择任何你喜欢的步幅，甚至三步
但我们在这里选择了步幅为二，这是一个常见的做法
然后你重复这个过程
你记录这里的最大值
如果你跨过这里，没关系
你只是继续做你正在做的事情
你仍然记录这里的最大值
零，在这里
最大值是四
在这里，最大值是二
最大值是一 零一
零二然后一
所以你可以看到一些事情发生了
首先，我们仍然能够保留特征
最大值它们所代表的，因为知道卷积层的工作方式
我们知道，最大值或大数字在你的特征图中
它们代表你实际上找到的特征最相似之处
但通过池化这些特征
我们首先去掉了不是特征的75%的信息
即我们不关心的信息
嗯 我们只关注重要的事情
因为我们只关注四个像素中的三个
所以我们只保留两个五
并且因为我们取特征图中像素的最大值
我们因此考虑到任何扭曲
例如
两张图片 嗯
例如 一只猎豹的眼睛在图片里有泪痕
在另一张图片里，它们在左边
或者稍微向左旋转 而另一张图片它们应该在正确的位置
或者我们想要的位置
如果我们以第一张图片为基准
然后另一张图片稍微向左旋转
池化后的特征将完全相同
所以你可以看到这里
如果我们谈论猎豹的泪痕
让我们说这是四 然后在这里
如果它稍微向左旋转
例如
四在这里
所以，例如 四在这里
然后我们在进行池化时
我们仍然会得到相同的池化特征图
这就是它的基本原理
这有一个非常粗略的解释
直观的解释 这就是池化的目的
我们仍然能够保留特征
并且 此外 考虑到它们可能的空间或纹理或其他类型的扭曲
除此之外，我们还减少了大小
所以这又是另一个好处
所以我们得到了
我们保留了特征
我们引入了空间不变性
我们减少了大小
嗯 减少了75%
这非常大
这对处理非常有帮助
此外，池化的另一个好处是我们减少了参数的数量
我们又减少了75%
我们减少了参数数量
这些参数将进入神经网络的最终层
因此我们防止了过拟合
池化的一个非常重要的好处是，我们移除了信息
这是一个好事
因为这样我们的模型就不会过拟合这些信息
因为 尤其是因为这些信息是不真实的，记住
就像我们刚开始说的
即使是对人类 对我们人类
重要的是看到确切的特征
而不是所有这些其他进入我们眼睛的噪音
嗯 神经网络也是一样
通过忽视不必要的不重要的信息
我们帮助防止了过拟合
这就是我们要做的 这就是池化的全部
问题是
当然
嗯 为什么最大池化呢
有很多不同类型的池化
你知道为什么步幅为2呢
2x2像素的大小
所有这些东西的大量 就在此处，我想向你介绍这篇可爱的研究论文
《卷积架构中池化操作的评估》
由波恩大学的多米尼克·谢尔撰写
这是链接，这篇论文的美丽之处在于它非常简单
非常直接 如果你从未读过一篇研究论文
你可能想尝试一下
这是一个很好的起点
它很短 只有10页
很容易阅读
此外，额外的好处是，现在我们讨论了卷积和池化
你将完全理解这篇论文中讨论的所有内容
你
这是一个很好的方式来实际加强你的知识
我强烈推荐你阅读这篇论文
我将花20分钟阅读它
你可以跳过第二部分
称为相关工作
如果你觉得它很遥远或不熟悉
就不要读那一部分
直接从第一部分跳到第三部分
这篇论文的一件事
他们谈论了一个叫做子采样的概念
嗯 子采样其实就是平均池化
所以，记得我们在这里
我们取最大值
在我们的正方形中
我们取最大值
有一个概念叫做平均池化
平均池化或一些池化
你只是求和这些值，然后平均池化或平均池化
你取所有这些值的平均值
子采样是一种平均池化的一般化 它是一种更普遍的方法来取这些值的平均值
你可以在论文中了解更多关于这方面的信息
但除此之外，只需在阅读论文时将其视为平均池化
这样你可以获得更多关于这个话题的信息
现在，让我们总结一下
我们已经走到了哪里
这是我们的输入图像
然后我们应用了卷积操作
我们有了卷积层
现在我们对每个特征图
我们应用了池化层
所以我们有了 我们已经完成了这两步
卷积和池化
现在我们要做一些非常有趣的事情
一些令人兴奋的事情 我们将尝试一下
这是一个截图
这是我从亚当哈雷创建的工具中截取的
嗯
当他还在里普森大学计算机科学学院时
现在他在卡内基梅隆大学
我认为做他的博士论文是一个很好的工具
让我们打开它
让我们看看 这样你就可以找到它
你实际上无法通过谷歌找到它
你必须知道URL
它也很好
通过谷歌很难找到它
因为这里没有文本
你看，很好
就是这个网址 cs dot ryerson ca
然后这些末尾的东西
基本上这就是我们要做的
但想象一下 所以这里你需要画一个数字
让我们假设我画了一个数字四
这个工具会将数字四放在这里
这就是你的第一步图像
然后这就是卷积步骤
这就是池化步骤
顺便说一下，池化也叫下采样
所以池化和下采样是同一件事
你可以看到它应用了卷积
然后应用了池化
你可以看到它确切的工作方式
所以你可以看到它应用了哪种卷积
或者应用了哪种滤波器
它们看起来什么样 你可以看到它正在寻找什么特征
嗯 然后进行池化
这样可以减小尺寸
你可以看到这里很重要
你可以看到这是卷积图像
这是池化图像
你还能看到相同的特征
只是信息减少了
但是同样的特征
特征被保存了
这是重要的部分
嗯 而且更重要的是
如果你知道如果四个都稍微转向像
侧面旋转一点
它还能拾取非常相似的池化层
然后之后它有更多的层
我们还没有谈论过这一点
所以然后它有另一个卷积卷积层在这里
我们实际上不会有
嗯 然后它有另一个池化层
但它基本上只是重复那个相同的过程
然后之后这就是我们要进一步讨论的
在课程中它有全连接层等等
但你可以肯定地玩一玩那个
所以如果我删除那个
如果我画一个七
你会看到它实际上告诉你猜测
它猜测这是一个七
第二个猜测第二个可能性是三
所以你可以画一些
一些具有挑战性的东西，看看它是否能拾取它们
所以让我们说如果我画一些看起来像零的东西
但它不是一个完成的零
它会拾取它吗
不这次这个没有拾取它
它看起来像一个九到那个图像
如果我稍微
完成它像这样看现在它认为它是一个零或一个九
你可以看到在那里
什么点亮了零或九
但我们会讨论那部分往下
让我们再做一个
让我们说像八
我认为八对这个来说很困难
没有拾取一个八
所以你可以看到这进入一个八
然后像之后它不再可识别
停止对我们有意义
人类对吧
这些 uh 特征它正在处理的
但同时它正确识别这是一个八
是的 所以肯定玩一玩那个
你可以画一个笑脸
看看会发生什么 然后看起来像一个三到这个嗯
到这个工具 因为工具显然是训练的
只有从零到九的数字
所以它必须识别那里某物
在那些中 它识别了一个三
这就像生活 当你当你看到某物，比如一种你从未见过的水果
比如一个
蛋奶酥 苹果或某物
你认为它是
嗯，像它是一个
它是一
因为你从未见过它们
你不知道如何分类它们，同样在这里
所以它从未训练过笑脸
这就是为什么它认为它是一棵树
它是三 所以，你看
这是一个非常强大的工具
这将对你有所帮助，去尝试它
实际上当你将鼠标悬停在像素上
它显示你哪里特征检测器拾取那个像素
所以你可以看到那些
嗯 这些像素来自
并且你可以看到如何过滤器通过图像
正是我们课程中讨论的
在这里你可以看到
你可以看到池化是用一个
池化是用一个2x2的小方块
并且你可以看到它的步幅是2
正如我们今天教程中讨论的那样
所以，你可以去尝试它
我希望你今天的会话你喜欢
我期待下次见到你 直到那时，享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p17 6. Step 3 - Understanding Flattening in Convolutional Neural Network Architectur.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p17 6. Step 3 - Understanding Flattening in Convolutional Neural Network Architectur

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎回来学习深度学习课程
我希望你跟上了这些直觉教程的进度
一切都很好 希望你有机会尝试我们到目前为止所学的一切
今天我们要谈论的是展平
好消息是这是一个非常简单的步骤
这个教程将会非常快速
然后我们就可以继续进行下一个有趣的事情
到目前为止，我们已经有了池化层提取的特征图
那是在我们对图像应用了卷积操作之后
然后我们将卷积的结果进行池化
或者对卷积后的图像进行池化
那么我们将做什么处理这个池化特征图
好吧，我们将其取来并将其展平成一个列
也就是说，简单地按行取数并将它们放入这个长的一列中
这样做的原因是因为我们想要将其后输入到一个人工神经网络中进行进一步处理
以便进行进一步处理
这是多个池化层看起来的样子
或者你有多个池化层和多个池化特征图
然后展平它们
所以你将它们放入这一列中
一个接一个地顺序排列
你得到了一个人工神经网络的输入向量
所以总结一下
我们有一个输入图像
我们应用一个卷积层
别忘了在卷积层之后应用relu或修正线性单元
我们在卷积层之后应用了修正线性单元函数
然后我们应用了池化
然后将所有内容展平
一个长的向量
它将成为人工神经网络的输入层
确切地讲它是如何工作的
我们将在下一个教程中找到答案
希望你们今天享受了这次课程 我期待下次见到你们，直到那时享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p18 7. Step 4 - Fully Connected Layers in CNNs Optimizing Feature Combination.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p18 7. Step 4 - Fully Connected Layers in CNNs Optimizing Feature Combination

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                欢迎回来，今天我们将继续学习深度学习课程
我们终于来到了步骤四，全面连接
那么这一步都是关于什么的
好吧 在这个步骤中
我们将在我们的卷积神经网络中添加一个完整的人工神经网络
所以，到目前为止我们所做的一切
哪些是卷积池化和展平
现在我们在背面添加了一整个新的角落
那有多强烈，那就是那绝对是某事
这就是我们的输入层
这里有一个全连接层输出
顺便说一下，全连接层
嗯 在人工神经网络中
我们曾经称它们为隐藏层
在这里，我们将它们称为全连接层，因为它们是隐藏层
但同时，它们是一种更具体的隐藏层类型
在人工神经网络中，它们完全连接
嗯
隐藏层不一定需要是全连接的
而在卷积神经网络中，我们将使用全连接层
这就是为什么它们通常被称为全连接层
所以基本上，我们在展平后得到的整个列或向量的输出
我们将其传递给输入层
这里我们有一个非常简化的例子
嗯 仅用于说明目的
并且
人工神经网络的主要目的是将我们的特征组合成更多的属性
预测类别
更好 我们已经在我们的输出向量中，展开和展平的
嗯 结果是我们已经做过的
我们在那个向量中编码了一些特征
它们可能已经能够很好地预测
嗯 什么
嗯 我们正在研究的是什么类型的班级
无论是狗还是猫
或者是肿瘤还是非肿瘤
等等 但同时我们知道我们有一个结构叫做人工神经网络
它是设计的
它有一个目的，就是处理属性和特征，或者处理特征
并产生新的属性，将属性组合在一起，以
甚至更好地预测我们试图预测的事情
我们知道这是从前一部分
那么为什么不利用这一点
这正是这里的计划
那么我们为什么不将这些值传递到一个人工神经网络中
让它进一步优化我们所做的一切
这就是我们将要做的
但我们看看一个更现实的例子
因为这个例子有点过于简单
这里有一个看起来更好的人工神经网络
我们有五个属性作为输入
在第一个隐藏层中
我们有六个神经元
在第二个或第二个全连接层中
我们有八个神经元 然后有两个输出
一个是狗，一个是猫
这里有一个重要的事情我们需要讨论
为什么我们有两个输出
我们习惯于在我们的人工神经网络中只有一个输出
但是当你预测一个数值时只有一个输出
当你运行回归类型的问题时
但当你做分类时
你需要每个类别一个输出
除非你有两个类别
就像我们这里有两个类别
狗和猫 我们可以只有一个输出，做一个二进制输出
说一个是狗，零是猫
这是完全可行的
实际上，你将在实践教程中看到这一点
他们将是这样结构的
同时
如果你有更多的类别
例如狗
猫和鸟 那么你需要每个类别都有一个神经元
这就是为什么我们在这个例子中练习两个类别
以便我们知道如果我们有超过两个类别
我们应该期待什么
所以这里将要发生什么
我们已经做了所有的准备工作
我们做了卷积
我们做了池化和展平
现在信息将通过人工神经网络
所以让我们看看这是如何发生的
信息从开始的那一刻通过
当图像被处理和卷积
然后池化，展平
然后通过人工神经网络
四个步骤，然后做出预测，我们将会看到它是如何发生的
会很快 非常有趣
但目前我们只需说一个预测被做出
例如
80%的机率它是一只狗
但结果发现是一只猫
然后计算一个误差
我们在人工神经网络中称之为成本函数
我们使用均方误差或卷积神经网络
称之为损失函数
我们使用这个交叉熵函数
我们将在单独的教程中讨论交叉熵和均方误差
以及所有事情是如何发生的
但目前我们只需说一个损失类型的函数
它告诉我们网络表现如何
我们正在尝试优化它
或最小化该函数以优化我们的网络
所以我们计算误差
然后通过网络反向传播
就像我们在人工神经网络中那样反向传播
并通过调整网络来优化性能
通常被调整的事项是
人工神经网络部分的权重
所以您在这里看到的蓝色线条
突触
另外被调整的事项是
特征检测器
我们知道我们正在寻找特征
但如果我们正在寻找错误的特征呢
如果这不起作用
因为特征是错误的
所以特征检测器
记住 那些我们拥有的小矩阵
嗯 那是
嗯 三乘三的矩阵
它们被调整
这样下次可能会更好
让我们看看会发生什么
类型的事情 当然这一切都是在大量的科学
在背景中进行了大量的数学
并且这一切都是通过梯度
梯度下降与反向传播
所以这一切 这不仅仅是随机扰动
实际上它是如何进行的非常有思考
但嗯
尽管如此 特征检测器被调整
权重被调整
整个这个过程再次发生
然后错误再次反向传播
这个过程会一直重复
这就是我们的网络被优化的方式
这就是我们的网络在数据上训练的方式
所以重要的是
重要的是数据通过我们的整个网络
从开始到结束
然后错误被比较
所以被计算
然后错误反向传播，所以和神经网络一样
只是 嗯
稍微长一点 因为那些我们已经做过的前三个步骤
现在让我们看看
有趣的部分 真正有趣的部分
这两类是如何工作的
因为 或者这两输出神经元是如何工作的
因为我们总是有一个输出神经元
当我们有两个时，会发生什么
如何
图像的分类情况如何
嗯 如何运作
我们从顶部神经元开始
我们从狗开始
我们主要需要
我们首先需要做的是
我们需要理解 我们需要为连接狗的所有突触分配权重
这样我们就知道哪些之前的神经元对于狗来说是重要的
让我们看看这是如何实现的
假设我们
让我们说 我们有这些数字在我们的前一层
前一层全连接在最后一层全连接
这些数字可以是任何数字
他们不必
他们可以是任何数字 但是他们
他们可以是任何数字
只是为了争论
我们同意我们正在寻找的特定数字在0到1之间
这样我们更容易争论这些事情并理解
并且1意味着那个神经元非常自信
它找到了一个特定的特征
而0意味着
嗯 那个神经元没有找到它正在寻找的特征，所以
因为归根结底
这些神经元
嗯，我喜欢
如果这张图像的左边有任何其他东西，那就是在寻找图像的特征
这已经是非常非常处理过的
但是仍然在检测图片中的特定特征或特征组合
在我们在卷积步骤之前
池中已经有了一些可识别的特征
它们在平面图像中变得更难以识别
然后在图像中变得更难以识别
然后他们被组合
然后继续 但是不管怎样我们在这里谈论的是
图片中存在的某些特征
或它们的组合 所以已经被激活的神经元
这很重要
已经被激活的神经元同时传递给了狗和猫
同时传递给了输出神经元
对我们来说，一个神经元被激活意味着
对于我们的论点来说 这意味着这个神经元正在放电
它真的很快检测到了这个特征
这可能是眉毛
它可能在再次检测这个眉毛
为了简单起见，检测到他的眉毛
并将这信息传达给狗的神经元
传达给猫的神经元
我能看到我的眉毛
然后它需要让狗和猫的神经元
理解这意思对他们来说意味着什么，所以在这种情况下，哪些神经元在活跃
这三种神经元在活跃，眉毛和鼻子
他说的是
他 我能看到一个大鼻子
我还能看到耷拉的耳朵
所以它对狗和猫说
然后狗
然后发生了什么
我们知道这是一个狗
所以狗神经元知道答案是
实际上这是一个狗
嗯 因为最后我们要与图片或图片中的标签进行比较
它知道那是一只狗 所以基本上狗神经元会说啊
所以我应该在这种情况下被触发
所以我这些是神经元
它们告诉我它们发送的信号，无论是对我，还是对狗，还是对猫
实际上是对我一个指示
那就是一只狗
在这些大量的迭代中
如果这发生很多次
狗会学习到这些神经元确实在特征属于狗时激活
另一方面
猫神经元会知道那不是猫 它会知道这个特征在激活
而这个神经元告诉我
它能看到耷拉的耳朵
但同时它不是猫
所以基本上对我来说
那就是一个信号我应该忽略这个神经元，就像
越多这样的事情发生 猫神经元就越会忽略
关于耷拉耳朵的这个神经元
所以基本上嗯，那就是通过很多很多的迭代
如果这经常发生
这只是一个例子
但如果这经常发生，也许一个
也许零点八，零点九
也许有时它不会激活 但总体平均
这个神经元确实经常激活
当它确实是一只狗时
狗神经元会开始赋予这个神经元更高的重要性
这就是那样
这就是我们要表示的方式 我们会说通过这个迭代过程
这三个神经元，通过很多很多
很多很多样本和很多很多轮次
记住所以 样本是你数据集中的一行，而轮次是你遍历整个数据集的过程
一遍又一遍又一遍
通过很多很多的迭代
这个狗神经元学会了这个眉毛神经元和大鼻子神经元
以及这个耷拉耳朵神经元
它们似乎都真的很
有助于uh
分类的对象是什么
这是一个狗
这就是它的工作方式
再次，这些耳朵、鼻子和眉毛
这些都是非常模糊或者非常不切实际的例子
因为到这个阶段，整个卷积神经网络的阶段
他们正在寻找的东西已经完全无法辨认
但同时，这也是狗或猫的特征，或者你正在分类的任何东西
然后让我们继续下一个
现在我们来看看猫神经元
但我们要记住这些权重是
你知道他们已经把狗分类了
所以狗基本上忽略了所有这些其他神经元
一二三四五
但它真的很在意这三种神经元在说什么
现在 猫在听什么
每当它是一只真正的猫
嗯，没错
这是一个例子，说明这种情况
实际上说的是一只猫 所以你会看到
这三种神经元
零点九
和一他们说了些什么
他们同时对狗和猫说了些什么
这再次很重要要记住
所以输出信号双向传递
这是一样的 它对狗说一就是对猫说一
然后这取决于狗和猫是否决定
考虑这个信号并从中学习
无论是狗还是猫都能看到这是一个照片
我应该放一张猫的照片在这里
但基本上想象一张猫的照片
无论是狗还是猫都能看到这个实际上是一只猫
所以基本上狗的想法是
哦，好的 所以这些胡须
以及这些尖尖的三角耳朵
以及这个较小的尺寸
我猜
或者我不知道
也许这种类型
你知道猫的眼睛有这些东西
他们的眼睛很小
他们不是圆形
他们是线条或者是什么像猫的眼睛
基本上这些猫眼
它们肯定没有对我起作用
它们没有帮我
预测 因为每次这些神经元亮起
预测不是我正在寻找的
另一方面 猫就像
嗯 那很有趣
每次这个亮起
或者大部分时间它亮起
它符合我的期望
它符合我正在寻找的
好的 我要听这个人
多于这个人
这个人同样的事情 每次它亮起
或者大部分时间它亮起
我碰巧得到一个好的
我碰巧因为我的预测而受到奖励
因为我做对了
这是只猫 好的 所以我要听他更多
你知道这对我没有用
嗯，因为他实际上
你知道，他是
他甚至没有亮起
这是只猫 但他没有亮起
相反的事情发生了 还有这个
这是只猫 但他没有亮起
所以我不会听他 但是这个，当它，当
什么，什么 眼睛，猫的眼睛亮起
我们可以看到，我能看到，这是只猫
大部分时间匹配，所以我将从中学习
我将听这三个人
比不常
所以基本上猫在听这三个
并忽略其他五个
这就是这些最终神经元学习的方式
哪些神经元在
最终全连接层中听
所以输出神经元学习哪些最终或哪些最终
全连接层神经元来听取
这就是它们理解的方式
基本上 这就是特征如何通过网络传播并传递到输出
因此即使这些特征
当然 对它们来说并没有太多的意义
比如柔软的耳朵或胡须
同时它们同时也有一些独特的
它们是该特定类别的独特特征
这就是网络的训练方式
因为我们在回忆的过程中
也在进行反向传播过程
我们也调整特征检测器
如果一个特征对输出没有用
那么它很可能会被忽视
因为这并不是在一或两次
这是通过成千上万次的迭代
所以随着时间的推移
对网络无用的特征将被忽视
替换功能很有用
最终，
在最后一层神经元中
你可能有很多图像特征或特征组合
这些确实代表了狗和猫
一旦你的网络被训练好
这就是它的应用方式
这就是下一步 我们已经训练好我们的网络
嗯 这发生了 让我们看看当这个网络被应用到时发生了什么
所以让我们假设我们传递了一张狗的照片
嗯 值通过网络传播
我们得到一些值
所以这次狗和猫的神经元不知道
它们没有狗的图像在这里
它们不知道那是狗还是猫
它们不知道那是什么
但他们已经学会了倾听这里所展示的内容
正确 他们已经学会了倾听狗神经元，这些三个神经元在倾听
猫神经元在倾听这三个
因此，狗神经元看着123并说，啊哈
这些相当高 所以我的概率将会很高
那就是狗 猫神经元看着这三个并说
好的 这个很高
但是这些很低，很有趣
所以我的概率是零点
零点五，那就是你的预测
所以对于神经网络的第一个选择是一只狗
第二个选择是猫
基本上就是这样
所以答案是狗
当你通过一只猫的照片时，也会发生同样的事情
嗯 你得到新的值，你可以看到即使这个很高
这些很低
对于猫来说，这个是高的
这个是高的，这个有点低
所以这里的概率可能不如之前
但你仍然可以看到它是一只79%的猫
因此神经网络将投票认为这是一只猫
所以基本上所有的神经网络都将得出结论认为这是一只猫
投票这个词被用来指这些家伙
所以这些神经元在最终的全连接层
他们得跳
这是他们的投票
再次我们只是为了论辩
把值放在零和一之间
这里这些可以是任何值
但他们得投票
然后这些权重是他们投票的重要性
所以这就是这些
这些紫色的权重是狗神经元如何看待他们的投票
它赋予这些神经元和这些投票的重要性
这就是猫神经元对这些的重要性
嗯
这些神经元对这些投票的重要性
因此，这些神经元投票给狗和猫
它们决定听谁的
然后它们做出预测
整个神经网络得出结论，在这种情况下这是一个猫
然后那就是然后那就是你的结果
这就是你如何得到这样的图像
你有一只猎豹
然后你有一只啊
猎豹班级，你知道，有很大的可能性
所以这是你知道的网络预测的概率
这些是低的 但这些仍然存在
因为这些仍然存在一种小的机会
其他神经元也在听它们的选民
他们正在说 哦 也许这实际上是一只豹子和一列子弹列车
非常可能的
这里 剪刀 你知道这个
但手光油非常接近第二名
然后油炸过去听诊器
因为你可以看到像这个人
这个神经元
剪刀 神经元 输出神经元听取了它的选民
它总体上有压倒性的优势
但然后手光油也有好的结果
所以我们去吧 这就是全连接是如何工作的
以及这是如何所有这些一起发挥作用的
我希望你今天的教程你喜欢
我们将在总结中也总结这一切
我会在下次见到你，直到那时 享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p19 8. Deep Learning Basics How Convolutional Neural Networks (CNNs) Process Images.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p19 8. Deep Learning Basics How Convolutional Neural Networks (CNNs) Process Images

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎回来参加深度学习的课程
我们在这门课程的这一部分学到了很多东西
让我们总结一下我们讨论的内容
好的，让我们开始 我们从一个输入图像开始
我们对其应用了多个不同的特征检测器，也称为滤波器，以创建这些特征图
这就是我们的卷积层
然后在这个卷积层之上
我们应用了ReLU或修正线性单元，以去除任何线性，增加图像的非线性
我们正在处理图像
然后我们将我们的卷积层应用了一个池化层
所以从我们每一张特征图中
我们创建了一个池化特征图
基本上池化层有很多优点
池化层的主要目的是确保我们有
嗯，图像中的一些特殊不变性
所以基本上，如果某些东西倾斜、扭曲或者与理想情况有点不同
那么我们仍然可以捕捉到那个特征
池化显著减少了我们图像的大小
池化还有助于避免我们的数据过拟合
或者将我们的模型应用于数据
因为它只是简单地去除了大量数据
但同时池化保留了我们追求的主要特征
只因为我们使用的指令和池化方式是最大池化
然后我们将所有池化后的图像扁平化为一个
沿着一个向量或列的所有这些值
并将它输入到一个人工神经网络中
这是第三步扁平化和第四步是全连接的人工神经网络
所有这些特征通过网络处理
然后我们有这一层
最终的全连接层
它进行投票以确定我们想要的类别
然后，这一切都通过前向传播和反向传播过程进行训练
并且经过大量的迭代和轮次
最终我们得到一个非常精确的神经网络
另一个重要的事情是，不仅在人工神经网络的部分权重被训练
而且在同一梯度下降过程中，特征检测器也被训练和调整
这使得我们能够得到最佳的特征图
最终我们得到一个完全训练的卷积神经网络
它可以识别图像并进行分类
所以我们就这样做 这就是卷积神经网络的工作原理
现在你应该完全熟悉这个概念，准备好继续进行实际应用
如果你想做一些额外的阅读
那么这里有一篇很好的博客
Debande来自十六
你可以在底部看到链接
所以博客叫做九深度学习论文
你需要了解关于理解cnn的三部分
这篇博客实际上给你九种不同cnn的简短概述
由像Jan Le Kun这样的人创造的
然后你可以进一步研究
所以你会发现很多新的东西，对你来说完全陌生
你必须理解它们
但请记住这个博客
或者记住这九篇论文
即使你现在还不准备阅读它们
也许在实践教程之后
也许在你在深度学习的空间中进行一些额外训练之后
你可以参考这些工作
理想情况下
我认为通过查看其他人的神经网络，你会得到很多价值
以及他们如何结构化卷积网络
这将帮助你理解最佳实践
以及为什么某人以某种方式做某事
这将帮助你理解神经网络的架构
神经网络和卷积神经网络也不例外
它们是一种架构挑战
你必须提出一个想法
然后结构化它
然后调整它和微调它
以获得最佳设计和最优性能
这就是我们今天的内容 我们今天就到这里
我希望你今天的教程和整个这一节都很有趣 我期待下次见到你，直到那时享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p20 9. Deep Learning Essentials Understanding Softmax and Cross-Entropy in CNNs.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p20 9. Deep Learning Essentials Understanding Softmax and Cross-Entropy in CNNs

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎回来参加深度学习的课程
这是一份额外的教程，用于讨论softmax和交叉熵函数
这并不完全必要
为了让你能够通过我们已经走过的所有部分
在主要部分的这一部分中
我们正在讨论的
卷积神经网络
但同时 我认为这将是一个很好的补充，增加你的知识和技能
所以让我们继续深入研究这些函数
所以我们首先从开始，我们有什么
这里是我们在本节主要部分构建的卷积神经网络
然后在最后它为0点弹出一些概率
95%为一个狗和0.05%为一个猫
给定左边的图片作为输入
这是在训练之后
这实际上是它的运行和一个啊
分类一个特定的图像
所以问题是为什么这两个值加起来等于1
因为我们所知道的，从我们学到的一切关于人工神经网络
没有理由认为这两最后一个神经元彼此之间是连接的
所以，他们怎么知道价值的
他们中的每一个怎么知道另一个的价值是多少
他们怎么知道要把他们的值加起来等于一
好吧 答案是在经典人工神经网络的版本中它们不会在。
并且他们唯一能做到的方式是因为我们引入了一个称为softmax函数的特殊函数
为了帮助我们解决这个问题
所以通常来说 如果狗和猫的神经元有任何实际的值会发生什么
嗯 它们不必非得是
它们不必非得加起来等于1
但我们会应用softmax函数，它在上面已经写好了
这会将这些值限制在0到1之间
并且使它们加起来等于1
引用维基百科的话，
softmax函数或归一化指数函数
是逻辑函数的一种推广，它将一个k维任意实数值向量
转换为一个k维实数值向量
在零到一的范围内，我将其加起来等于一
所以基本上它正好做了我们想要的事情
它使得这些值介于零和一之间
确保它们加起来等于一
并且它运作的方式是，这种可能的方式就是这种方式
那是因为在这里底部你可以看到有一个求和符号
因此它取指数
嗯，把它放在z的幂上，然后相加
所以z希望你在所有的课程中都能做到这一点
所有这些值和因此那就是
嗯 你的正常化就在这里发生
这就是softmax函数的工作方式
将softmax函数引入卷积神经网络是有道理的
因为如果你有狗和猫的可能类别
对于狗类别你有80%的概率
而对于猫类别你有45%的概率，对吧
那样说不通
因此引入softmax函数要好得多
这就是大多数时候会发生的事情
在卷积神经网络中
现在 另一个事情是，softmax函数是手牵手出现的
被称为交叉熵函数的东西
这对我们来说非常实用
那么，让我们首先看看公式
这是这个交叉熵函数的样子
实际上我们将会使用不同的计算
我们将会使用这个交叉项的表示法
但结果基本上相同
这只是更容易计算
这是我所知道的
这可能听起来与现在任何事情都无关
只是屏幕上的公式
但是啊 在本节末尾会有一些额外的推荐阅读
所以不要担心
如果你没有抓住数学要点
就像如果我们现在没解释数学一样
但重点是什么是交叉熵呢
交叉熵函数
还记得我们在人工神经网络中曾经使用过一个叫做均方误差函数的函数吗
我们使用这个函数作为评估网络性能的成本函数
我们的目标是最小化MSE，以优化网络性能
这就是我们的成本函数
然后，然后在卷积神经网络中，我们可以继续使用MSE
但在卷积神经网络中，一个更好的选择是交叉熵函数
在应用softmax函数后，交叉熵函数成为更好的选择
在卷积神经网络中，当应用交叉熵函数时
不再称为成本函数
这叫损失函数
它们非常相似，只是有些术语上的区别
它们的意思有点不同
但对于我们的目的，它们差不多是一样的
发生的事情是，损失函数再次
是我们想要最小化的东西，以最大化我们网络的性能
所以让我们快速看一下这个函数如何应用的例子
假设我们将一只狗的图像输入到我们的网络中
预测的狗的值
0.9 这是在训练期间
所以我们知道我们知道标签
这是一个狗
所以预测的值是0.9
猫的预测值为0.1
然后这里我们有标签
所以我们知道它是一只狗 因为这是训练
零一是狗
零是猫 所以在这种情况下你需要
你需要将这些数字代入你的交叉熵公式
所以你这样做是将左边的值代入变量q
在右边下方logarithm中的数值
右边的值将进入p
所以重要的是记住哪一个放在哪里
因为你如果搞错了
你不想对零值取对数
或者对一取对数
所以你只需将它们代入
确保你将它们放入正确的位置
然后基本上你就把它们加起来
这就是交叉熵的工作方式
现在我们将看一个实际的
现在
我们将看一个具体的步骤 实际应用中的应用示例
这将使交叉熵更直观
我的目标是让你对交叉熵更熟悉
因为它听起来可能很复杂
没有讽刺之意
它听起来可能很复杂
就像卷积神经网络
它听起来可能很复杂
是的 它很吓人
但它并不
那就是重点 让我们去应用它
只是为了确保它并不吓人
所以
这是一个神经网络
这也将解释我们为什么
为什么我们看两种不同的成本函数
所以让我们说有两个神经网络
神经网络一神经网络二
假设我们有两个神经网络
然后我们传递一只狗的图像
我们知道这是一个狗而不是猫
然后这里有一只猫
这是一个猫 不是狗
这里有一个看起来奇怪的动物
实际上是一只狗
不是猫 如果你仔细看
嗯 我们想看看我们的神经网络会预测什么
在第一个案例中 神经网络190%的狗
嗯 10%的猫正确
神经网络2
60%的狗
40%的猫仍然正确
更差但正确
第二个选项首先
神经网络10%的猫狗
90%的猫正确
你知道他们在谈论230%的狗
70%的猫
更差但仍然正确
然后最后神经网络1在3张图片
神经网络1 40%的狗
60%的猫错误
神经网络2 10%的狗
90%的猫错误更差
所以关键在于即使两个网络都错了
在最后一个在所有三张图片
神经网络1一个比另一个好
神经网络2所以即使在最后情况它
它非常
它有一个
它给了狗40%的机会
相反神经网络2只给了狗10%的机会
所以神经网络1在所有方面都比神经网络2好
与神经网络2相比
现在我们将看看它们可以测量的功能
我们已经谈论过的性能
让我们把这些放在一个表格中
所以这是神经网络1
你有行号
这是图片编号
对于图片1你有它预测的
90% 狗10猫
所以这些都是帽子变量
然后你有实际值
狗 嗯
正确的猫，错误的
对于图片2也是一样的
对于图片3也是一样的
对于神经网络2也是一样的
一只狗
第一张图片60%的猫 第一张图片40%的狗
这就是它预测的 正确答案是一只狗
不是猫等等
现在我们来看看我们能得到哪些错误
所以我们可以计算哪些错误来估计和监控我们网络的性能
一种错误类型被称为分类错误
那就是基本上问你
你正确了吗或者不正确
不管概率如何
你正确了吗或者不正确
或者你没有正确
所以对于两种神经网络都是
嗯 他们每个人
嗯 他们错了一个或两个
这是他们做错的数量
所以他们三个人中有一个做错了
所以他们的出错率是33%
嗯 神经网络一的出错率
神经网络二的出错率也是33%
从这个角度来看
两个神经网络表现相同
但我们知道这不是真的
我们知道神经网络一表现更好
比神经网络二
这就是分类错误不是一个好衡量标准的原因
尤其是对于反向传播的目的
均方误差不同
顺便说一句，我在Excel中进行了这些计算
我只是不想让你感到无聊
但你完全可以坐下来在纸上做它们
或者在Excel中
这些都是非常直接的计算
仅仅就是求平方误差之和
然后只需在你们的平均值上取平均。
在你的观察中
那就是这样了
嗯，所以在神经网络方面
你在神经网络二中获得了百分之二十五
你得到了71%的错误率
所以你可以看到，这个更准确
它告诉我们 神经网络1的错误率远低于神经网络2
然后交叉熵再次
我们已经看到了公式 你也可以计算这个
这实际上比均方误差更容易计算
交叉熵给出神经网络1的0.378，神经网络2的1.06
所以你可以看到结果有所不同
所以可以看到结果有所不同
嗯 当你那样看他们时
当你看
你知道均方误差和交叉熵
嗯 为什么你会使用交叉熵而不是
嗯
均方误差不仅仅是关于种类的
就像他们吐出的数字一样
这些计算只是为了向你展示这一切
这一切都是可以实现的
你可以在纸上完成它
这不是
这些并不是非常复杂的数学
这些都是非常简单直接的事情
但是为什么要使用交叉熵而不是均方误差
这是一个非常好的问题
我很高兴你问了
嗯 这个问题的答案是有很多优点
交叉熵与均方误差
这些并不是显而易见的
所以我会提到几个
然后我会告诉你在哪里可以找到更多信息
所以其中一个是，如果例如说
你正处在你的后向传播的初始阶段
你的输出值非常非常小
所以它比你想要的实际值要小得多
那么在初始阶段，梯度在你的梯度下降中会非常非常低
而你，这不会足够
对于神经网络来说，实际开始做点什么并开始移动会很困难
并开始调整那些权重并开始实际朝正确的方向前进
而当你使用像交叉熵这样的东西时
因为它里面有对数
它实际上帮助网络评估即使是一个小错误
并解决它
这就是如何思考的
所以假设再次
这是非常 并且在非常直观的方法中
这里有这个
这里有一个链接到数学
你可以通过数学更详细地推导出这些内容
但一个非常直观的方法
让我们说
嗯 你的
就像你想要的结果是一个是
而现在你处于一一
百万分之一
正确 所以零点零零零零零零零一
然后你下次改进，你的结果从一百万分之一改进到一万分之一
从计算方差的角度来看
你只是减去一个另一个
或者基本上在每个案例中你计算方差
当你比较一个案例与另一个案例时，你会看到方差的变化不大
你的模型并没有改进很多
当你看均方误差时，你的网络并没有改进很多
但是如果你正在查看交叉熵
因为你正在取对数
然后你在比较两者并相除
你会发现你实际上显著改善了你的网络
所以你从百万分之一提升到了千分之一
在均方误差的术语中会非常低
它会微不足道
它不会影响你的梯度提升过程
或者不会正确引导你的后向传播
它会正确引导它
但这就像非常缓慢的指导
它不会足够
而如果你通过交叉熵做
交叉熵会理解这一点
哦 即使这些是非常小的调整
它们只是
你知道 在绝对意义上做出微小的变化，相对意义上
这是一次巨大的改进
我们肯定在正确的方向上前进
让我们继续那样做
所以交叉熵将帮助你的神经网络
达到正确的状态
达到最佳状态
这是对神经网络达到最佳状态的更好方法
但请记住，这仅在交叉熵是首选方法时才有效
仅适用于分类
所以如果你谈论的是像回归这样的东西，就像我们在人工神经网络中所做的那样
那么你更愿意使用均方误差
Whereas cross entropy is better for uh
分类，再次这与我们使用softmax函数有关
这就是一种直观的解释
如果你想了解更多
如果你真的感兴趣
嗯 你知道 我们为什么使用交叉熵而不是均方误差
在谷歌上搜索杰弗里·辛顿的视频，标题为softmax输出函数
他解释得非常好
你知道，作为深度学习的教父
嗯 谁能解释得更好呢
嗯，顺便说一句，杰弗里·辛顿的任何视频都是黄金
他拥有解释事物的巨大天赋
所以这就是softmax与交叉熵
我希望这能给你一种直观的理解，这里的情况
但更重要的是，你不应该被交叉熵这个术语吓倒
因为Hal会在实践教程中提到它
我想确保你已经为此做好准备
它是计算你损失函数的另一种方式
也是优化你的网络的另一种方式
这专门针对分类问题
因此卷积神经网络
并与softmax函数紧密相关
所以额外阅读
如果你对交叉熵有一个轻量级的介绍
如果你对交叉熵更感兴趣
嗯 交叉熵
当然，一篇好文章值得一看
叫做友好的交叉熵损失介绍，由Rob DiPietro于2016年撰写
以下是链接
嗯
非常好 非常友好
没有超级复杂的数学
好的比喻
好的例子使用汽车的类比
你看到汽车并谈论信息和比特以及限制
你知道你如何编码这
你如何编码那
这是一个
这是好文章值得一看
它会给你一个交叉熵的概述
从入门的角度来看
如果你想深入研究重数学
就像你看到的这里
嗯 然后查看这个由Or编写的博客
如何实现一个神经网络
间奏二
所以间奏就像
就像一个中间的事情
就像一种间歇
你知道的，就像你去剧院
在你第一部分和第二部分之间有一个休息
所以因为他正在经历所有这些步骤
然后他说我得先解释这个
嗯，是的
这就是为什么它被称为间奏曲
没有其他原因 据我所知
彼得·罗尔兰的文章
2016年
所以两者都很新
嗯，是的
查看这个 如果你对数学感兴趣
在交叉熵和softmax以及交叉熵这篇文章背后
实际上 就是这样
这就是这两者的全部
我希望我能为这些添加一些额外的清晰度，祝你好运
那么，继续前进
嗯 这将很有趣，享受实践教程
下次再见，直到那时 享受深度学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p21 11. Step 1 Intro to CNNs for Image Classification.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p21 11. Step 1 Intro to CNNs for Image Classification

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们
欢迎来到这个非常令人兴奋的新实践活动，卷积神经网络
如果你对之前的部分没有太感到不知所措
你知道人工神经网络
嗯 那么你将和我一起在这个新部分中大放异彩，因为基本上卷积神经网络
正如你在直觉讲座中所看到的，仅仅添加了一个额外的层
这是卷积层
那
正如你所理解 为AI赋予眼睛
你知道，深度学习模型
因为确实 使用卷积神经网络
我们现在可以将图像
或者 你知道 三维帧作为输入
与我们之前的人工神经网络相反
这需要一个包含一些特征的信息的输入向量
记住银行的客户特征
但我们将在前面添加一个卷积层
我们可以像人类一样可视化或看到图像
所以 这相当令人兴奋
你知道 我们在向人类智能迈出了一步
因为你知道科学家对深度学习的迷恋
知道 这是机器学习的一个分支，使得人工智能越来越接近人类智能
甚至在一些更深入的深度学习课程中，你会看到
我们不仅可以给AI添加眼睛
还可以用LSTM细胞给它添加一些记忆
还可以给它添加一些批判性思维
在深度学习科学中有很多创新
这绝对是令人着迷的
但我们将专注于CNN
就这样了
我的朋友们 让我们开始这个新的实践活动
像往常一样 在我们进入这个文件夹之前
让我们确保这里的每个人都在同一页面上
我在这个教程之前给了你链接到这个文件夹
所以现在请跟着我进入第八部分
深度学习
我们正在里面
我们现在将转到卷积神经网络
好的 所以对于这一部分
异常情况下我们只有python的实现
这主要是因为r更常用于数据挖掘
类似于机器学习 或者你知道的高级统计
高维统计
但我一生中从未遇到任何使用r进行计算机视觉的科学家
有一些库，如deep water，可以构建用于计算机视觉的cnn
但真正最好的，最先进的编程语言用于深度学习肯定是python
多亏了谷歌和脸书开发的令人惊叹的库
你知道谷歌开发了tensorflow
这是深度学习的一个惊人的库，而Facebook开发了pytorch
这也是另一个惊人的深度学习库
但这些两个tensorflow和pytorch只适用于Python
这就是为什么特别针对这一节
这里不会有CNN的R实现
对吧 ANN是可以的，因为我们还在用神经网络做一些高级的数据挖掘
但对于计算机视觉
你真的最好的选择是Python，没错
那么我们进入Python
与以前相比，现在第二个不同之处
如你所见 你将只找到这个文件夹中的实现
而不是数据集，这是一个非常好的原因
那是因为数据集实际上超级大
你知道，按大小来说
它有几百兆字节
因为数据集包含大量猫和狗的图片
我们很快就会看到它们
但是既然它包含了很多图片
好吧 我没有在这里包含数据集
否则你们知道对于那些想要下载整个机器学习数据集的人来说
代码和数据集的文件夹
这将花费更多的时间
如果我在这里包含这个数据集
那么如果我把它分开留下
这就是我所做的 我分开留下了它
我把它给了你
实际上，在这篇教程之前，在同一篇文章中
我希望你已经下载了它
因为现在我们将查看文章底部
在这篇教程之前
你必须下载这个确切的文件夹
嗯 实际上，压缩文件夹
但我已经解压了它
但你必须下载这个文件夹部分
四十个卷积神经网络
确实包含了不仅 ip y 和 b 格式的代码
Npy 格式
但主要是数据集
包含三个子文件夹的数据集
第一个文件夹包含猫和狗的所有图像
但是为训练集
这意味着我们将训练我们的 cnn 模型
所有这些猫和狗的图像在训练集中
然后我们有这个其他文件夹
这是我们的测试集，我们将在其中使用新的猫和狗图像来评估我们的模型。
在这个数据集上，我们的模型没有进行过训练。
最后，这里有一个小文件夹，里面只包含两张图像。
这将仅用于在生产环境中测试模型。
我们将使用单个图像来测试模型。
首先，我们将使用这个美丽狗狗的图像来测试我们的卷积神经网络是否能够检测到狗狗。
也就是说，我们可以预测在这张图像中确实有一只狗。
我们将使用这两张图像来测试我们的CNN是否能够检测到狗狗。
也就是说，我们可以预测在这张图像中确实有一只狗。
我们将使用这两张图像来测试我们的CNN是否能够检测到狗狗。
我们将对猫的图像做同样的处理
以便我们可以检查
确实我们的CNN预测这张图像中有猫
正如你所理解的
我刚刚解释了问题
实际上 我们将构建和训练一个卷积神经网络
以识别图像中是狗还是猫
好的 所以我希望你喜欢这个案例研究
当然 这次不是商业案例研究
但我们做这个会很有趣
这也是了解卷积神经网络的好方法
即使这只是一个介绍
你将看到我们将构建的CNN相当先进
实际上，实现相当先进
使用了许多技术工具
当然，最终会完美地完成任务 当然
好的 这就是第二个具体的事情
数据集已经单独发给你了
好的，快速给你展示一下
训练集和测试集
在训练集中，你有很多猫和狗的图片
实际上你有四千张猫的图片和四千张狗的图片
我可以随便拿一张
这是只狗
另一只狗 你知道许多种类的狗
如果你喜欢狗
你会在图片这里度过一段美好的时光
我们走吧
这是一只非常可爱的狗
顺便说一下 好的，猫也是一样的
你有许多猫的图片
正确的，不同的风格
不同的颜色 你知道这么多
无论是猫迷还是道格迷
你会在查看这些图像中的任何一个时度过一段美好的时光，测试集也是如此
嗯 这里有一千张猫的照片，同样有一千张狗的照片
所以，总结一下在训练集中
总共有八千张图片
有四千张猫的照片和四千张狗的照片
在测试集中
总共有两千张图片
有一千张猫的照片和一千张狗的照片，重要的是要记住这些数字
因为我们将在实施中使用它们
好的，很好
所以确保将这些放在你的机器上 因为
当然，我们将使用它来运行我们的代码 现在，第三
我想在这一次介绍性教程中强调的特定事情
是我们第一次无法运行我们的实现
这是一个事实
这是这一个卷积神经网络
我a b我们不可能在谷歌协作上运行这个实现
为什么那是因为简单的原因
这个数据集对于谷歌协作笔记本来说太大了
因此，在这门课程的第一次
我将向你展示如何在jupyter notebook上运行这个实现
因为使用jupyter notebook，我们将能够直接从我们的机器访问数据集
我们将从我们的机器上运行代码
但在一个jupiter笔记本中
好吧 笔记本 好的
所以我们要做的是
实际上，在这个新的部分是
我们将继续重新实现整个代码从零开始，在谷歌协作中
但一旦这一切都实现了
我们将简单地转到文件这里
然后点击这里
下载i p y和b这将下载ipp y和b文件
这将能够运行在jupyter笔记本上，好的
这就是会发生的事情
但我们将继续在谷歌协作上实现这一点，说到这一点，好吧
现在我们必须保存一个副本到驱动器
因为现在是只读模式
因此我们需要创建一个副本以便能够修改并重新实现整个代码
好的 那么我们像往常一样做吧
让我们删除所有代码单元格
对了 只删除代码单元格
确保保留技术单元格
以保留那些高亮显示的结构
因为确实现在我们有一个相当长的实现
所以保持结构很重要，以便我们
你知道的 任何时候都可以后退一步并知道我们正在前进
好的 所以只删除代码单元格
现在到达第三部分
你知道你将会认出一些与以前一样的步骤
与a n right
这是第四部分 那里我们走 all right
这就是整个结构 让我们看看它
你知道从这里开始
首先我们会导入库
然后我们有四个部分结构
第一部分 day repressing 第二部分
构建cnn 第三部分训练cnn 第四部分做一个单预测
这正是与以前一样的
你知道的，与ann
只是这次在第一部分我们会做不同的工作
因为第一次，实际上在课程中我们不会预处理一个经典数据集
但这次我们将会预处理一些图像
因此数据预处理阶段将会不同
它将会包括两步
首先我们会预处理训练集
然后我们会预处理测试集 all right
然后在第二部分我们会构建一个cnn
你知道整个卷积神经网络的架构
我们会初始化cnn为一个层的序列
然后我们会进行第一步卷积到添加卷积层
然后我们会进行第二步池化，更具体地说最大池化
然后我们会添加一个第二卷积层来使它
你知道的，一个深度神经网络而不是浅层神经网络
然后我们会进行第三步，展平
好的
然后进行第四步，创建预测
完成 将所有卷积和池化的结果展平为一维向量
这将成为全连接神经网络的输入
最后我们将连接所有这一切
最终的输出层
那么在第三部分
当训练CNN时
与ANN相同
我们将首先编译CNN
然后在训练集上训练CNN
你知道 在测试集上评估它
在输出中我们将清楚地看到
最后我们将做一个单一的预测
你知道 在产品中测试我们的模型
因此我们将在我们的CNN上部署两幅不同的照片
一幅将有一只狗，另一幅将有一只猫
我们希望我们的CNN能够分别识别出狗和猫
这就是我们的结构
我希望你已经准备好了
实际上我相信你已经准备好了
如果是这样的话
请加入我进行下一阶段的教程 直到那时，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p22 12. Step 2 - Keras ImageDataGenerator Prevent Overfitting in CNN Models.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p22 12. Step 2 - Keras ImageDataGenerator Prevent Overfitting in CNN Models

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                好的 我的朋友
你准备好构建卷积神经网络了吗
我们前面有很长但是非常令人兴奋的旅程
让我们开始吧
好的 我们将从非常基本的步骤开始，即导入库
这将只包括导入tensorflow和keras库的预处理模块
所以让我们在新的代码单元格中快速高效地这样做
实际上你知道如何导入tensorflow
我们从导入命令开始
我们指定库的名称为tensorflow
我们像之前与ann一样添加tf快捷方式
然后我想导入其他东西
这将使我们在第一部分中能够进行图像预处理
这是keras库中的图像子模块，用于图像预处理模块
因此，我们将从这里开始
从keras库中获取预处理模块的访问权限
我们从中获得图像子模块
我们想要导入这个的原因是因为我们想要导入一个特定的类
那就是图像数据生成器
我会很快解释这是关于什么的
但这绝对是强制性的
在第一部分数据预处理中
你知道在预处理你的照片时
让我们在这里导入它
我们需要添加的导入
然后是图像数据生成器
好的
我很快就会解释这是关于什么的
以及我们将如何使用它，好的
然后你知道我喜欢做的另一件事
只是为了向你展示我们确实在使用 tensorflow 2.0
我只是想打印出我们现在正在使用的 tensorflow 版本
记住要做这个
我们需要先调用 tensorflow
然后之后一个点，两个下划线
然后版本和两个下划线
这会让你知道
在输出中打印
我们使用的tensorflow版本
这是为了确保我们使用的是tensorflow 2.0
但是 你知道
根据你运行这段代码的时间
你知道在我录制这个教程之后
你可能会有一个不同的版本
但你肯定会得到一个tensorflow 2的版本
好的
所以我在这里执行第一个单元格，导入tensorflow
以及像keras这样的图像处理模块
现在让我们运行这个
确实确认我们自己使用的是tensorflow 2.0
这比tensorflow 1.0好得多，好的
所以现在我们可以继续第一部分，数据处理
这将分为两步进行
首先预处理训练集，然后是预处理测试集
那么我们从训练集开始，创建一个新的单元格
现在让我来解释一下我们如何做这一切，好的
那么我们将如何预处理我们的图像
嗯 实际上我们将要做多件事情
首先我们会做的事情是
我们将对所有训练集的图像应用一些变换
只有训练集的图像
我们不会在测试集上应用相同的变换
我们想要在训练集的图像上应用一些变换的原因是
只有一个目的
这是为了避免过拟合
确实 如果我们没有很好地应用这些转换
在我们在训练集上训练我们的cnn时
我们会在训练集和测试集之间的准确率上产生巨大的差异
你知道在评估集上
实际上我们在训练集上会得到非常高的准确率
你知道接近98%并且在测试集上得到较低的准确率
这就是过拟合
这是我们绝对需要避免的
总之 你知道 无论是处理经典数据集还是在计算机视觉领域工作
嗯 避免过拟合的方法是
如我所说 应用变换
这就是为什么 现在让我来解释你知道的
这些变换是什么
然后我将最后解释我们如何实施这一点
所以，什么 这些转换是什么
一些简单的几何转换
或者对图像进行缩放或旋转
我们基本上将应用一些几何转换
然后我们将稍微旋转图像
我们将进行水平翻转
我们将进行放大和缩小
你知道我们将应用一系列的变换，以便修改图像，使它们成为我们所说的增强图像。
实际上，我们现在要做的技术术语是图像增强。
你知道，所有这些变换的技术术语被称为图像增强。 它基本上涉及对你的训练集图像进行变换，
这样你的卷积神经网络模型就不会过度学习。 你知道，它不会过度训练于现有的图像。
因为通过应用这些变换，
因为你知道，我们不想让模型过度拟合现有的图像。
因为通过应用这些变换，
我们可以生成更多的训练数据。
我们将获得新图像
这就是为什么我们将此称为图像增强的原因
我们基本上增加了多样性
你知道 训练集图像的多样性
这就是什么
现在我们将进入如何做，进入如何做
我将带你进入keras api
因为你必须看到它
你知道，就像我们在scikit learn中做的那样
我将向你展示并引导你通过keras api，找到适合这个任务的工具
我们将使用这个
所以让我们打开一个新标签页
这里我们走，并在搜索栏中
让我们只输入keras，就像这样
按回车键，然后让我们只获取第一个链接
只有一个keras
当然这是python中用于深度学习的库，由franz wai开发
顺便说一句，这是一个非常有才华的法国数据科学家
让我们转到api文档
现在，我的朋友们，欢迎来到keras api
这是我最喜欢的深度学习库
它绝对棒极了
现在我们想去的地方当然是数据预处理
这当然包括三件事
实际上你必须知道
图像数据处理，这是我们即将使用的
然后是时间序列数据预处理
还有文本数据预处理
你也可以做一些深度NLP
你知道使用深度学习与keras进行自然语言处理
但现在当然我们在寻找图像数据中的东西
让我来告诉你那正是什么
我们只需要滚动下来
嗯 实际上你已经知道这是什么了，因为我们已经导入了类
它就在那里
我正在谈论 当然关于图像数据生成器类
它将确实生成带有实时数据增强的张量图像数据批次
这正是我刚刚解释的
我还没有提到批次
那是因为你知道我们会创建不同批次的
实际上三个两个图像
这些图像将是原始图像
或者你知道的增强后的图像
我们应用变换后的图像
在我们应用变换后
说到应用这些变换
嗯 我们将用这张图像数据生成器类来做
在这里你会找到所有参数
你知道大多数都对应不同的变换
我可以告诉你我们会使用缩放变换
它包括在图像上放大或缩小
我们也会使用水平翻转
它包括将图像水平翻转
然后我们也会使用这个
剪切范围
这是一些变换
你可以在线查看
但没有必要了解所有细节
只需知道这是一些几何变换
如果你想深入了解，实际上这是一些变换
但就是这样 这是这三种变换
我们将使用剪切范围
缩放范围和水平翻转
现在我可以肯定有些人会问
我们为什么使用这些变换
嗯 我会诚实地告诉你
我使用它的原因是因为我简单地从keras中复制了
你知道 代码片段示例
就在下面
正好在这里
这是使用图像数据生成器类的代码片段示例
正如你所见
我们使用剪切变换
缩放变换和水平翻转变换
我们将做同样的事情
但当然，你可以尝试一些其他变换
谁知道呢 也许你会得到更好的准确性
好的 但让我们相信这一点
实际上我相信这一点 因为当然我在我们的未来的cnn上试过了
我们即将构建 你将会看到最终的结果会绝对令人惊叹
好的 那么我们就拿这个
我们就拿这段代码片段
你知道 实际上获取那些将应用这些转换的工具
当然，我们还需要将工具连接到我们的训练集
所以回到实现中
嗯 让我们把这里粘贴
正如你所看到的，创建了一个我们称之为训练数据生成的对象，即图像数据生成器类
因此，训练数据生成器是图像数据生成器类的一个实例
它代表了
当然，这是工具，它将对训练集的图像进行所有转换
还有一个我没有提到的
你知道，我提到了并解释了这三种转换
但我们还注意到这个rescale等于255/2
你能猜到这是关于什么的吗
你知道，我们已经在很多经典数据集中看到过这个了
嗯 这当然关于特征缩放
这将对每个像素进行特征缩放
通过将其值除以255
因为记住每个像素的值在0到255之间
通过将所有像素值除以255
我们确实将所有像素值缩放到0到1之间
这确实像归一化
再次强调，特征缩放对于神经网络是绝对必要的
你知道在训练神经网络时
所以这基本上就是特征缩放
这就是要进行图像增强的变形，用于训练集的图像
我提醒这是
为了预防过拟合
最后 你可以尝试实际上
你知道未来的训练将没有这些
你会看到我所说的过拟合的意思
很好 那不是全部
你知道在训练集上
我们需要处理的
当然现在将训练数据生成对象连接到我们的训练集
你知道到我们的训练集图像
这就是对象
所以我们这样做的方式是
我们将 当然回到keras api
因为确实这样做的方式就是取这个代码
这将实际从你知道我们的目录中导入训练集
同时创建这些批次并调整图像大小
你知道 如果我们需要为了减少机器的计算量而调整图像大小
以便减少计算量
这就是我们将要做的
因为最终我们会看到，使用较小的尺寸仍然可以获得惊人的结果
所以让我们开始吧
再次，我会解释这段代码
并且大部分我们需要正确地修改它
这样我们就可以根据我们的实际情况来调整它
那么我们一步一步来
这就是你想给你的训练集起的名字
你在笔记本中导入它
我们保持常用的名字
我们将其命名为训练下划线集，就像以前一样
然后我们确实使用我们的训练数据生成器对象
这是图像数据生成器的实例
然后我们从这个对象中调用这个类的一个方法
因为这个类中的每个类都包含方法
并且其中之一就是这个流目录
它将简单地知道将这张图像增强工具连接到你的训练集图像上
让我们看看不同的参数
首先这是一个指向你训练集的路径
当然，我们必须更改这个
因为我们的数据集路径不同
这是一个完整的文件夹
我在这个部分的开始时与你分享了这个文件夹
这也是根文件夹
你知道，这是文件夹的基本文件夹
你知道这条路的开始
所以现在为了能够访问训练集
我们首先需要指定我们要进入这个数据集文件夹
然后进入这个训练集文件夹
这正是通往训练集的路径
因此，你知道在这个流的目录参数中
我们只需要在这里将数据替换为dataset
然后在这里将train替换为training set
好的 这是通往训练集文件夹的简单路径
从我们的目录文件夹的根目录开始
好的 很好现在
下一个参数目标大小
这确实是你图像的最终大小
有一天你知道会被输入卷积神经网络
实际上我尝试过一百五十乘以一百五十
实际上这确实让训练变得非常非常长
所以我实际上想减少这一点
你知道 六十四乘六十四
这是完全可以的
这将使训练速度更快
但我们仍然会有惊人的结果
你会在最后看到
然后批次大小是
你知道批次的大小
这意味着我们想在每个批次中拥有多少图像
32是一个经典的默认值
我们将保持不变，这将是完全可以的
最后，我们必须指定类模式
它要么是二进制的，要么是分类的
当然，由于我们现在有一个二进制结果
你知道 猫或狗
我们必须选择 当然
类模式等于二进制，完美
这完成了训练集的预处理
我们完成了数据处理的第一步
现在我们将进入下一步，预处理测试集
当然，为了尽可能高效，我们总是尽可能高效
嗯 我们将回到keras api
我们将使用这个代码行
获取相同的图像
数据生成器对象
将变换应用于测试图像
但请小心
我们不会在这里应用相同的变换
比如剪切 缩放和水平翻转
因为我们当然不想触碰测试图片
因为它们就像新图片
就像我们在生产中部署我们的模型时
因此当然我们必须保持它们完整
就像原始的
然而，我们必须对他们做的事情确实是重新缩放他们的像素
这和以前一样
你知道 记得当我们对训练集和测试集进行特征缩放时
我们在训练集上使用了fit transform方法
但在测试集上只使用了transform方法
这当然是为了避免测试集的信息泄露
而这里情况完全相同
我们必须通过不应用任何变换来保持测试集的图像完整
然而，我们必须对它们进行特征缩放
因为再一次 CNN的未来预测方法必须应用于相同的缩放
与训练集上应用的缩放相同
所以你看这和之前一模一样
只是之前我们用了一些不同的课程
但归根结底，这些都是相同的工具，对吧
所以让我们开始 让我们把我们的实现放在新的代码单元格中
所以我们要把它粘贴过来
我们将保留对象的名称，这是完全可以的
然后，同样的，我们将回到这个
我们将得到完全相同的结果
这将实际将我们的测试集图像导入到我们的笔记本中
好的 所以现在让我们粘贴它，让我们做必要的更改
实际上 请按
暂停视频并自己做出更改
我相信你会成功完成
因为这与以前完全相同
好的 所以现在让我们一起做
我想做的第一件事就是改变它的名字
这就是将要包含测试集的变量名称
为了与前面一致
我们仍然将其命名为测试集
所以测试集
这是正确的 我们将测试数据称为gen这里
这将仅对测试集中的图像像素应用特征缩放
然后我们调用相同的功能flow从目录中访问测试集
这里再次我们需要将数据这里替换为数据集并且验证
你知道 记住，我们现在想要得到通往测试集的路径
因此，那个数据集和测试集都是正确的
所以这里我们需要用测试集来替换验证集，这样就好了
然后当然我们需要有相同的目标大小
因为基本上，砖块方法必须在完全相同的格式下被调用
用于训练图像的那个
所以，在这里我们需要得到与训练集相同的大小
因此六十四乘六十四并且使用相同的批处理大小
基本上，我们的模型将在三张两张图片的批次上进行评估。
当然，同样的类模式二进制
好吧 就是这样 我们已经完成了数据预处理
这非常不同
这实际上是全新的
但我们认出了一些相同的过程步骤，这是我们之前做过的
所以我现在非常兴奋，因为我们可以继续进行令人兴奋的部分
那就是关于构建CNN
是的 我们现在准备好进行第二部分了
我们将分几步来解决这个问题
所以请确保为这做准备获取足够的能量
一旦这种情况发生
请加入我的下一节教程来攻克时间部分二构建CNN 在此之前享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p23 13. Step 3 - TensorFlow CNN Convolution to Output Layer for Vision Tasks.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p23 13. Step 3 - TensorFlow CNN Convolution to Output Layer for Vision Tasks

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们 欢迎来到本项目的第二部分
我们将一起构建卷积神经网络
更具体地说，我们将构建这个新的人工神经网络的整个架构
实际上，它将从我们的人工神经网络开始
因为卷积神经网络仍然是一系列层
因此，我们将在这里初始化
我们的cnn，记住，这是同一个序列类
这是我们的第一步
我们要去的地方，不仅会称之为顺序类
但主要是创建那个cnn变量
这将精确地代表这个卷积神经网络
并且cnn变量将再次作为顺序类的一个实例创建
这允许创建一个人工神经网络作为层的序列
所以现在记得我们如何才能访问到这个类
首先我们需要调用tensorflow
它有一个快捷方式tf
我们从其中调用keras库
我们从其中获取到models模块
我们从这里称之为顺序类的那个，我们精确地与以前一样
这确实初始化了r cnn作为一个层的序列
与计算图相反，很好
现在我们一步一步地使用这个
你知道 添加方法添加不同的层
无论是卷积层还是全连接层
最后输出层所以我们将依次使用
现在添加方法从tip one卷积开始
所以现在在新的代码单元格中
首先我们会使用我们的cnn对象
我们的卷积神经网络，我们将调用它
当然，我们会使用add方法添加我们的第一个卷积层
我们现在想要添加的当然是一个卷积层
这个卷积层仍然是某个类的对象
这个类当然是conf two d类
这个类就像构建全连接层的dance类一样
属于同一个模块
即来自cares库的layers模块
自从tensorflow 2.0以来
首先，我们将获取tensorflow
通过它我们可以访问keras库
通过它我们可以访问layers模块
然后我们就可以开始了 通过它我们可以调用conf to d
然后创建类
然后我们添加一些括号
当然，因为这是一个类
在里面我们有两个输入
三个重要参数
这些是过滤器吗
这基本上就是特征检测器的数量
你想应用到你的照片上
你知道要检测特征
这些确实也被称为过滤器或核
如果我们向下滚动这里
实际上你可以看到这些参数的所有信息
正确，过滤器参数
卷积中的输出过滤器数量
嗯 这基本上就是特征检测器
所以这是我们的第一个参数
然后我们也会指定一个核大小
实际上我已经准备了一些幻灯片，我为了向你展示
所以 基本上这就是过滤器
这个过滤器参数会告诉我们我们想要多少特征检测器
我们想要多少过滤器
核大小正好是
你知道那个特征检测器的大小
意思是行数
这也是列数，因为它通常是一个正方形数组
你知道，所以
例如 如果我们选择一个大小为三
实际上这就是我们要选择的大小，嗯
这意味着我们的特征检测器的大小将是3x3
好的，就这么简单
然后我们有一些其他参数
但是别担心
我们将保持其余参数的默认值，因为这将很好
然而
当然我们不会保留那个激活参数的默认值 这对应于
当然 激活函数 因为确实
你知道，在一般规则下 只要我们还没有到达输出层
我们更愿意得到一个激活函数
矩形激活函数
因此对于这个激活
我们将再次选择relu参数名称
这对应于矩形激活函数
最后我们有一个最后一个参数要输入
并且这里不显示这里
因为这一个被隐藏了
但你实际上可以在这里看到它
这是你添加第一个层时输入形状
无论是卷积层还是密集层
你必须指定你输入的形状
在这里，因为我们一直在处理彩色图像
因此，在三维空间
对应于颜色的rgb代码
因为我们实际上在部分一中将图像缩放
我们的图像缩小到64x64
那么 我们的图像输入形状将是64
64和3
如果我们在这里处理黑白图像
我们会有一个而不是三个
但我们处理的是彩色图像
因此这就是我们的输入形状
六十四和三
这是我们必须输入的基本参数
好的，这就是我们 让我们输入它们
从过滤器参数开始，好的
那么问题是
我们要多少个特征检测器
嗯 我们只是想选择一个经典的架构
你可以找到许多架构
卷积神经网络可以在线找到
我们将选择一个经典的架构
我当然在我们的图像上尝试过它
而且它效果非常好
这个架构包括在第一个卷积层中有三个两个滤波器
然后在第二个卷积层中有另外三个两个滤波器
好的 那么我们就在这里选择
过滤器等于32，随意
当然可以选择另一个参数值
我提醒这是艺术家的工作
你可以自由尝试
任何你喜欢的建筑
你可能最终得到的结果比我们即将得到的更好
好的 过滤器等于32
这是第一个参数
现在来说第二个参数
正如我们所说，它将在这个分数大小上作为内核
这个 正如我们所说，我们希望有三乘三的维度
我们只需要指定三个
正如我们所说，我们希望确保我们有一个归一化激活函数
所以对于新的激活参数
我们将选择引号中的
正是之前的relu激活函数
最后，我们需要为最后一个参数指定值
我们需要指定我们图像的输入形状
我们需要在方括号内输入一个数组
我们完成了
我们已经将我们的图像调整为64x64的尺寸
因为我们处理的是彩色图像
我们需要在这里输入3而不是1
这就是我们的输入形状
就是这样
这将添加一个卷积层到你的CNN中，并且已经初始化
到目前为止，这是一个序列层的好方法
现在我们可以继续进行第二步，池化
让我们创建一个新的代码单元
这当然包括应用池化
更具体地说，我们将应用最大池化
正如你在直觉讲座中所看到的那样
所以我们需要从我们的CNN对象开始
我们将调用一个新的方法
但这真的新吗
你认为呢 我们需要再次调用add方法
嗯 是的
实际上我们需要将池化层添加到我们的卷积层中
你知道，这是我们在层序列中的下一步
好的 我们再次调用add方法
然后里面
我们将创建一个最大池化层对象
你知道，这是一个特定类的实例
这个类叫做MaxPool2D类
这个类属于相同的模块，即layers模块
好的 我们将复制并粘贴这个
我们将替换Conv2D类
我们将使用MaxPool2D类
我们需要指定两个关键参数
它们是池的大小
让我看看这代表什么
这是一个完整的卷积过程
你知道，特征检测器应用到输入图像上
产生了特征图
这就是我们所做的
现在我们继续第二步
我们有特征图
这是我们之前的卷积的结果
我们对特征图应用最大池化
得到池化特征图
你知道，这是我们卷积层的特征图
我们已经完成了
在我们应用最大池化之后
当我们这样做时
你知道这里有一个小框架
它将获取四个单元格内的最大像素
你知道四个像素
并且那个池大小参数
我们将在这里输入的恰好是那个框架的大小
你知道，再一次是一个正方形
所以我们只需要指定宽度
或者你知道高度
所以基本上这里
在这个例子中两个
好的，嗯
你知道，说到两个
这正是池的大小
我们将选择 这是我推荐的一个
当我们应用最大池化
好的 然后让我们看看另一个重要的参数
步幅是
所以很有趣
我们再看一下我们的幻灯片
所以我将转到下一张幻灯片
让我们看看这张图片向右移动了多少像素
让我们看看
实际上它向右移动了2个像素
你知道，而不是从这张图片跳到那张图片
这将是一个滑动1
我们直接从这张图片跳到了那张图片
好的，这有道理
在应用最大池化时
因为我们只想得到每个正方形的最大值
这里就是像素
所以推荐的滑动步长再次是2
那么我们确实在以2x2的像素滑动
当我们到达
你知道特征图的边缘这里
你知道这里有额外的空单元格
嗯 实际上你可以选择两种不同的方式
这与那个参数相对应
这是填充
默认值是有效的
但另一个值是一样的，也很好
区别在于，你知道有效的填充
你将忽略这里的其他两个单元格
与相同的填充
你将添加一个额外的列，只有假像素是等于零
但不必太担心这个填充
我实际上尝试了两个值
这并没有改变最终结果
所以我建议保留默认值
但是滑块很重要
现在我们正在两个一组地滑动
好的 让我们这样做
让我们将我们的参数输入到最大池化类中
首先一个
正如我们所说 池的大小
我们进去想要正好像幻灯片上所示的二乘二框
我们只需用参数input 2来指定
然后第二个参数是步幅
你知道关键的一个
我们希望每两像素移动那个框
因此我们将选择步幅为二
好的 这成功地应用了最大池化就这么简单
你可以复制粘贴这条命令
当你想对你的cnn应用最大池化时
实际上说到这
你知道现在我们想添加一个第二卷积层
并欣赏我将如何高效地做这件事
首先我将创建一个新代码单元
然后我将复制那个单元
然后将其粘贴到这里
对于池化
复制那个单元
然后将其粘贴到这里
那么根据你的说法我们是否需要更改这里
或者我们可以保持原样
嗯 我们不能保持原样
实际上我们只需要删除那个输入形状参数
因为只有在你添加你的第一个层时才需要输入它
你知道为了自动将第一个层连接到输入层
这自动添加了输入层
但是我们现在已经有了我们的第二个卷积层
所以这很好
我们可以删除它
现在完美
这添加了一个带有最大池化应用的第二个卷积层
现在我们可以继续进行第三步，展平
这将包括
当然 展平所有这些卷积和池化的结果，将其展平为一个一维向量
这将成为未来全连接神经网络的输入
就像我们在上一节中构建的那样
好的 那么我们开始吧
让我们实施步骤三，扁平化和往常一样
你知道我们需要从我们的cnn对象中获取
我们从which我们将再次调用ad方法
因为我们将要创建那个扁平化层的方式再次
通过创建一个特定类的实例
并且那个特定类是扁平化类
你知道 keras将
自动理解
这是多层卷积和池化结果的体现
它将被压平成一个一维向量
我们所需要做的就是指定这一点
我们希望应用压平操作，为此
我们需要再次调用层模块
通过keras库 来自tensorflow
我们从中导入
这次导入flatten类，好消息是
这个类实际上不需要任何参数
所以这简单地执行了第三步，展平
我们可以直接进入第四步，全连接，好的
所以，现在轮到你了
你可以自己动手做
所以我希望你请点击
视频暂停
因为我们现在处于与以前一样的情况
你知道 构建一个完全连接的神经网络
所以你知道如何做
我希望你给那个展平层添加一个全新的全连接层
它现在只不过是一个一维向量
它将成为全连接神经网络的输入
首先这样做，然后我们将在几秒钟内实现解决方案
好的，很好
让我们这样做 所以你知道如何做这一点，首先我们创建一个新的代码单元
然后我们再次取我们的cnn神经网络
我们从其中调用add方法
因为我们即将添加一个新层
这是一个全连接层
它还属于tf keras layers
我已经复制了它
所以我可以直接粘贴到这里
这次使用tense class perfect
现在进入一些新的括号
我相信你已经知道应该将什么作为参数
首先 记住我们有units
这是您希望在此新的全连接层中拥有的隐藏神经元数量
而且现在我们正在处理一个更复杂的问题
你知道计算机视觉比数据挖掘要复杂得多
我们仍然使用经典的数据集
嗯 我们将选择更多的隐藏神经元
我们将选择128个隐藏神经元
但是如果你选择了与以前一样的数字
你知道在我们之前的ANN部分
我肯定这是完全没问题的
我相信你会得到很好的结果
但我们可能在最后通过大量的神经元获得更高的准确性
因此让我们在这里选择
单元等于128个
并且第二个参数是
当然，激活函数
再一次，我的建议是
只要你还没有到达最终的输出层
我建议使用矩形激活函数
这正是我们在这里通过激活参数来指定的
记住，矩形激活函数的代码名称是relu，好的，完美
添加一个全连接层
最后第五步
你看到我们在这里多么高效
这是第五步 我们需要添加一个最终的输出层
它将仍然与前一个隐藏层全连接
因此我们将再次
使用密集类
因此在新的代码单元格中
我将实际
你知道 把这些都拿走
然后把这里和里面的东西粘贴到这里，我们只需要替换两件事
这两件事是这两个参数的值
因为确实，单位的数量
你知道 最终输出层的神经元数量肯定不是128
但你告诉我，好吧
实际上当然只有1
这正是我们在做二分类之前做的事情
因此我们只需要一个神经元来编码那个二分类
0或1 或者你知道
猫或狗 g
因此我们只需要一个神经元
对于激活函数
记住对于输出层
不建议使用矩形激活函数
而是使用sigmoid激活函数
这是因为我们当然在做二分类
否则如果我们在做多类分类
我们将会记住一个softmax激活函数
但是，我们已经完成了 这将增加一个很好的输出层
这将在最终优化结果
现在我必须再次说
向你表示热烈的祝贺
因为，你已经完成了
你刚刚构建了一个卷积神经网络
我们已经完成了第二部分
我们可以直接进入第三部分
训练CNN
当然，这包括
让这个大脑
你知道的 这个人工大脑
有一些眼睛
非常聪明，能够识别图像中的猫或狗
所以现在我们值得好好休息一下
确保在下一个教程中充满活力
当你准备好的时候，我们会
一起努力 第三部分 训练CNN
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p24 14. Step 4 CNN Training - Epochs, Loss Function & Metrics in TensorFlow.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p24 14. Step 4 CNN Training - Epochs, Loss Function & Metrics in TensorFlow

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们
欢迎回来，实现这一部分
主要是欢迎您参加第三阶段的卷积神经网络训练，在之前的教程中
我们构建了AI的大脑，包含了它的眼睛
你知道的 多亏了卷积层
现在我们要让这个大脑通过卷积神经网络的训练变得更加聪明
在所有的训练图像上
同时，您可以看到
我们将在测试集上对我们的模型进行评估，通过多个时期
我们知道我们将使用CNN进行训练，训练两个五个时期
每个时期都将看到我们的模型在测试集图像上的表现
这与我们之前做的训练不同
因为我们总是将训练和评估分开
但这里会同时进行
这是因为我们做了一些特定的应用
这是计算机视觉
好的 你准备好了吗
让我们开始吧 让我们从第一步开始，编译CNN，好的
所以在一个新的代码单元中，我们将编译CNN
这意味着我们将将其连接到一个优化器
一个损失函数 以及一些指标，嗯
你知道的，在这里我们又在进行二分类
因此，我们非常简单地将以相同的方式编译我们的CNN
正如我们在上一节中编译我们的ANN一样
因为我们仍然选择Adam优化器
你知道 进行随机梯度下降来更新权重
为了减少预测值与目标值之间的损失误差
然后我们会选择相同的损失
你知道，再次使用二进制交叉熵损失
因为我们正在做完全相同的任务，二分类
然后对于指标也是一样的
我们将选择准确率指标
因为这是你知道的 衡量分类模型性能的最相关方式
这正是我们cnn的情况
因此，我们需要编译cnn
好的 这将是一块蛋糕
因为我们将做与以前一样的事情
我们将从我们的cnn开始
我们将调用compile
这将需要输入
首先我们的优化器，我们将选择adam优化器
然后是损失函数，我们将选择二进制交叉熵
最后，最终论据
我们选择的指标
我们只选择一个
但请记住，我们有选择多个指标的权利
但仅仅准确率就可以了
因此，在这些方括号中，我们将输入引号中的
这是准确率，完成，这个编译成功，cnn到优化器
损失函数和指标，完全相同
然而，现在要在训练集上训练cnn，同时在测试集上评估它
同时评估它
它不会再和以前一样
但再次非常相似
让我们检查一下
让我们创建一个新的代码单元格
现在你实际上可以猜测前两步，它们总是一样的
第一步是从中取出
当然，我们的cnn
这就是第二步
我们需要调用什么方法呢
再次，这永远不会改变
这是当然fit方法
fit方法总是用于在训练集上训练cnn
好的 所以这次输入是什么
嗯 第一个输入总是一样的
它将是当然集
你知道你将在这里训练你模型的数据集，当然cnn
那就是当然训练集
那个参数的名字很简单x
因此，我们将指定x为
你知道我们的训练集
那就是我们在第一部分创建的完全相同的训练集
你知道，就在这里的训练集
那就是我们应用了这个图像数据生成器工具的训练集，确实执行了图像增强
好的 那就是我们的训练集
这是我们fit方法中的第一个参数输入
好的 然后下一个参数，好的
所以下一个参数是这次你知道的差异
与我们之前做的不同之处
所以它必须做 当然，考虑到我们不仅是在训练集上训练CNN
但同时也在测试集上评估它
并且第二个参数正好对应于这个
在这里我们必须指定
验证数据
那就是参数的名称
但是那是我们当然想要评估我们的cnn的集合
这就是测试集，它将成为参数的值
但那个参数的名字是
正如我刚才所说
验证_数据
这当然等于
当然再次等于测试集
那个确切的测试集
我们在第一部分中创建的
在预处理测试集时
这个当然没有应用任何转换
只有特征缩放
好的 测试集很好
现在我们有一个最后的参数
当然你可以完全猜到它是什么
这当然是在训练深度神经网络时不可避免的参数
我正在谈论的当然是epochs参数
这是epochs的数量
嗯
你知道为了向你证明我选择了什么数字
我实际上从10个epochs开始
我发现准确率没有收敛
然后我试了15个epochs
因为你会看到1个epochs实际上很慢
你知道实际上比之前的神经网络的epochs要长得多
你知道a n所以我从10开始
还不够
然后15个仍然不够 你知道仍然没有收敛
然后25个和25个是完美的
我有一个几乎收敛的准确率
不仅训练集
也在测试集
你会看到的所以在epochs这里
我们将选择25
如果你有时间
请随意增加
你知道如果你想让你的电脑运行一个小时或更长时间 在这里使用25个epochs
它将很好
它将只需要10到15分钟 所以我们会得到很快的结果
好的，实际上
就是这样
这就是我们需要对cnn进行训练
在训练集上评估它 而
实际上
这就是全部
我们需要训练我们的cnn
在测试集上，完美无缺
我们打破了第三部分
现在我们可以继续前进到第四部分
在那里我们将做出我们的单一预测
我提醒，这 将包括在我们的模型上部署两个单一预测文件夹的图像
这张图片是我们的模型需要识别出有狗
当然，我们的模型需要识别出有猫
这张图片
希望它是正确的
但在下一节课中我们不会得到预测
我们将在下一节课中得到他们
因为我们将从我们的jupyter笔记本中运行我们的实现
因为我们不能在谷歌协作中做
数据集太大
好吧，一旦你准备好第四部分
让我们这样做 直到那时享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p26 16. Hands-on CNN Training Using Jupyter Notebook for Image Classification.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p26 16. Hands-on CNN Training Using Jupyter Notebook for Image Classification

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                好的 我的朋友们
所以现在我们将要进行一个非常激动人心的教程
因为我们即将观看演示
你知道我们的AI演示版本是首先构建的
然后进行训练，最后做出我们的单一预测。
所以这就是我们在前一个教程中停下来的地方
基本上所有实现都已经完成
现在我将引导您了解如何在Jupyter Notebook中运行这个。
因此，我做的第一件事将是下载并安装一切
我们需要使用jupyter notebook
如果你已经安装了anaconda
你知道它包含jupyter notebook
如果你已经在你的机器上有jupyter notebook
那么请随意跳过这个教程的前五分钟，从第五分钟开始
好的 我们将开始使用jupyter notebook
其余的人请跟着我
我将引导你通过anaconda的安装
因此jupiter notebook
那么我们在新的最喜欢的浏览器上打开一个新的搜索标签，然后在搜索栏中
让我们在安娜康达那里输入。好的，安娜康达
然后我们将去第一个链接
安娜康达现在变得非常流行，我们将去
开始并安装安娜康达个人版
然后你可以点击这里下载
然后你将选择适合你系统的安娜康达安装程序
无论你是使用Windows、macOS还是Linux
我在macOS上
所以我将选择这个
你将会安装图形界面
不是命令行安装程序
所以图形安装程序，你将使用Python 3.7版本
不是Python 2.7对吧
所以只有这一行在这里
所以选择你的系统
点击文件，这将下载anaconda
你知道安装者
几秒钟后，您将了解在您机器上的安装程序
很可能在你的下载文件夹中
这对我有好处
让我们把这个下载删除
现在我们去我的机器那里，好的
这是我的下载文件夹，安装程序就在这里下载的
确保你能找到他
然后双击它
这将启动anaconda的安装
你可以直接点击继续
只需点击 同意并继续
你可以读出来 如果你想的话，然后安装
这将安装anaconda
这将只需几分钟
不超过一分钟
你知道
好的 不到一分钟 我们做到了，很好
所以现在anaconda正在安装
让我告诉你一些关于anaconda的事情
这基本上是一个包含你可以在python中编码的几个想法的平台
甚至R，因为你会看到它现在包含我们的工作室
但它包含的python id包括jupyter笔记本
还有蜘蛛，蜘蛛是另一个伟大的python编码id
但我们将使用jupyter笔记本，因为我们已经习惯了
你知道的ipo y b格式，这是我们在google collab中使用的格式
但这次，因为我们有一个无法在google collab中导入的大型数据集
好吧 我们将使用jupiter notebook运行这个，好的
所以让我们看看现在我们在哪里，还在安装中
你知道运行包脚本
但你的机器上将不会有任何问题地安装anaconda
好吧 所以这里只是为了确实能让你访问你的下载文件夹
所以 当然你会点击确认
然后它应该现在顺利前进
让我们看看
完美，搞定
现在我们有一个图标，你可以点击它
继续完成安装
然后点击关闭
然后你可以选择保留安装程序或者删除它
根据你的需要 我就保留吧
很好 现在我们有了anaconda
然后这不算完
我们还需要安装几样东西
不幸的是这些东西是tensorflow库和keras库
我提醒一下google collab的美妙之处
这也是我想要在google collab中编写一切的原因
是因为我们不需要安装任何东西
因为所有的库和包都已经预装好了
除了那些罕见的
但在jupyter
笔记本或蜘蛛或其他anaconda id well
我们必须手动安装软件包
这正是我要向你展示的
对于mac和Linux用户
请打开您的命令行界面
Linux用户 您会很容易找到他们，而mac用户
您可以同时按下command和空格键
然后在聚焦搜索中输入terminal
这将打开您的命令行界面
对于Windows用户
没有理由 我没有忘记您
Windows用户 请前往
您知道在显示器的左下角
请点击那个窗口按钮
然后在您的程序列表中找到anaconda
在anaconda标签下，您将找到命令提示符
然后请点击它
这将相当于您的命令行界面
您可以在此运行命令从网上安装软件包
所以现在我们应该在同一页面上
您知道的，Windows用户 mac用户或Linux用户
我们将安装tensorflow和keras
您将看到它仍然非常快速和容易
因为我们在这里需要输入的简单命令
以安装tensorflow和keras如下
我们需要分别输入它们
让我们从tensorflow开始
我们只需输入pip
然后安装和tenser flow
然后只需按回车键
这将从网上下载并安装tensorflow到您的anaconda环境中
所以现在正如您所看到的，它正在下载并安装它
所以请不要担心所有这些
这是完全正常的
看，正在安装收集的软件包 包括确实tensorflow
它不仅安装tensorflow
而且还安装了我们称之为依赖项，它们是与tensorflow一起工作的
但是请不要担心所有这些
这将只安装tensorflow
这正是我们需要的
好的，安装完成，正如我们所见，已成功安装了所有这些依赖项
包括tensorflow 现在要安装keras，我们将做同样的事情
我们将使用pip install keras
然后按回车键
这将从网上下载并安装keras到您的anaconda环境中 我们将进入pip，然后安装并安装keras，然后按回车
这将在你的机器上安装keras，好了，已成功安装keras
这就是我们刚刚安装的版本
你可能会得到一个不同版本
如果你在这个课程开始时
在我录制之后
完成了终端
没问题 我们不再需要处理它
我希望这不会让你太震惊
你知道那些第一次使用它的人
我知道开始时可能会感到惊讶
但这确实是安装包的经典方式
当你不在谷歌协作上工作
然后你可以关闭终端
然后我们就去那里
我们现在准备好最后打开anaconda和大多数打开jupyter笔记本
所以我们将在要么
你知道mac用户应用程序列表
或Windows用户的程序列表以及Linux用户的相同位置找到anaconda
所以在mac上这里是anaconda
所以我们只是双击它
这将打开它
我可以回到我的桌面
因为我知道我的桌面在这里
因为anaconda正在打开
不久我们应该看到这美丽的平台
非常用户友好
包含你可以用python编码的所有不同的环境
好的 加载应用程序
再来一次，欢迎来到anaconda
正如我所说，你有几个
你有这个RStudio用于R
但你有几个用于Python的
包括Jupyter
笔记本和蜘蛛
正如我们所说，我们将在Jupyter笔记本上运行我们的实现
所以我们将点击启动所有
这将启动Jupyter笔记本
这将自动在新标签页上打开它
你会看到它应该在几秒钟内弹出
欢迎来到jupyter notebook
这就是你的机器
你会认出你的机器的文件夹
当然，你现在将前往包含数据的文件夹
你知道数据集在哪里
你知道你在这次实践活动的开始时下载的数据集在哪里
请记住，我的是在桌面上
这就是文件夹
你知道第40节卷积神经网络
所以我们点击它，在里面，正如你所注意到的
我只保留了数据集
我移除了那两个之前的实现
它们在那个文件夹里
现在我想做的是实际上取我们的精确实现
我们在这次实践活动中编码的
我将通过点击文件来下载它
然后下载ip y和b
确保取ip y和b
因为这是Jupiter笔记本使用的格式
好的，我将关闭这个
现在我们将去下载的地方
这意味着在下载文件夹中
我们将把它放在这个文件夹中
你知道，包含数据集在这里的文件夹中
你必须把它放在同样的文件夹中
这很重要，因为你必须在Jupyter笔记本中运行这个代码
在同一个包含数据集的目录文件夹中
这就是为什么这很重要
所以这就是我们实际编码的精确实现
我们在实践活动中一起编码
现在我们将检查它是否工作
通过运行每个单元格来检查
让我们这样做 让我们回到jupyter笔记本
它就在这里
好的 现在我们确实得到了我们的实现很好
所以我们只需点击它来打开它
欢迎来到卷积神经网络的实现
现在现在是真正的表演时间
因为我们唯一要做的就是点击这个运行按钮
单元格一个接一个
甚至技术单元格 你知道我们从头开始，让我们看看会发生什么
好的 你准备好了吗
让我清除所有输出
这是我们在谷歌协作中获得的输出
所以来做这个 我们可以点击内核这里，然后重启并清除输出
我们不会得到这些输出
我们将真正从头开始
好的，现在让我们这样做
三二一，go run
好的 所以这不会运行任何东西
因为这只是一个技术销售
再次运行 现在开始
所以我们要点击第一个单元格的第一次运行
这将导入tensorflow
这个星号意味着它正在运行
你知道单元格正在运行，当它运行完成后
我们将看到第一个数字1
这意味着单元格已成功运行
好的 我们使用tensorflow后端
这就是这个单元格的输出
为了使其正常工作
请确保运行
像我一样，运行tensorflow和keras的pip install命令
好的 很好
让我们检查一下版本 它还会是
你知道的，tensorflow 2.2.0
然后运行其余的单元格，就这样
现在我们进入第一部分
预处理训练集
现在运行这个单元格
我们将在输出中看到，我们确实导入并预处理了数据
你知道，通过数据增强，共有8000张属于两个类别的图片
狗和猫
好的 然后点击运行下一个单元格
预处理测试集
现在运行这个单元格
这次我们将得到属于两个类别的2000张图像
当然没有应用过图像增强
只应用了特征缩放，好的
现在进入第二部分
构建CNN，开始吧，首先
我们初始化CNN为一个层的序列
然后我们开始第一步
第一步，卷积
我们添加一个卷积层
然后池化
让我往下滚动一点
实际上正确
然后池化，在这里我们对第一个卷积层应用最大池化，好的完成
然后我们添加一个第二个卷积层
同时我们应用最大池化，完成
然后我们继续到步骤三
我们将所有这些卷积的结果展平到一个一维的单一向量
作为步骤四全连接神经网络的输入
这将成为步骤四全连接神经网络的输入
这将包含只有一个全连接层
我们将要运行的这个单元
现在让我再往下滚动一点
好的 让我们像这样滚动
好的 现在我们在构建我们cnn的最后一步
我们将所有这些连接到最终的输出层
这将包含最终的预测
所以让我们运行这个单元
就这样
现在我们已经完成了CNN的构建
一切都看起来很好 到目前为止，我们已经有了一个能够看到图像的眼睛的大脑
你知道 就像我们人类用眼睛做的那样
现在我们有了这个大脑和这些眼睛
是时候通过训练CNN来让这些眼睛变得聪明，以便在图像中识别猫和狗
就这样 现在我们进入第三部分
首先使用原子优化器编译cnn
它将执行随机梯度下降
这是最好的方法 然后使用二进制交叉熵损失函数
因为我们在做二分类，使用准确率指标
搞定了，现在我们的cnn已经编译好了
现在，我的朋友们
是时候进行训练了
你准备好了吗
接下来的部分将运行两轮五次训练
同时在测试集上我们会得到准确性
这将非常令人兴奋
因为我们将看到训练集和测试集的准确性都在增加
随着时间的推移
你准备好了吗
我不会让我们等太久
现在训练已经开始了
我们开始第一个epoch，共两个五个
在这里你可以看到损失
你知道准确性正在逐步增加
所以基本上这里二百五十
对应于你知道批次大小是三个两个的事实
我们有总共八千张图片
为了确保你知道三乘以二
二百五十等于八千
所以基本上你知道我们在批次中有32张图片
并且我们在每个时期内有二百五十个步骤
你知道 达到总共八千张图片
好吧 所以第一个时期已经完成
让我们看看结果 我们得到了61%的准确率
在训练集上要小心
在测试集上我们得到了67点
75%的准确率
这相当不错
好的 现在，其他时期正在运行
但正如你所看到的 这将需要一些时间
所以我将快速前进
伴随着一些激动人心的音乐
以便我们可以观察并主要欣赏结果
和进展
你知道 在加速模式下不断提高的准确性
好的 你准备好了吗
三二
一个行动
好吧，就在这里
我又回到了游戏中
我非常兴奋想看到最后的结果
在第二十五个时代这里，我们开始
我们在训练集上的最终准确率为89%
在测试集上的最终准确率为80%
这很好 我提醒你们，如果我们没有进行图像增强的前处理
你知道在第一部分
好吧 我们会以
你知道 你可以在这里尝试训练集的准确性达到98%
甚至99%
这显然表明过拟合
在这里测试集的准确性较低，大约70%
这就是为什么我坚持图像增强是绝对基础的
好的 所以训练已经完成，你看
你完成了第一次高级训练
再次祝贺你
现在我们
让我们在生产环境中测试我们的模型
你知道 通过制作单个图像的单个预测
好的 在我们运行这之前
让我们确保我们知道我们在预测什么
所以我们要回到我们的文件夹
就在这里 我们将进入我们的数据集
记住那些单个图像在单个预测文件夹中
我们将从这里开始
获取一个当然包含狗的图像
现在我们将检查我们的cnn是否能预测到
确实这个图像中有一只狗
你准备好了吗 让我们开始
它在哪里 它就在这里
好的 播放
现在 我们将首先运行这个单元来
你知道 获取预测
确保这里有猫或狗一
这与我们刚刚看到的图像相对应
现在让我们运行这个单元
现在我们即将在控制台打印最终预测
我们当然希望看到doug在输出中
你准备好了吗
三二一运行完美
我们的cnn预测图像中有一只狗
好的 第一次测试通过成功现在
让我们看看其他图像
这个当然包含一只猫
所以让我们在这个单个图像上部署我们的模型并检查
确实我们的cnn返回一只猫
所以要做这个 我们就需要
你知道 替换这里的图像名称为catdog two
然后我们可以再次运行单元
只需点击运行
现在我们将再次打印这个
以打印这个其他图像的新预测
让我们这样做 让我们希望确实我们在控制台输出中得到了猫完美
所以 我们的cnn得到了所有答案都是正确的
但如果我让它更加具有挑战性
你知道 因为我可能很狡猾
也许我在测试集中选择了图像
我已经检查过我们的cnn
能够正确预测
所以为了让它更具挑战性
我的想法是打开一个新的标签在这里
然后在搜索栏中
我想要生成一个随机数
我们将使用这个经典的谷歌工具来生成一个随机数
你知道谷歌的经典工具
我们将从我们的测试集中生成一个随机数
你知道 这个测试集包含新图像，这些图像用于训练模型
我们将从这个测试集中随机选择一个图像
并将其作为最终测试
你知道，这是我们的cnn
所以让我们看看测试集中的狗图像
从四千零一到四千
五千猫从四千零一到再次
五千 好的
让我们先从暗的开始
让我们生成一个随机数
你知道在四千到五千之间，让我们生成这个
我们得到四千六百八十九
好的 让我们得到这个图片
四六八九
这稍微有点低
好的 就在这里
四六八九好的
所以这将是非常具有挑战性的
我们的CNN可能无法识别出这是一个狗
让我们看看 所以我将那个图像
我刚复制并放入单次预测文件夹
我正在粘贴并重命名这个
我知道我要重命名这个猫狗
三，好的
这将是我们的第三张图片
现在让我们为猫生成一个新的数字，好的
四千五百三十八，所以在测试集中
让我们进入猫的文件夹，然后抱歉
再说一遍
四千五百三十八
是的 四千五百三十八
就在这里
好的 哇 又要面临挑战了
我们看到的只有一只猫的头
让我们看看
好的 嗯
我没有想到挑战这么难
但是让我们看看cnn会怎么做
所以我只是复制并放入单次预测文件夹
让我们粘贴
让我们知道
复制这个名
然后粘贴这里来替换那个为四
好的 所以让我们先在这个单张图片上部署我们的模型
让我们希望这次你知道它预测
一只狗
这就是
狗三 我害怕并且让我们玩跑
然后打印预测
道格
呜 嚯，太好了
我真的很害怕 因为你知道对于机器来说，图片中的狗是一只狗并不总是很明显
但那真的很好
好的
现在，这只特别的猫在这件红色礼物包装里
猫狗四 让我们希望我们的o能识别出它是一只猫
你知道对我们来说很明显
人类
但在这里我们只看到头
实际上 你知道，猫的特征
所以是的 让我们希望它会起作用，所以猫狗四
现在让我们播放细胞 我又害怕了
啊，优秀
所以百分之百
正确答案从我们的cnn
所以那太棒了
我真的很高兴它百分之百工作
那是因为你知道我们 毕竟在测试集上准确率为80%
这意味着确实10个预测中有8个是正确的
是的
即使图片很具有挑战性
你知道，不是很明显的狗或猫 嗯
我们的模型能做得很好
所以 我们的模型能做得很好
所以恭喜你
你刚刚构建了一个相当先进的人工神经网络
你知道卷积神经网络在技术上非常先进
祝贺你
你不仅建造了它
而且你主要成功地建造了它
它现在是一个非常好的猫或狗预测器，随意
你知道 通过生成随机数来玩同样的游戏并测试
一些其他单个图像
你可能会惊讶于
你知道 模型的预测能力
你刚刚构建的
所以我们在这里取得了伟大的进步，现在关于深度学习的部分我们已经完成了
所以我们将转向下一部分
关于降维
这对你和你的职业生涯非常重要
因为你知道你将与拥有许多许多元素的巨大数据集一起工作
所以你需要拥有正确的工具以减少你的数据集的维度
当然不会失去信息
你知道
允许我们学习特征与因变量之间的相关性的信息 所以这是一个非常重要的章节
我期待着在下一部分见到你 直到那时享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p27 1. PCA Algorithm Intuition Reducing Dimensions in Unsupervised Learning.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p27 1. PCA Algorithm Intuition Reducing Dimensions in Unsupervised Learning

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                欢迎来到第三节
在您获得实际经验之前，我们将介绍主成分分析（PCA）的基本原理
在实践练习中，我们将探讨PCA的实际应用
我们将探讨PCA背后的直觉
PCA被认为是最常用的无监督算法之一
它可以被视为最受欢迎的降维算法
PCA用于可视化、特征提取、噪声过滤等操作
在股票市场预测和基因分析等算法中也可以看到PCA的应用
PCA还用于噪声过滤
PCA在股票市场预测和基因分析等算法中也可以看到应用
仅举几例
PCA的目标是识别和检测变量之间的相关性
如果发现很强的相关性
那么你就可以减少维度，这正是PCA的目的
在高维数据中找到最大变异的方向
然后将其投影到一个较小的子空间中
同时保留大部分的信息
通常情况下，使用PCA
目标是减少D维数据集的维度
通过将其投影到一个K维子空间，其中K小于D
对于PCA的整体分解和总结，我们可以在这里看到PCA算法的主要功能是标准化数据
获取特征向量和特征值
然后按降序对特征值进行排序
从选择的k个特征向量构造投影矩阵w，并将原始数据集转换为
你可以进一步探索它
如果你跟随那个链接
但是有一件事我想在这里与PCA一起检查
我认为可视化真的很有帮助
如果我们访问以下链接
它将带我们到这一页
我们可以在这里查看2D和3D的例子
现在以2D的形式查看PCA
你可以开始看到关系以及如何在变量中实现PCA
在数据中
你也可以在这个网站上
拖动它们
拖动数据点以查看PCA
坐标 嗯，系统内的调整
但是，我认为有帮助的是3D的例子
与3D的例子
你可以实际看到关系
这个模型中的数据
现在将其与2D进行比较
你知道，在更高的维度空间中
显然它可以是一个更容易的可视化
我认为这对理解PCA在做什么非常有帮助
如果我们再次拖动数据点
只是为了测试
我们可以点击显示
重置PCA
然后我们会显示它
我们可以在这里看到PCA
实际上我们可以移动模型
因为它不在二维图上
我们可以在三维示例中可视化它
好的 所以总结一下PCA
PCA不像线性回归
尽管它可能看起来像
因为PCA不是试图预测值
PCA试图学习X和Y值之间的关系
它通过找到一组主成分来量化
我认为最好的方法是看可视化
你不需要比较二维和三维
我们之前看到的分析和可视化
此外 顺便说一下
PCA有一个弱点
它对数据中的外点非常敏感
但PCA被认为是最常用和最受欢迎的
我认为一旦你开始实际操作
你会更明白
如果你有任何问题
请告诉我们 享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p28 2. Step 1 PCA in Python  Reducing Wine Dataset Features with Scikit-learn.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p28 2. Step 1 PCA in Python  Reducing Wine Dataset Features with Scikit-learn

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们，欢迎来到这个关于时间维度减少的新实践活动
这并不是机器学习的一个分支
但是一个很重要的技术，需要了解如何处理
当你处理大数据集时
你知道有大量特征的大型数据集
并且你知道你想要通过减少维度来降低复杂性
这正是维度减少所涉及的
所以，在这个新部分
第九部分：维度减少
我们将构建三种不同的模型，能够执行此类任务
这些是第一个主成分分析
最著名的一个
然后是线性判别分析
最后是核主成分分析
我们将构建这些三个模型
每个部分一个
现在我们准备开始第一个，主成分分析
但在我们开始之前
让我们确保这里的每个人都在同一页上
我在这个教程之前给了你链接到这个文件夹
所以在文章里
确保连接到它
现在我们应该都在同一页上了
我们将进入第九部分：维度减少，好的
如我所说，你有对应于每个模型的三个部分
我们将从主成分分析开始，Pca
正如往常一样，我们将从Python开始
在这个Python文件夹中，你将找到两个文件
正如往常一样，首先是在ip y和b格式中的实现
现在再一次，我们将能够在Google Colaboratory上运行它
因为我们将使用经典数据集
说到这个，这是数据集
葡萄酒.csv
所以让我们打开它，让我解释这是关于什么的，好的
所以实际上首先你注意到，我们确实有很多特征
我没有选择一个具有几百个特征的数据集
因为这样我们会
你知道，在数据集中迷失方向
所以我只选择了一个具有多个特征的数据集 当然这些都是所有特征
从酒精到这一行
正如你所猜测的，每项特征都给出一种葡萄酒的某种信息
你知道，每行都对应于一种葡萄酒
对于每种葡萄酒，我们都有不同的信息
不同的特征
你知道
葡萄酒的特性 特征
特性
酒精含量
苹果酸
我不是葡萄酒专家
但这些是些葡萄酒
特性：单宁，酸度，酒精
镁，硫，酚类物质
类黄酮
不管怎样 所以你可以看到葡萄酒有很多特性
而这些特性适用于每种葡萄酒
好吧，这就对了
我正要解释因变量
对于这些每瓶酒
我们有客户群体
你知道那是最后一列，酒属于哪一类
好的 所以让我来解释在商业上会发生什么
首先这是一个数据集
我从UCI机器学习仓库中获取的
所以所有的荣誉都归他们
当然，这个惊人的数据集平台
然而，我在这个数据集中改变了最后一列客户细分，使其更具商业性
你知道，为了使这个案例城市更具商业案例研究
因为场景如下
假设这个数据集属于酒商
有许多不同的酒瓶要出售
因此有大量的客户基础
这位酒商实际上聘请了你作为数据科学家
首先进行聚类工作
这意味着在没有最后一列客户细分的情况下，我们首先有了所有这些特征
我们有所有这些功能，从酒精到专业线
这位酒商实际上要求您进行一些聚类
以识别出根据相似性分组的客户多样化群体
这些群体对应于他们偏好的葡萄酒
所以这里每个客户群体，顺便说一句，有三个
如果我们滚动下来
我们可以看到有三个不同的类别
或者 你知道 聚类
这些片段将对应于特定的客户群体
这些客户群体对相似葡萄酒有相似的偏好
这正是这些片段的内容
但这是第一次工作
如果你想 你可以自己享受并完成这项工作
但我们想进行维度减少
所以这是酒商交给你的第二项任务
这位酒商对你的第一次工作很满意
你知道 识别这三个部分
但现在业主希望
你知道 通过减少特征的数量来简化这个数据集
同时
业主希望您构建一个预测模型，用于训练这个数据
你知道 包括这些特征和因变量
这样，每当这个业主有新酒在其商店时，我们可以
部署这个预测模型
应用于降维数据集，以预测这个新客户属于哪个客户群体，从而我们可以预测这个新客户属于哪个客户群体，
然后，我们就可以向正确的客户推荐这款酒，
这就是我们要做的，
我们即将要做的就是一个推荐系统，
因为每款新酒上架时，
我们的预测模型会告诉我们，这款酒最适合卖给哪个客户群体，
你知道，这款酒会被哪个客户群体最欣赏，
这就是商业案例研究，
因此，我们的预测模型将为这款酒带来巨大的价值。
因此，如果这位业主能够建立一个良好的推荐系统
当然，它会优化销售
因此，企业的利润也会增加
好的 这就是案例研究的内容
现在我们将进入实施阶段
当然 因此，我打开了主成分分析文件
你可以选择用谷歌协作或Jupyter笔记本打开它
就像我们在前一节关于CNN的部分所做的那样
但是，我们继续 让我们用谷歌协作工具打开它，享受全新的实现
好的 这就是主成分分析的实现
这是以只读模式
所以，像往常一样 我们会创建一个副本，点击文件这里
然后保存到云端
这将创建一个副本
我们可以重新实现
这次不是整个实现
因为我会解释大多数单元格都是单元格
我们已经在前面做过了
你知道在很多分类部分
以及在第八部分的第一节
所以我们不需要重新实现一切
这将是浪费时间
我们更想关注降维
所以我们要做的就是
我会向你展示实现
当然 但我们将重新实现的唯一一行将是这一行，应用PCA
所以让我们立即删除它
不是技术销售，只有这一行
现在我将向你展示，确实
你知道所有单元格对我们来说都非常熟悉
因为确实我们从导入我们一百次做过的库开始，对吧
所以我们这里有三个基本库
然后我们导入数据集
与您在数据预处理模板中拥有的完全相同的代码
所以当然这里我只是放了数据集的正确名称
这是wine.csv
好的 然后你将认出数据预处理模板的下一步
这是将数据集分为训练集和测试集的完全相同的代码
然后我们应用特征缩放
正如你所知，大多数时候都是推荐的 所以我们当然分别
应用于训练集和测试集
这样就完成了数据预处理阶段
然后我们应用PCA
当然这就是我们将一起重新实现的单元格
然后让我就此删除所有输出
这样你就看不到它们
我希望当我删除它们时你闭上你的眼睛
但我希望你现在稍微闭上你的眼睛
我也会删除这个输出
因为实际上我们将使用的降维技术将使我们获得伟大的结果
只使用两个提取的特征，对吧
我们不减少现有的特征数量
我们是基于这些现有特征创建新的提取特征
所以我们最终将得到完全不同的新特征
我们称之为你知道的主成分
所以最后我们将有主成分一和主成分二
但我们继续我们的实现
在应用PCA之后，我们将一起重新实现它
训练逻辑回归模型在训练集上
我选择了逻辑回归模型作为我们分类工具集的第一个模型
但我可以选择任何其他模型
但你会看到用这一个我们将获得伟大的结果
但请随意选择其他分类模型
任何都将工作
但请注意，在训练您的分类模型之前，您应该先应用PCA，对吧
您希望在训练集上训练您的数据之前降低数据集的维度
训练集基本上是您在所有数据预处理阶段和降维之后得到的最终数据
如果您想在训练集上训练您的分类模型，您当然应该在训练集上应用PCA
训练集基本上是您在所有数据预处理阶段和降维之后得到的最终数据
如果您想在训练集上训练您的分类模型，您当然应该在训练集上应用PCA
训练集基本上是您在所有数据预处理阶段和降维之后得到的最终数据
如果您想在训练集上训练您的分类模型，您当然应该在训练集上应用PCA 好的
所以，降维技术应用后进行训练
然后当然
我们会制作混淆矩阵
你知道怎么做
我们已经做过很多次了
并且由于我们的降维技术只提取了两个特征，就能得到很好的结果
主成分一和主成分二
这将使我们能够将训练集的结果可视化在两个维度
正确 因为记住每个维度对应一个特征
我们在这里对训练集进行操作，以及对测试集
好的 正如你所见
我在这个实现中做的事情，你可以在不到五分钟的时间内完成
多亏了你的工具包
因为你只需要使用数据预处理工具包来制作这些销售
然后你只需要在你的数据预处理工具包中抓取特征缩放工具
然后你只需要抓取你的逻辑回归实现来实施这个单元格
其他同样如此
你知道混淆矩阵，同样的，对这最后两个也适用
可视化训练集的结果和测试集的结果
这些都是你在逻辑回归实现中拥有的单元格
所以绝对没有必要再一起做了
因此我们现在可以直接关注这个单元格
应用PCA，这就完了
我们将创建一个新的代码单元格
现在让我们实现PCA主成分分析，好的
所以你几乎可以按
在视频上暂停现在
并且从scikit learn api获取正确的工具，看看如何实现这一点
这将是一个很好的练习
但如果你不想这样做
那也没关系 让我们现在实现这一点
正如我刚才所说，你猜对了
我们将使用scikit learn库实现pca
所以我们要做的第一件事是从scikit learn开始
我们从中获得访问某个模块的权限
你会在scikit learn api中找到它
这就是分解
就像我们将要导入的分解
当然，一个允许我们构建这个对象的类
它将只是应用于我们的数据集的PCA工具，进行降维
这个类非常简单，叫做PCA
在API中你无法错过它，PCA
那么接下来的自然步骤是
当然，创建一个对象
或者你知道的，这个类的一个实例
我们如何称呼这个对象呢？
非常简单，我们称之为对象pc
这非常直观
现在你知道下一步
下一步是调用pc类
它需要一个必要的参数
你知道在这里我们只需要输入一个参数
你可以完全猜到这个参数会是什么
它是你想要在新数据集中最终得到的特征数量
这个参数来选择这个数量的名字叫做n_components和components
好的 所以现在问题是
当然 我们应该选择哪个数字
我们如何知道要降到多少个特征
我们想要减少数据集的维度提取的特征
嗯 我对这个问题有一个非常简单的答案
我通常的做法是从两个开始
你知道两个主成分
因此两个提取的特征
看看最终我得到的结果
多亏了我们的代码
你知道我们的代码模板
我们可以很快很容易地检查这一点
而且我们确实想尝试两个
因为如果我们在两个方面得到好结果
我们将能够用两个维度可视化训练集结果和测试集结果
你知道我们在三部分分类中看到的那个漂亮的图
我们肯定想从两个开始
如果你知道我们得到非常差的结果
在这里的图形中，我们可以看到，我们无法正确分离三个类别
你知道记得那些不同的预测区域和预测边界
如果我们在可视化中看到结果很差
那么我们可以尝试使用更多的主成分
这意味着从三个增加到四个
在某个点上，我们会得到
你知道一些能够很好地解释方差的提取特征
这正是PCA的目的，对吧
它关于提取一些能够很好地解释方差的特征
一旦你找到了它们，很好
即使维度较低，也会得到良好的结果
好的，让我们尝试使用两个维度
让我们看看结果如何
我已经告诉你我们会得到惊人的结果
因此，n个成分等于2
两个主成分
换句话说，两个提取的特征
好的 这是对象的
现在进入下一步
当然，我们需要将这个对象应用到我们的训练集上
以减少训练集的维度
以便简化逻辑回归模型的学习过程
但我们也必须将这个应用到测试集上
因为 记住，我们将调用的predict方法
必须在与训练集使用的数据完全相同的格式下调用
只要你对你的训练集应用了一些变换
比如数据预处理或降维
很好 在测试集上你也必须做同样的事情
但是请注意，特征缩放要完全一样
我们需要在训练集上应用fit_transform方法
而在测试集上只使用transform方法
这总是出于同一个原因
那是因为我们希望避免在测试集上泄露信息
没错 测试集应该是新的观察数据
就像我们在生产中部署模型的数据一样，我们不应该拟合它们
进行缩放
你知道 在测试集上的特征提取器对象
我们可以应用它们来转换它们
因为它们是训练集拟合的
但我们不能再次拟合它们到测试集
因为这就像试图从测试集中获取一些信息
我们不应该拥有的
这就是信息泄漏的全部内容
就是这样 我说了一切
现在您可以按
暂停这个视频以完成PCA的实现
在接下来的两秒内我将与您一起实现解决方案
好的 我希望你现在做得很好
让我们一起做 正如我们所说，我们希望将这个PCA对象分别应用于训练集和测试集
所以我首先将取x_train
我将通过应用此PCA对象来更新它
然后我将调用这个旧版本的x_train的fit transform方法
PCA之前的意义
所以这里技术上发生了什么
是fit部分从这个fit transform方法中获取它需要的所有信息从x_train
应用主成分分析
然后 当然，transform部分从这个fit transform方法中应用转换本身
以提取主成分特征
好的，这就是技术上的意义
现在，让我们对x_test做同样的事情
所以我复制并粘贴在这里，并在这里替换
X训练由X测试
然后X训练再次由X测试
并且只应用转换方法
然后我们开始 我的朋友们 这个实现已经完成
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p29 3. Step 2 - PCA in Action Reducing Dimensions and Predicting Customer Segments.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p29 3. Step 2 - PCA in Action Reducing Dimensions and Predicting Customer Segments

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                好的，很好 现在我们来测试一下
当然，整个实现过程已经结束
因为所有其他部分都来自不同的模板
数据处理模板
数据预处理工具包和逻辑回归实现
你知道，其余的部分
所以现在我们可以运行整个代码，看看最后发生了什么
基本上我们准备好运行这段代码了
但在那之前，让我们不要忘记将数据集上传到笔记本中
所以点击这个上传按钮
然后请在您的计算机上找到你的机器学习数据集文件夹
无论你何时下载的
然后让我们进入第九部分降维
然后主成分分析
然后Python，搞定
让我们使用葡萄酒数据集
点击打开，然后点击确定
现在您已经准备好使用简单的运行全部来运行此实现
所以点击运行这里
你准备好了吗
让我们在三二一之后这样做
好的，运行全部
导入库和导入数据集
然后应用数据预处理阶段
然后应用PCA
它比我快得多
我们最终会得到什么呢
我们实际上得到了97%的惊人准确率
这位酒商
你知道，这位酒商
肯定对这样的想法有很好的直觉，即应用降维
因为降维不仅减少了数据集的复杂性
它也可以提高最终的结果
你知道，通过将降维与预测模型结合使用
这里正是发生了什么
我们得到了97%的惊人准确率
实际上只有一次错误的预测
顺便说一下，这很有趣
这是第一次你看到三行三列的混淆矩阵
当然，这是我们有三个类别的时候 我们有三个客户群体
一个是二和三
因此我们有三个类别需要预测
所以这是客户群体一的正确预测数量
这是客户群体二的正确预测数量
这是客户群体三的正确预测数量
这是客户群体一的错误预测数量
所以总共只有一次错误的预测
总之
这就是我们为什么能获得如此高的准确性
所以现在我们应该在图表上看到惊人的结果
首先，我们需要可视化训练集的结果
确实，很好
这是我们的两个主成分
PC1在x轴上，PC2在y轴上
然后是这些不同预测区域
这是类别三预测区域
每个预测区域的坐标都是PC1和PC2的提取值
在蓝色区域内的坐标将被预测为属于客户段三
然后，这是客户群体二预测区域的特征
在这个区域内的所有葡萄酒，PC1和PC2提取的特征，
都会被预测为属于客户群体二
最后，这个预测区域的红色对应于客户群体一
在这个区域内，所有葡萄酒的特征，
PC1和PC2的特征，都落在这个区域内，
都会被预测为属于客户群体一
好了 然后 当然，这些点
你知道这里的绿色点
这里的蓝色点和红色点是真实的观察结果
你知道训练集中的真实葡萄酒本身
因此，在这里我们可以确实看到有几个错误的预测
但这只是在训练集上
例如 这是一个绿色葡萄酒
意味着属于客户组2的葡萄酒
被模型预测属于客户组3
这是另外两个错误的预测，真实的葡萄酒属于客户组
第二项 但模型预测它们属于客户群体一号
好的 然后这里又有一些错误的预测
但来看这些错误的预测
在测试集上检查它们更有趣
这里是测试集
确实在新的观察中
我们的逻辑回归模型
结合降维能够完美地将三个类别分开
我们可以很清楚地看到，这里有一个错误的预测
在混淆矩阵中
就在这里
错误的预测对应于一瓶绿色葡萄酒
这意味着一瓶葡萄酒实际上属于客户群体2
但模型预测它属于客户群体1
但这没关系 你知道的
任何商业所有者或数据科学家得到这样的结果
只有一个错误的预测就可以超级开心
但是让我们看看是否可以用我们的其他降维技术来超越它
比如线性判别分析
你知道，要超越它，我们必须达到100%的准确率
所以我们看看线性判别分析
线性判别分析提取的特征能否构建一个预测边界
很好地分离这三个类别
这将是非常具有挑战性的
但这是可行的
然后我们将检查我们是否也能用核PCA做到同样的事情
这是我们最后的降维技术
好的，一旦你准备好进入下一个技术
我会非常高兴在下一个实践活动中与你一起实现LDA 嗯 直到那时，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p30 4. Step 1 in R - Understanding Principal Component Analysis for Feature Extracti.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p30 4. Step 1 in R - Understanding Principal Component Analysis for Feature Extracti

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这门艺术教程，欢迎来到第九部分：降维
所以我们将从降维的第一种技术开始
那就是PCA：主成分分析
正如你所知 在降维中
有两种技术：特征选择和特征提取
我们在第二部分中做了特征选择
当我们实现向后消除模型来选择我们特征矩阵中最相关的特征时
那就是那些最能解释因变量的特征
现在我们开始了这种新的降维技术
那就是特征提取，PCA：主成分分析是一种特征提取技术
作为提醒
假设你的特征矩阵有m个自变量
那么 PCA将提取更少的自变量
但这些将是新的维度
这些新提取的自变量将解释最多的
你数据集的变异
这与你的因变量无关
这使得PCA成为一个无监督模型
因为我们在模型中不考虑因变量
所以这就是PCA，记住在第二部分和三部分中
我们只使用一到两个自变量
那是出于两个特定的目的
第一个目的是我们需要图形化我们的结果
由于每个自变量对应于数据集中的一个维度
我们可以用最多两个自变量来可视化我们的结果
第二个原因是通过这种PCA降维技术
即使开始时有很多自变量
我们可以最终得到很少的自变量
但这些将是相关的自变量
因为这些自变量将解释最多的你数据集的变异
因此，既然我们可以减少自变量的数量
我们可以最终得到两个或三个自变量
因此，我们可以像第三部分中那样可视化结果
这就是我们在这门教程中要做的
在接下来的教程中，我们将覆盖其他降维技术，如LDA和核PCA
当我们开始时有很多特征
因此不可能可视化结果
但当我们应用PCA或LDA时
我们将特征减少到两个
因此我们可以可视化结果
所以让我们开始吧
让我们首先设置正确的文件夹作为工作目录
正如往常一样，我们去到机器学习
那是文件夹
然后是第九部分：降维
我们在第一部分这里
PCA主成分分析
让我们开始吧
这是我们的第一个技巧
点击它
这是我们想要设置为工作目录的文件夹
确保你有一个名为one dot csv的文件
如果情况是这样的
你可以点击这里的更多按钮
将此文件夹设置为工作目录，完美
现在我们将打开我们在第三部分分类中创建的另一个文件
这是我们的逻辑回归r文件
因为我们将要做的是取这个逻辑回归代码
然后我们将更改数据集的名称
因为我们将处理一个新的数据集
这将是wine dot csv文件
我们将在这个数据集上应用pca
当然，我会快速解释背后的商业问题
我将从这里到底部的所有内容都拿走
好的，复制
我将此粘贴到我的pca r文件中
让我们上去并更改数据集的名称
这不是social network at csv
现在是wine dot csv
完美 所以现在我们将做的第一件事是导入这个数据集
然后进行数据预处理
也许我们需要更改一些东西，比如这里的索引
但这会很快
首先导入数据集
我将选择这条线并执行，好的
数据集已成功导入，在这里
现在让我们扩展背后的商业问题
好的 首先这是一个非常著名的数据集
在机器学习文献中广为人知
你可以在uci机器学习仓库中找到它
正如你所看到的，这个链接
首先，这些是自变量
以及因变量是什么
well这些自变量是从酒精到这 proline的所有变量
最后一个变量customer segment是因变量
在原始数据集中
这个因变量并不叫customer segment
实际上，这是葡萄酒的产地
让我们假设我们是一位数据科学家，为一位葡萄酒业者工作
这位葡萄酒业者收集了这些信息，形成了这个数据集
首先，这位业者收集了这些自变量的信息
这些是化学信息
关于多种葡萄酒的信息
这位业者应用了一些聚类技术，以找到喜欢特定葡萄酒的客户群体
根据葡萄酒的信息
并且应用了这些聚类技术
这位企业主确定了三个客户群体，第一个在这里
然后是第二个，最后是第三个
基于这些信息
多亏了其聚类技术
这位企业主成功地找到了一些客户群体
每个群体对某种酒有特定的偏好
所以这位企业主发现了三种类型的葡萄酒
每种葡萄酒对应一个客户群体，因此有三种客户群体
这为什么为他的业务创造价值
嗯 那是因为现在，这位企业主可以做的是收集所有这些关于葡萄酒的信息
除了关于客户细分的信息
创建一个像逻辑回归的分类模型
在其中，自变量是所有这些变量
并且自变量是客户细分
因此对于每种新酒
它可以预测到哪个客户细分
它应该推荐这个
这为这个企业主增加了很多价值
但是然后 如果这个企业主想要一个清晰的视觉预测区域和分类模型的预测边界，那么我们将建立一个模型来查看预测是否在正确的客户细分区域。
如果我们要建立一个分类模型，以便能够清晰地看到预测区域和预测边界，那么我们需要对独立变量进行降维处理。
我们需要应用一些降维技术来提取两个独立变量，这两个变量能够解释最多的方差，然后我们就能看到预测区域和预测边界。
我们需要提取两个独立变量，这两个变量能够解释最多的方差，然后我们就能看到预测区域和预测边界。
因此我们将清楚地看到客户细分在哪里
以及这些客户细分的预测在哪里
根据我们独立变量的所有信息的提取特征
请记住这些提取的特征被称为主成分，好的
现在我们理解了挑战和业务问题
让我们应用PCA，看看我们如何减少这个数据集的维度
因为它确实包含13个维度
因为它包含13个独立变量
并且 我们将看到
我们可以使用PCA将独立变量的数量减少到两个独立变量
但是要小心 重要的是要理解，最终我们将拥有的两个新独立变量
将与特征选择不同，它们是新的，而不是从原始特征中选择的
你知道 使用PCA，我们将从这13个原始独立变量中得出两个独立变量
我们将得到新的提取特征
这是特征选择和特征提取之间的重要区别
好的 所以在我们像往常一样应用PCA之前
我们需要预处理数据
而这实际上会非常快
因为我们的模板已经准备好了
我们只需要更改几件事
首先，数据集等于数据集35
这是为了选择对我们问题重要的自变量
但这里所有事情都重要
我们只是想减少这个数据集的维度
所以我们会保留所有自变量在这里
因此我们不需要这里这条线
所以我会删除它
好的 首先部分，导入数据集准备好
执行得很好
让我们继续到下一部分
所以下一部分是关于将数据集分为训练集和测试集
并且这里要小心
我们只需要更改这个因变量的名称
因为逻辑回归中
我们处理社会网络数据集，并且因变量是购买了
但现在对于新的商业问题
因变量不再称为购买了
它被称为客户细分
所以我们只需要替换
这里购买了由客户细分
好的
我们是否保留75%的拆分比率
让我们取80%
但这取决于你
80%是一个很好的拆分比率
所以我们会这样做
然后这里对于训练集和测试集
我们不需要更改任何东西
所以我们已经准备好将我们的数据集分为训练集和测试集
让我们这样做 我将选择这里所有部分并按command + enter执行
好的
训练集现在已经创建以及测试集，太好了
所以准备好继续到下一部分
下一部分是关于特征缩放
对于PCA来说，特征缩放会更好
你可以实际上执行它
通过调整我们将要使用的PCA函数的参数
但让我们使用这个特征缩放部分的代码模板
将我们的特征放在同一尺度上
这里我们只需要更改索引
我们实际上需要指定我们要缩放的特征的索引
所以基本上我们要缩放的特征是从酒精到脯氨酸的所有特征
所以我们可以指定我们要缩放所有变量
除了最后一个变量客户细分，它有索引14
因此，在这里，我们不再放特征的索引
我们可以把它替换为-14
我们可以删除它
让我们复制这个，因为我们需要对其他部分做同样的事情
因此，在这里我们将其替换为-14，在这里也是-14
最后，-14
因此，现在特征缩放部分已经准备好
我们已经准备好选择这一部分并按command + control + enter执行
现在我们所有的变量都已经缩放
如你所见 我们可以清楚地看到，我们所有的特征都在同一尺度上
当然，客户细分仍然保留其标签
一、二和三，测试集也是如此
让我们确保一切都正确，完美
特征缩放已完成
实际上，预处理阶段已经完成
我们做得非常高效
这很好，因为我们即将进入令人兴奋的部分
将我们的数据应用于PCA
实际上，我们将在这里进行操作
你在数据预处理阶段之后应用PCA
在你在训练集上拟合你的逻辑回归模型之前
因为你当然希望你的模型在新的数据集上训练
那是在你提取了新的特征之后
在你训练了你的分类器之后
你准备好预测测试结果了
制作混淆矩阵
然后你也可以可视化训练集的结果
记住这个部分是应用在包含两个特征的数据集上
所以我们会看到通过提取这两个新的特征我们会得到什么
所以为了完成这个教程
我只会在这里介绍这个新的章节
然后我会调用应用PCA
在下一个教程中我们将应用PCA
然后最终我们将在我们的新减少的数据上构建我们的模型
所以我期待着在下一个教程中做这件事 直到那时享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p31 5. Step 2 - Using preProcess Function in R for PCA Extracting Principal Componen.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p31 5. Step 2 - Using preProcess Function in R for PCA Extracting Principal Componen

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这个艺术教程
所以在这个教程中，我们将应用PCA
实际上，我已经为你准备了应用这一第一维缩减技术的所需包
主成分分析
这些包是carrots，我认为我们已经安装了
但如果情况并非如此，你可以在这里的包中检查
你可以在这里的包列表中查看是否可用carrots
如果你在这里看不到它
你可以执行这条没有评论的行
这将安装carrots
这就是第一个包
然后这是实际导入胡萝卜包的方法
我们也执行这个方法
我们还需要安装在第三部分中安装的其他包
分类
e ten seventy one包
正常情况下你应该已经安装了
但如果不是这样
你可以选择这一行并安装包
别忘了执行这一行以选择它
现在我们准备好开始应用PCA了
所以我们要做的第一件事是创建一个新变量
我们将其命名为pca
我们将在后续使用它来转换我们的原始数据集，该数据集包含我们的13个特征
以转换为这个新数据集，包含新提取的特征
现在我们来创建这个变量
我们将使用函数
这是预处理函数
它来自carrot包
现在我们按F1键这里，以查看预处理函数的所有信息
因为 你会发现有一些非常有用参数，允许你应用PCA
根据你的目标
例如 你可以指定最小解释方差比率
你想要得到那些
例如 如果你想要减少你的数据集的维度到一个特征数量
这将解释至少60%的方差
嗯 你可以通过此预处理函数中的一个参数来指定这一点
让我们看看信息
这就是信息
让我们跳到参数，好的
第一个参数是x，一个矩阵或数据框
这实际上是我们想要降低维度的数据
所以这将是我们的训练集
所以x将是训练集
然后下一个参数是方法
所以方法是你的降维技术
正如你所看到的，你有几种降维技术，如PCA
这些都是其他方法
但我们想使用的当然是PCA，即主成分分析
所以我们在这里使用方法等于PCA
然后阈值阈值是一个非常重要的参数
这正是我刚才告诉过你的
如果你想减少你的数据集的维度
至少以最低量的解释方差
你可以通过使用此阈值参数来实现
正如你所见
这是通过PCA保留的累积方差比例的截断值
例如 如果你想要新提取的特征至少解释60%的方差
那么 你需要在这里指定
阈值设置为0.6，即60%
但我们在这里不会使用阈值参数
因为我们已经知道我们要什么
我们要求两个独立的变量
因为我们想要能够可视化训练集结果和测试集结果
并且我们能够在下一个参数pca comp中获取到
这就是保留的具体的pca组件数量
这就是你最终想要获取的提取特征的精确数量
在这里我们将输入pca comp等于2
因此我们的训练集
我们的原始训练集
我们将从拥有13个独立变量
我们数据集中的13个原始独立变量，变为拥有2个新提取的特征
这些特征将解释最多的方差
正如你所看到的
如果我们指定这个PCA
Com参数 这将覆盖阈值
这就是为什么我们不需要指定读取参数
以指定最小累计百分比的解释方差
然后你有其他参数
但我们不会使用它们
实际上我们只需要指定我们要转换的数据
以提取新特征
使用PCA方法并指定我们要获取的特征数量
最终 这是两个新提取的特征
所以让我们输入参数
让我们从第一个开始x等于
所以这是训练集，开始吧
实际上我们需要指定特征
实际上这不是完整的训练集
因为记得PCA是一种无监督的降维技术
这意味着我们在提取新特征时不考虑因变量
所以我们实际上需要从这里移除因变量
记住这是指第14个索引
我们可以用与特征缩放相同的方法来做
这意味着我们在这里加上-14
好的 现在PCA将应用于所有特征
我们训练集的13个特征
下一个参数是方法
正如我们所说，方法等于引号PCA
然后逗号下一个参数和最后一个参数
正如我们所说，PCA comp
所以我们想要两个新提取的特征
好的 所以创建了我们将要用于训练集的PCA对象
来转换我们的原始训练集
由我们的13个自变量组成的训练集
到新的减少维度的训练集
包含解释最大变异的两个新提取的特征
让我们这样做
让我们使用我们的训练集，因为我们将要称它为新的训练集 因为你知道
然后我们有我们所有的模板
并且我们使用这个训练集变量名
所以我们想要保留这个训练集的名称
但如果你想保留你的原始训练集和测试集
你可以使用其他名字，如训练集
下划线PCA
但如果你这样做
不要忘记在这里将trainset更改为training at pca
以及在测试集pca也是如此
以及在混淆矩阵部分
特别是在可视化训练集结果这里
你需要在这里将training set替换为training set pca
这就是为什么我们保留名称
以便不必更改一切
所以我们回到training set等于
现在我们将这个原始训练集转换为我们的新训练集
由我们的新提取的特征组成
这样做非常简单
我们使用预测函数
在里面我们取我们的PCA对象come up
并且我们应用PCA转换对象到我们的原始训练集，它也命名为training set
并且通过这样做
这个原始训练集将变成由两个新提取的特征组成的新训练集
让我们这样做
让我们从创建这个对象开始
然后我们将转换我们的训练集
我将选择这条线并执行它，完美
PCA对象已经准备好用于原始训练集
来将其转换为我们的新训练集
由两个新提取的特征组成
让我们也执行这个
开始
我们的新训练集现在已经创建
你可以看到
当我点击这个时
我有一个新的训练集，包含两个新提取的特征
记住这两个新提取的特征被称为主成分
这就是为什么你有PC1和PC2
当然我们还有我们的因变量向量
客户细分的因变量，有三个标签
一二三，好的
但现在你可以明显地注意到
因变量向量现在排在第一位
并且我们将使用数据集模板
我的意思是训练集和测试集，其中因变量在最后
我们需要将这个因变量放在最后位置
这实际上是非常容易的
我们所需要做的就是处理索引
将这个客户细分的因变量放在最后位置
方法非常简单
我们将再次使用我们的训练集
开始
然后我们再次取我们的训练集
然后括号
然后在这些括号内
我们将取我们训练集的列索引
按照我们希望的顺序
你将会理解我们现在将取得一个向量
记住在我们的向量中，它是用c然后括号
然后在这些括号内，我们输入我们希望获取的索引的正确顺序
让我们回到我们的训练集
我们希望获取的第一列是pc1
这应该是我们新训练集的第一列
这个索引是2
在这里我们输入第一个索引
这是2
然后逗号
然后我们输入我们希望获取的第二列的索引
那就是第二列
第二列是pc2
这个索引是3
在这里我们输入3
在这里你输入你想要在你的训练集中拥有的最后一列的索引
你想要在你的训练集中拥有的最后一列是这个客户细分列
因为这是因变量
到目前为止，这个客户细分的索引是1
所以你需要在这里指定
这个索引是1
这样我们的新训练集这里就是我们这里的训练集
但是，列的一个新顺序
并且这是由这里给出的顺序决定的，首先第一个独立变量，索引为二
然后是第二个独立变量，索引为三
最后，依赖变量列，索引为一
如果你选择这条线并执行
如果我回到训练集
我有我的前两列作为新提取的特征
pc1和pc2
最后一列
客户段在最后位置
正如我们将要使用的代码模板
期望它
这很好
我们可以回到pca
现在我们需要为测试集做同样的事情
我们将做这些事情
复制它们并替换这里的训练集为测试集
这里也是测试集，这也是
测试并最终测试
当然，你想要的顺序是同样的索引
我们可以检查一下 我将选择这条线，正如你所看到的
测试集仍然有13个原始特征
如果我执行这条线
它现在有两个新提取的特征
主成分一和二
但是客户段在第一位置
我们希望把它放在最后位置
为了做到这一点
我们执行这条线，这将完成它
如果我回到测试集
现在客户段在最后位置
我们现在准备好使用模板的后续部分
预测测试结果
制作混淆矩阵
并且，最重要的是
我们现在将能够可视化训练集的结果
因为我们的训练集和测试集现在有两个维度
所以我期待着在下一课中可视化这些结果 直到那时，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p32 6. Step 3 - Implementing PCA and SVM for Customer Segmentation Practical Guide.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p32 6. Step 3 - Implementing PCA and SVM for Customer Segmentation Practical Guide

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这个艺术教程
在上一个教程中，我们处理了预处理阶段
然后我们对我们的数据集应用了PCA
将其维度降至两个新的提取特征
现在我们准备好构建一个分类模型了
说到分类模型，我们首先从逻辑回归模型开始
但实际上，从这个点开始，我们可以构建所有分类模型中的任何一个
我们在第三部分中制作的所有分类模型
如果我回到第三部分
分类
这个文件夹里
我们第三部分中制作的所有模型
基本上，从这个点开始，你可以通过选择你想要的分类模型来构建任何模型
例如 让我们选择支持向量机分类模型
然后你可以打开svm文件
然后基本上你所需要做的就是从数据预处理阶段开始
从那里开始构建你的svm模型
并选择底部的所有内容并复制
然后在你的PCA文件中包括你的分类模型
在你对数据集应用PCA之后
所以我只是用svm模型替换了逻辑回归模型
你可以为任何分类模型这样做
你想要我们在第三部分中制作的分类模型之一
所以用简单的复制粘贴替换不同模型非常容易
这样你可以非常高效地尝试不同的分类模型
让我们看看用这个svm模型能得到什么
例如 我们需要更改这里
这是可依赖变量的名称这不是购买
但这是客户细分
好了，这就是我们需要更改的唯一内容
因为这里的数据有输入训练集
这是训练集，这是一个转换的训练集
由新提取的特征组成的新训练集
所以基本上我们准备好选择这个部分并执行它
以构建我们的svm分类模型
现在模型已经构建完成
我们准备好预测测试集的新观察值
所以现在这条线准备好了，实际上我们不需要更改任何东西
因为索引3
这里是可依赖变量的索引
由于我们将数据集的维度降至2
这意味着我们有两个特征和一个可依赖变量
因此，可依赖变量的索引仍然是3
所以我们准备好选择这条线并执行
现在我们有了测试集的预测结果
我们可以在控制台查看为什么面包，按Enter
对于测试集中的每个观察值
我们都有模型的预测
SVM模型
例如 数据集中的第四个样本，属于测试集
预测属于客户一号
132号样本预测属于客户三号
非常简单
现在我们可以做混淆矩阵
我们不需要更改任何东西
因为这对应于因变量的索引
我们准备好执行了
混淆矩阵准备好了
让我们看看，哇
完美的结果 我们只获得了正确的预测
如你所见
12个葡萄酒被正确预测属于客户一号
14个葡萄酒被正确预测属于客户二号
10个葡萄酒被正确预测属于客户三号
然后我们没有错误的预测
所以这些是优秀的结果
当然我们得到100%的准确率
现在我们移动到下一个部分，可视化训练集结果
我们应该得到非常清晰的预测区域和预测边界
让我们检查一下
但现在我们需要改变一些东西
这不是一个小的改变
因为我们以前做的
因为我们现在有三个类别
如你所见在这段代码
当我们绘制预测区域时
多亏了这条线
嗯 这段代码模板允许我们这样做
当我们只有两个类别时
因为如你所见我们有这个
if else条件
如果y grid等于一
那么颜色是绿色
否则如果y grid等于零
那么颜色是番茄红，当我们绘制观察值时
如果观察值属于训练集
属于类一
那么它是绿色的
否则如果它属于类零
那么在else条件中
点会是红色的
但现在问题是我们有三个类别
所以我们需要改进这里的代码以区分三个条件
如果y等于零
如果y等于一
当y等于二
那么我们来做
这将很好 编码实践和说到编码实践
这将非常好
是你在我之前尝试
在这个教程中
你可以暂停并尝试
现在我要做
基本上我们需要添加一种新的条件
当y等于二
那么我们来做
让我们在这里添加新的条件
如果y网格等于等于二
那么,然后,在这个条件之后y网格等于二
我们将放我们所需要的,我们需要的是一个新的颜色
因为每个y网格的值都有一种颜色
我们将保持绿色三
对于y网格等于一的情况
我们将保持番茄红对于y网格等于零的情况
对于y d等于二
我们需要引入一个新的颜色
因为我们这里有绿色和红色
让我们放蓝色
所以,一个好的颜色实际上是深蓝天空
然后,逗号以获取下一个条件
到目前为止,我们看到的是如果y网格等于等于二
那么颜色将是深蓝天空
然后如果y网格等于一
那么颜色将是绿色
如果y网格等于零
那么颜色将是红色
但这并不是这样工作的
这并不是那么简单
因为这实际上是不正确的语法
因为这个if else函数期望三个参数
第一个参数是条件y网格等于一
然后第二个参数是当这个条件为真的结果
第三个参数是当这个条件不为真的结果
这里我们有很多超过三个参数
所以这不对
所以解决这个问题的技巧是将所有这些
即y网格等于一的条件
然后将结果放在三
然后将结果y网格等于零放入这个if else函数的第三个参数
如果else函数
这意味着我们将得到第一个参数
y网格等于二
这是条件
然后第二个参数深蓝天空
当y网格等于二时，这就是结果
并且第三个参数，所有这些都在同一个参数中
那么我们如何将所有这些包含在一个参数中
嗯 我们需要在这里使用另一个if else
它将包含其他两个条件
当y网格等于一且y网格等于零时
所以我们需要在括号中小心
因为我们添加了一个新函数
这个新函数if else，这里是新鹦鹉
这是新添加的
现在应该没问题
所以让我们总结一下
我们从这里开始
这里是if else 所以当y网格等于二时
那么颜色将是深蓝天空
然后如果y网格不等于二
那么我们进入这个新的
如果else并且这个新的
如果else包含最后两个剩余条件
那就是如果y网格等于一
那么颜色将是春绿色三，如果y等于零
那么颜色将是番茄红色
因此我们将三个条件放在对的语法中
这是一个技巧 实际上这是很常见的编码方式
知道如何做是好的
这是同样绘制我们观察点颜色的方法
所以我们需要将这个复制到这里
然后替换这里的一个为二
这就是新的第一个条件
如果我们的观察点属于类二
那么我们想给它一个新的颜色
这将是一个蓝色
但不是这个深蓝天空
所以你知道我们需要得到一个好的对比
这样我们不会混淆点的颜色和区域的颜色
实际上一个好的颜色
这里是蓝色三，蓝色三
你会看到它会给我们一个好的对比
这就是第一个条件的第一个结果
然后同样我们需要将剩余的两个条件包含在一个参数中
那就是在这里一个新的
如果else，所以如果else在这里和括号
我们不要忘记在这里和这里添加关闭括号
这准备好了 所以总结一下
如果我们的观察点属于类二
那么它将具有蓝色三的颜色
那么如果它不属于类别二
那么我们来到这里，这里有两个新的独立条件
如果我们的观察点属于类别一
那么它将用绿色表示
如果它不属于类别一
那么它将用红色三表示
这应该就完成了
然后我们需要添加小的更改
请记住在这条线这里
第49行，列名
我们需要输入训练集的实际列名
这些列名不是年龄和估计工资，那是之前的分类问题
现在列名是
当然pc1和pc2
在这里我们需要将h替换为pc1，将估计工资替换为pc2
这很简单
这就是你需要输入的
否则当你执行代码时会出现错误
然后这里不是必须的
但这对可视化更好
你可以将h替换为pc1，将估计工资替换为pc2
但如果你不这样做
你不会出现错误
因为这是只是为了可视化
这仅仅是图表上的标签
然后，我想我们很好
我想这已经准备好执行了
让我们希望我没有犯错
所以我们将要尝试执行这个，让我们看看结果
所以我将要选择这里的所有部分
从这里到顶部这里，并且执行所有
好的，开始运行了
让我们看看结果
让我们进入这个绘图标签
它还在运行
这里我们走
我们得到了我们的漂亮结果
我希望你喜欢我的颜色选择
这是深天空蓝
这是蓝色三
这样我们可以得到观察点和预测区域的对比
所以我们可以实际上放大这个，如果你愿意
所以作为一个快速提醒
点是真实的观察点
这些是我们训练集中的酒
区域是我们的模型预测酒属于客户段
例如
绿色点是训练集中的属于客户段二的酒
而这个绿色区域这里，模型预测酒属于客户段二
同样对于蓝色和红色部分
现在我们可以快速地对测试集做同样的操作
实际上我们需要对测试集做与训练集相同的更改
那就是 让我们从最简单的开始，我们需要在这里替换这里
H by pc one
Estimated salary by pc two
这些都是必须更改的部分
我们也可以更改标签
即使这不是必须更改的部分
Replace h by pc one
Replace estimated salary by pc two
就这样
我们几乎准备好了 我们需要在这里做大的更改以添加第三个条件添加第三个颜色
我们可以实际上取这两行
复制它们并选择这个然后粘贴所有
我们可以这样做，因为这些是训练集中的相同变量名
因为我们在这里使用了这个set变量名，既用于训练集也用于测试集
所以基本上这就准备好了
我们现在可以选择这里整个部分并执行以可视化测试结果
让我们这样做
我们进入处理测试结果正在生成
我们应该得到一个完美的图，没有错误的预测
这意味着我们应该得到所有绿色点在绿色区域
所有红色点，这里是
所有红色点，正如你所见，在红色区域
所有蓝色点在蓝色区域
所以这完美 这是对100%准确度的完美表示
因此，总的来说
我们能够把一个由13个独立变量组成的数据集
转化为一个新的降维数据集
我们能够将维度降低到2
多亏了这一点，我们能够将结果可视化为二维
好的 完美，我们对PCA的第一部分已经完成
现在 有趣的事情是我们想看到的是
我们即将实施的下一维降维技术
将如何处理这个数据集
下一维降维技术是lda线性判别分析
我们将在下一部分了解这一点 直到那时，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p33 1. LDA Intuition Maximizing Class Separation in Machine Learning Algorithms.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p33 1. LDA Intuition Maximizing Class Separation in Machine Learning Algorithms

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                大家好，欢迎来到线性判别分析（LDA）的直观讲解
对于那些从主成分分析（PCA）前一节过来的人来说
这可能看起来有点相似
但它们之间存在一些差异
我们将从整体上开始探讨LDA的含义
这是一个简短而直接的直观讲解
但我们会探讨PCA和LDA之间的主要区别
LDA通常被用作降维技术
我们之前在PCA中听说过这一点
它在模式分类和机器学习算法的预处理步骤中被使用
它的目标是将数据集投影到一个低维空间，听起来与PCA相似
但LDA有所不同，因为它除了找到成分轴之外
我们还对最大化多个类别之间的分离轴感兴趣
这就是主要要点
或主要观点是，PCA中我们与这个区别一起工作
与轴
数据中的主成分
但在LDA中我们看
我们在数据中寻找这些类别的分离，进一步分解
LDA的目标是将特征空间投影到一个小的子空间
在保持班级歧视信息
我们有PCA和LDA这两种线性变换技术用于降维
PCA是一种无监督算法
但LDA是有监督的，因为它与因变量有关
在这里我们可以看到这种可视化
PCA和LDA的主要操作和主要区别
再次，PCI
我们在寻找数据子空间和数据降维技术
检查主成分轴的关系
而在LDA中我们寻找这种分离
我认为这种可视化方式在两者之间最清晰明了
如果你想获取更多信息
你可以随时查看以下链接
这里我们有PCA和LDA以及它们各自的主要操作
LDA是有监督的，因为它与因变量有关
当你在即将到来的讲座中开始深入研究时
在实践部分 这将会更有意义
但主要关注点是LDA
你可以通过五个主要步骤来完成
与PCA相似
LDA的五个主要步骤包括以下内容
计算d维均值向量
计算散度矩阵
你还需要计算特征向量
按降序对特征向量进行排序
使用d乘k的特征向量矩阵将样本转换到新子空间中
与PCA非常相似
两种不同的降维技术
一种是无监督的，另一种是有监督的
但是LDA的主要区别是，我们需要寻找类之间的分离度
在整个数据集中
如果你来自PCA 大多数操作应该对你来说很熟悉
如果你刚接触这个 我建议你去看看PCA
当你开始处理接下来的部分时
这将更有意义 但是请记住LDA的主要要点是类之间的分离度
它是一个有监督的学习技术
如果你有任何问题，一如既往 请随意分享，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p34 2. Mastering Linear Discriminant Analysis Step-by-Step Python Implementation.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p34 2. Mastering Linear Discriminant Analysis Step-by-Step Python Implementation

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们，欢迎来到第九部分降维的新实践活动
在上一节中，我们尝试了PCA主成分分析
我们确实在我们的葡萄酒数据集上获得了伟大的结果
这将是本节中的同一个数据集
因为你知道，我们要比较几种降维技术
所以我们去看看我们是否甚至可以击败PCA 它只有一例错误预测
所以我们将使用相同的数据集
因此，实现将完全相同
除了一行代码
当然，我们将在那里实现LDA而不是PCA
所有的代码 你准备好了吗
让我们开始吧，在我们进入这个文件夹之前 第九部分
让我们确保每个人都在同一页面上 我给你这个文件夹的链接
包含所有代码和数据集
在这个教程之前
所以请确保连接它
现在，让我们开始
让我们进入第九部分降维
现在我们将进入第四部分
四线性判别分析LDA
这将是一个新的降维技术
我们将会看到它非常强大
让我们从Python开始，像往常一样
并且，这就是我们的文件夹
就像之前的一个，有两个文件
这是实现
这是相同的数据集
你知道，这属于一家葡萄酒商店的老板
他首先问你，你知道，最出色的数据科学家
来做一些聚类，以识别不同的顾客群体
对于每一款葡萄酒 你知道，这个数据集的每一行都对应于一款特定的葡萄酒
并且对于每一款，我们有几款葡萄酒的特征
或者你知道，特性
所有这些，直到这里
你知道，你使用了所有这些特征来识别这三个顾客群体
或者你知道，顾客聚类
然后，你知道
由于这个葡萄酒商店的老板如此高兴和被你的工作所感动
当然，老板又让你做另一个任务
这就是我们即将用LDA要做的任务
它涉及将预测模型与降维应用到这个数据集相结合
因此，对于这个老板新拥有的每一款葡萄酒，这家葡萄酒商店
好的
通过部署这个新的预测模型
这个所有者将能够预测新客户属于哪个客户群体
以便可以将新客户推荐给正确的客户
从而最终优化销售
这正是相同的数据集
现在让我们继续我们的实现
线性判别分析
我们可以通过谷歌协作打开它
就像我现在做的那样
或者Jupyter笔记本
正如你所注意到的，我保留了之前在PCA上实现的代码，以便最后可以比较结果
这是我们之前做的PCA
这是我们之前做的LDA
正确 这是PCA
这是LDA
但是，你知道 由于这是只读模式，我们将创建一个副本
以便我们可以重新实现构建LDA模型的那行代码
所以现在我们创建一个副本
所以我们保存一个副本并继续
这将在内部创建一个副本
我们可以重新实现lda模型
现在我们可以
关闭这个，以便我们可以将两个实现放在一起
你知道两个副本
现在让我们这样做
让我们快速删除
你知道实现lda的单元格这个，让我们重新实现这个
因为你知道其余部分都是一样的
我将实际删除这里的所有输出
这样你们就看不到最终结果
我们可以把它们保留为惊喜
所以我将删除输出
不要过于靠近
就这样，好了
基本上，这个实现的所有单元格与前一个完全相同
PCA 除了当然实现lda的单元格在这里
所以没有必要重新解释所有这些
加上所有这些其他销售都来源于我们多样化的工具包
所以你肯定百分之百熟悉它们
好的 那么我们来做这个
让我们 你知道
应用lda
所以我们要创建一个新的代码单元
就这样
让我们实施线性判别分析
所以现在你有两个选项
第一个也是最佳的选项是点击
视频暂停，然后尝试自己实现
当然浏览scikit
Learn API并找到可以实现lda降维技术
的那个lda类，
你将肯定会得到相同的解决方案
我在几秒钟内实现
第二个选项当然是当然不
点击视频暂停并和我一起实现
让我们说在三秒内
321开始，好了
让我们这样做 让我们一起实现lda
正如我刚才所说，我们将实现lda
多亏了cycllibrary
因此我们将从sk learn开始
我们将获得一个新的模块，
不是循环学习的分解模块
而是另一个非常容易记住的
因为实际上这就是判别分析
下划线分析，好的
这是循环学习的另一个模块，
当然包含lda类
并且那个类，你知道，
在这条导入语句之后 我们需要添加这个类的名称
这个类的名称是大写的L
然后非常简单线性判别分析
好的
非常好
谷歌协作之所以不能帮助我， 原因是笔记本没有运行，记住运行笔记本
或者你知道的连接
你需要运行任何第一个单元格
或者上传数据集
所以让我们现在来做
这样你知道谷歌协作可以帮助我 我真的很喜欢它
当它这样做时 所以现在我只是点击了这个文件夹按钮
然后点击上传按钮
我们将最终到达
你知道 主成分分析之前的文件夹
但让我再次显示路径
我把我的数据集文件夹放在我的桌面上
所以里面我们将现在去第九部分
然后第四节线性判别分析
然后是python和1
所以这是完全相同的数据集
但我只是想向你展示路径
然后我们就去了
我们有一个，所以现在我要向你展示
如果我重新输入这个线性判别
现在 它在帮助我
所以这可能更好
你知道这个反射要一开始就上传数据集
好的 线性判别分析
但是，由于这个类名太长且不实用，让我们给它起一个简单的别名，比如lda
这样做是完全可以的
现在我们按回车键，继续下一步
当然，下一步是创建这个线性判别分析类的对象
好的 当然，我们将其命名为lda
现在我们要称呼这个班级为
因为我们给它设置了快捷方式lda
我们可以简单地调用lda这种方式
现在，正如我们所看到的
这个lda类需要作为输入只有一个参数
这与之前一样
它也有相同的名称
它是n
这与你最终希望得到的特征数量相对应
在应用这一降维技术后
当然，正如我在上一节推荐的那样
我们将从两个开始
这样我们就可以看到即使只有两个提取的特征
我们也可以得到很好的结果
如果这种情况属实的话
我们不仅可以得到很好的结果
而且，锦上添花
在最后，我们可以在一个漂亮的二维图上可视化结果
你知道的 多亏了这两个代码部分，好吧
但现在我们需要完成这个
好了 最终我们只提取两个特征，为此我们现在需要
当然，我们需要将我们的lda对象与我们的数据集连接起来
但再次分开训练集和测试集，并正确连接它们
当然，我们需要在训练集上应用fit transform方法
然后在测试集上只使用transform方法
这与之前一样的原因
这是为了避免测试集中的信息泄漏
好的 那么我们开始吧
这是我们下一步
所以我们首先取x列车
然后我们将其更新为新的x列车
在我们应用lda特征提取技术之后
我们需要 当然
从我们的lda对象中获取fit transform
这将作为输入输入，请注意
这不会是之前的完全相同的输入
因为，你知道PCA
拟合转换方法只接受x_train作为输入
因为它只需要特征来应用PCA降维技术
但是，LDA实际上不同，为了应用该技术
它不仅需要特征
还需要目标变量，对吧
目标变量是LDA方程中必需的元素
因此，在这里拟合转换方法中
我们需要输入不仅x_train
还有在应用LDA之前的x_train和y_train，对吧
所以这一点要非常小心
无论你选择使用lda还是pca
对于pca，你只需要输入x_train
对于lda 你需要输入特征x和因变量y_train，好吗
最后一步，现在我们有了一个基于训练集的lda特征提取器对象，我们可以通过只调用transform方法将其应用到测试集上，对吗
没有必要再次拟合它到测试集上
因为测试集应该是我们部署模型的新数据，就像在生产环境中一样
因此，我们必须在这里只使用变换方法
因此，我正在以下方式更新我们的x_test变量
首先调用我们的lda对象
我们从中只调用趋势形式方法
根据你所说，它是否需要只接受x_test作为输入
或者x_test和y_test
显然它只需要接受x_test
因为我们不应该有y_test
你知道 x_test就像我们部署模型的新数据
然后我们会得到预测和白面包
你知道，我们会比较面包和白色的关系
但是我们不应该有白色测试
因为白色是真实的结果，它们包含了隐藏的真相
你知道，基础真相
所以 当然，我们这里只需要应用x测试
我们之所以能将y train输入这里，是因为
确实，我们应该得到训练集的基础真相
否则我们就无法训练我们的机器学习模型，好的
所以x测试，搞定
不仅lda的实现完成
而且整个实现也完成了
所以现在我们将运行所有，现在我们
你知道将数据集上传到笔记本
所以我们已经百分之百准备好了
让我们回顾一下，我们在之前的实现中想要改进的是什么
你知道 在主成分分析实现中，当我们获得混淆矩阵时
只有一个错误的预测
导致准确率达到97%
在测试集结果，最有趣的部分
嗯 我们确实对三个类别进行了几乎完美的分离
现在我们将看看，使用我们从lda提取的新特征
我们能否得到类别的完美分离
因此，我们可以得到一个100%的准确率，你准备好了吗
让我们这样做，3，2，1，运行所有
所以现在所有单元格都在运行，搞定
哦，搞定
我们刚刚得到了100%的准确率
换句话说
我们的逻辑回归模型完全有能力将我们的三个类别完美分类
通过将它们分开
这正是我们要看到的
你知道测试集结果
因为确实
我们在这里有一个错误的
但是，正如我们所见，真正的葡萄酒
你知道 所有的点在这里
红色，绿色和蓝色落入正确的预测区域 这个预测区域，我们的模型预测一个属于客户细分第一号
然后，这里，我们的模型预测葡萄酒属于客户细分第二号
最后，这个预测区域
我们的模型预测葡萄酒应该推荐给客户细分第三三号
并且，多亏了这些新提取的特征
你知道lda一和d二
嗯
这次我们有完美的类别分离器 换句话说
我们有一个完美的分类器 如果你在 wonder lda如何完美地分离类别
而在PCA中，我们看到很难分离
你知道，测试集中的葡萄酒
你知道
嗯，这是因为提取的特征不同 因为，你知道
这一个落在红色葡萄酒的中间
你知道它们与PC1和PC2不同，它们在某些其他维度中，嗯，
在这个时间点上，完美分离类别是可能的，这就是为什么这次有效，
换句话说，我们在另一个维度中，
好的，
所以我猜现在我们没有太多挑战，因为不可能打败这个，
这太完美了， 我提醒一下，我没有制作这个数据集，
你知道，这是一个来自UCI ML仓库的数据集，
所以它非常接近真实的数据集，
但这就是结果，
这显示了降维技术的威力，
线性判别分析，
现在我们将转到下一个实践环节， 这次是核PCA，
我们希望至少能得到与PCA或LDA一样好的结果，
换句话说，
让我们希望得到一次错误的预测，
所以我期待下一节实现核PCA，
直到那时，享受机器学习吧，
好的， 让我们希望得到一次错误的预测，
所以我期待下一节实现核PCA，
直到那时，享受机器学习吧， 好的，
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p35 3. Step-by-Step Guide Applying LDA for Feature Extraction in Machine Learning.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p35 3. Step-by-Step Guide Applying LDA for Feature Extraction in Machine Learning

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这个艺术教程
所以，在上一节中
PCA特征提取技术降低了我们问题的维度
通过提取解释方差最多的变量
而在LDA中，这非常不同
我们提取一些新的独立变量，这将最大程度地分离依赖变量的类别
因此，这次它考虑了依赖变量的类别
这意味着它考虑了依赖变量，以便进行这种特征提取技术
因此，LDA是一个监督的降维模型，好的
所以现在让我们在R中应用LDA，所以首先非常快速
让我们将正确的文件夹设置为工作目录
所以我们会转到我们的机器学习
这是一个文件夹
第九部分降维
我们现在在这个部分四四线性判别分析
所以让我们进去，这就是你想要设置为工作目录的照片
我们仍在对一点csv文件进行工作
这正是我们在实现PCA时处理的相同业务问题
这将是一个比较这两种降维技术，PCA和LDA的好机会
LDA到之前的一个PCA
那么现在我们不要忘记点击这里的更多按钮
并将设置为工作目录，完美
并且，因为我们还在处理与PCA之前相同的商业问题
那么，在这里实现LDA将非常容易
我们将只使用PCA代码
从这里往下复制所有内容
然后我们回到LDA并将整个代码粘贴到这里
在这个代码内部
我们只需要基本上替换这一部分
将应用PCA的部分替换为新的专门用于应用LDA的部分
所以我将移除所有这些部分
让我们移除这个，并在这里将pca替换为lda
现在是时候实现lda了
我们将使用mass包来应用lda
M a s s
实际上，这个包默认存在于你的包列表中
它就是这里这个包
mass支持函数和数据集用于enables和替换mass
好的 正如你所看到的，这个没有导入
那么我们使用库命令来导入它
我们开始并按这种方式进行大规模
我们可以选择导入这个包
现在让我们实现lda
首先我们必须要做的是询问pca
创建一个lda变量，我们将使用它将我们的原始数据集转换为新的数据集
由线性判别组成
所以我们将给这个变量命名为lda等于
现在我们将使用lda函数，就这么简单
让我们添加一些括号
现在让我们看看如何通过按f1来查看论据。
所以论据在这里。
第一个论据是公式。
这就是你的因变量相对于自变量的公式。
原始的公式在这里。
我们将输入公式等于客户细分。
记住，这是因变量的名称，然后是波浪号。
我们可以添加一个点。
别担心。 我们不必写出所有自变量的名称。
点在这里为我们服务。
所以逗号和下一个论据。
然后是下一个论据是数据。
对于PCA来说，这里的数据将是训练集。
所以让我们在这里添加训练集。
训练集，好的。
实际上就是这样。
而且那就是全部。
而且那就是一个特定的原因。
一个非常重要的原因，这与LDA直接相关。
这是因为LDA是一种有监督的降维技术。
记住，有监督的意思是LDA模型考虑了因变量。
既然它考虑了因变量，
就很直观地理解，
线性判别数的数量将与因变量的信息相关。
而这种信息实际上是因变量的类别数量。
而且， 线性判别数和因变量信息的显式相关性是，
将有k-1个线性判别数，其中k是类别的数量。
这意味着将有最多k-1个线性判别数。
由于我们有三个类别，
这意味着我们将得到最多3-1=2个线性判别数。
所以，
在这里， 如果不指定线性判别数的数量等于2，
我们将自动获得2个线性判别数。
因此，我们不需要添加任何其他论据。
LDA对象已经准备好将我们的原始数据集转换为由线性判别数组成的新数据集。
我们将得到2个线性判别数，
这正是我们所需要的。
对于PCA，
我们需要两个新的提取特征。
这次这两个新的提取特征将分离两个类。
我们应该得到很好的结果。
然后，这与PCA相同，
我们需要转换训练集和测试集，
以便我们可以在下一节中使用它们。
我们将使用训练集来拟合SVM。
实际上，我们将使用训练集来构建分类器。
然后我们将进行预测
用这组测试集进行预测，它将被转换为测试集
并制作混淆矩阵
最重要的是，我们将可视化训练集和测试集的结果
这是我们能做到的，因为我们现在有两个特征
让我们这样做 让我们做同样的事情，应用lda到训练集和测试集
首先，我们从训练集开始
训练集
记住我们保留训练集的名称，以便在其余部分中不需要更改
所以训练集等于
然后，记住我们需要使用预测函数
实际上这与pca完全相同
我们将
然而，需要添加一些内容才能使其工作 我会解释这是什么，
但肯定我们是使用预测函数进行转换
所以在括号内
现在我们需要在预测函数中指定
你知道
第一个参数是对象 所以对象是lda
然后逗号
然后是第二个参数
第二个参数是我们要在其上进行转换的数据集
提取新特征
那就是训练集在这里
作为提醒
这是原始数据集，由13个独立变量组成
这将是新的训练集，由两个新提取的特征组成
它们是两个线性判别特征
好的
我们可以立即这样做，看看我们是否得到了预期的训练集
正如我们所期望的那样
在执行这一行之前
当然 我们需要执行之前的部分
因为我们需要先导入数据集并应用数据预处理
让我们这样做
这里我们没有任何东西需要更改
一切都已经准备好
感谢我们在前一节中做的pca工作
所以让我们执行这个，好了，执行
现在应用lda
创建lda对象
然后使用该对象将我们的原始训练集转换为新的训练集
由两个线性判别特征组成
我们已经导入了mass包
所以我们只需要执行这行代码
让我们这样做
好的 LDA 对象已成功创建
现在我们准备好转换训练集了
但在我们选择并执行这条线之前
我们需要添加一些我刚刚提到的东西
那就是我们将应用到整个预测训练集上的功能
这将把训练集转换为数据框
因为对于PCA
当我们这样做时
当我们将训练集转换为新的由主成分组成的训练集时
我们得到了一个新的训练集，其中包括主成分
但我们得到了一个数据框
但对于LDA
情况并非如此
我们将得到一个矩阵，我们需要一个数据框
因为接下来我们有一些代码段，在这些代码段中
我们将使用一些函数
这些函数期望训练集是一个数据框
例如，它期望一个数据框
所以我们绝对需要将这个转换训练集转换为数据框
如果我们这样执行
但它是一个矩阵，所以为了简单地将这个转换为数据框
我想我们已经做过了，我们需要使用as.data.frame函数
我们需要在括号内加上训练集
然后在括号内加上结束符号
这将把这个转换训练集转换为数据框
现在我们准备好执行这条代码来获取我们的新训练集
它包含提取的特征
线性判别分析
让我们这样做
让我们选择并执行这条线
如你所见
训练集仍然是训练集
否则它将在values中
当我点击它时
让我们看看刚刚创建的内容
首先，我们首先看到的是这个第一列
那是因变量本身
我知道这不再称为客户细分
但实际上是客户细分列
这完全相同，用于相同的观察和相同的标签
一个是二和三 但predict函数自动将其称为class
所以不用担心
那是因变量
然后，下一个有趣的事情我们看到的是线性判别分析
Ld一和Ld二
正如我所说的
我们得到的线性判别分析的数量
因为我们的因变量有三类
这就是我们现在关心的
这就是我们将要使用的变量
这是我们将要用于训练svm模型的新提取特征
用于做出预测
用于制作混淆矩阵
最终用于可视化结果
然后我们还有三个其他变量
后一 后二和后三
这些都是从lda模型方程中衍生出来的变量
所以这里并不重要
重要的是我们有我们的因变量类别和我们两个新的提取特征
线性判别分析一和二
现在我们需要做的就是将我们的训练集设置为正确的格式
我们希望的训练集由两个提取特征组成
两个新的独立变量
然后在最后位置是我们的因变量类别，那就是客户细分
所以基本上我们需要在这里做的和pca时做的是一样的
那就是玩弄索引
不仅设置我们列的正确顺序
也不包括这三个列
后一，后二和后三
为了高效，我们会从我们的pca模型中取
取这条线
复制并回到lda粘贴
在这里，好的
和pca一样
我们需要包括三个索引
这个索引是一
那就是这个列的索引
那是12345
所以这是索引5
让我们在这里添加
将2替换为5
然后第二个索引应该是第二个新提取特征的索引
那就是ld d二
那是索引6
这个列的索引是6
让我们将3替换为6，好的
最后这个应该是因变量的索引
这个索引当然是1
因为这个是第一列，它有x1
现在我们执行这条线，好的，看看我们的新训练集
嗯 这正是我们所希望的
前两列是新提取特征
最后一列是因变量向量
这正是代码其余部分所期望的
完美 我们的训练集已经正确转换并准备好用于训练svm模型，好的
现在我们需要为测试集做同样的事情
这样会很快也很容易
我们将选择这里的这两行
复制粘贴
现在我们只需要在这里这里将训练集替换为测试集
最后这里也进行替换，现在我们可以执行这两行
但我们一个一个执行
这是到目前为止的测试集
由13个独立变量组成
原始的变量
当我们选择这一行并执行时
我们只能得到两个新提取的特征
Lone和lt two以及方程式中的三个变量
当然还有因变量class
当我们再次这样做以获取正确的索引并按正确顺序排列时
我们执行这一行
现在我们得到了测试集，前两个新提取的特征在首位，依变量在最后
Lone和lt two以及依变量在最后
完美
现在我们准备好执行剩下的部分来构建我们的svm模型
好的 让我们这样做
实际上我们在这一部分不需要做太多更改
你认为我们需要更改什么吗
答案是因为请记住，依变量不再称为customer segment
即使它是customer segment变量
但这次它有一个不同的名字
即class
而这是我们需要更改的唯一一件事
因为训练集仍然使用相同的名称
只是这里需要转换测试集
没问题 然后类型和核都是一样的
因为我们正在建立一个线性svm模型
完美 让我们执行这一部分
完成
模型创建
现在我们准备好预测测试集的结果
测试结果
我们需要更改一些东西吗
这次答案是不需要
因为我们已经对我们的测试集进行了转换
它有相同的名称
分类器就是这个
一切完美
我们准备好执行这行代码，完美，这里的也一样
我们不需要更改任何东西
我们可以通过执行这行代码创建混淆矩阵，混淆矩阵创建
让我们看看是否也能得到100%的准确率
我们将在闪光灯中看到结果，因为如果有一个错误的预测
好吧 这意味着我们不会像使用PCA时那样获得100%的准确性
这意味着它不会像PCA那样完美
让我们这样做
在这里输入cm并按回车
不幸的是，我们在这里有一个错误的预测
但这并不是一个大问题
因为不仅仅是一个错误的预测仍然非常优秀
但也要记住当我们使用PCA可视化训练集结果时
好吧，我们也有错误的预测
所以我们只是稍微幸运地在PCA中获得了零个错误的预测
好的 所以这仍然是优秀的结果
现在让我们可视化训练集的结果
我们是否需要在这个部分更改任何东西
试着找出如果需要更改
因为这很重要，以便理解这一点
如果你使用这个代码部分来可视化你问题的结果
在你的数据集上，嗯
答案是这次
是的 因为这行代码
命名 期望有真实变量的名称
新提取的特征LD1和D2
所以这里我们需要用PC1和PC2分别替换
X·LD1
因为这是第一个提取的特征名称
第一个新独立变量和X·LD2
第二个新提取的特征
第二个新独立变量
所以让我们替换它们
PC1替换为X·LD1和PC2替换为X·LD2
这非常重要
并且这就是你需要更改CallNames的唯一事情
当你可视化结果时，这里必须包含你独立变量的真实名称
然后，我们是否需要更改其他东西
嗯 我们也可以更改这一点
但这不是强制性的
这只是为了X轴和Y轴的标签
所以不管怎样，我们做吧
这次我们不需要指定独立变量的真实名称
我们可以将PC1替换为LD1
以指定它不是主成分而是线性判别
这里我们可以将PC2替换为LD2，好的
现在完成，
这段代码已经准备好执行
所以让我们快速为测试结果的可视化做同样的更改
所以将P1这里替换为X·LD1
然后将pc2替换为x dot l d2
并将pc1替换为lone，pc2替换为of the two
现在所有事情都准备好了
我们不需要再更改任何东西
我们可以去拿一杯咖啡并查看训练集的结果
以及测试集的结果
让我们这样做
让我们希望一切都没问题
我将选择所有这些部分直到这里
以便可以查看训练集的结果
让我们开始吧 现在我们开始，好的
所以它正在执行
它总是需要一点时间
但我们会到达那里
我们已经可以点击图表了，好的
所以计算几乎完成
这是结果
漂亮的结果
三个类别几乎被很好地分开
完美分开
我们可以看到错误的预测
但请注意 这不是我们在混淆矩阵中看到的错误预测
因为这里涉及到测试集
这里是训练集 所以我们在训练集中还有一个错误的预测
那就是这个 但这几乎完美
这相当直观
因为正如你所记得的
Lda试图分离你的因变量类别
这就是为什么 这里 你可以看到
预测边界大致等距于这里的大多数绿色点
和大多数这里的蓝色点
这太完美了
每个都在正确的客户区域
因此这个葡萄酒业者可以很有信心地预测每个新葡萄酒
他应该向哪个客户群体推荐它
不仅如此 他可以相当自信地向合适的客户推荐新酒
而且，多亏了特征提取技术，他可以将结果可视化为二维
得益于这两个新的独立变量
线性判别
现在，这位葡萄酒业老板可以清晰地绘制出其不同客户群体的不同
在每一个客户群体中放入不同的酒
因此，最终这可能相当方便
好的 如此完美
我们成功地构建了一个伟大的lda模型
所以我们将以这个良好的状态结束
因此我们将进入课程下一部分的内容
这部分将介绍另一种特征提取技术
但这次是为非线性问题设计的
因为这个问题是显然的线性问题
因为我们成功地应用了非常成功的线性模型，如pca和lda
嗯 在这个数据集上应用非线性特征提取模型将不相关
所以我们将处理另一组非线性的数据
接下来我们将看到的新的特征提取技术将是核PCA
所以我期待着在下一节开始 在此之前，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p36 1. Kernel PCA in Python Improving Classification Accuracy with Feature Extractio.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p36 1. Kernel PCA in Python Improving Classification Accuracy with Feature Extractio

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们，欢迎来到这一阶段的最后一项实际活动
九维降维
我们已经构建了两个降维模型
首先是主成分分析，然后其次是线性判别分析
两者都得到了惊人的结果，但线性判别分析稍微更好，实际上完美
结果
所以现在我们希望用我们降维工具箱中的第三种工具
我们至少能得到与PCA相同的结果，或者与LDA相同的完美结果
你们可能猜到，因为我们即将添加一个核
正如我们看到的，SVM和核SVM，添加核总是能改善结果
你可能猜到我们也将得到惊人的结果
好的
让我们开始 让我们构建那个最终的模型
但在这之前，让我们确保每个人都在同一页上
我给你们这个文件夹的链接
在这个教程之前
确保连接它
现在我们开始
让我们进入第九部分和第四十五节核主成分分析
像往常一样，我们将从Python开始
这个Python文件夹包含两个文件
首先是在IPA和B格式中的核主成分实现
当然还有相同的数据集葡萄酒CSV
这是一个许多葡萄酒的数据集
你知道许多不同种类的葡萄酒
每行对应一种葡萄酒
对于这些葡萄酒，我们有这些特征，从酒精含量到脯氨酸
然后对于这些每一瓶酒，我们还有客户细分
这是客户细分，客户属于哪种细分
也就是说每个细分的客户
总共有三个细分，所有客户对这类酒的偏好相同
好的 所以现在
挑战是建立一个逻辑回归模型
结合某些降维技术应用到这个数据集上
以便我们能得到一个更简单的数据集
哪个 同时
将为逻辑回归模型提供一个优秀的学习方式
以学习所有这些特征与因变量之间的相关性
然后对于每一瓶新酒
我们将使用这个预测模型来预测这瓶酒属于哪个客户群体
这样酒店的所有者就可以将每瓶新酒推荐给正确的客户
好的 这就是完全相同的k城市
现在让我们打开这个实现
使用谷歌协同或jupyter笔记本
正如你所见
我保留了这个pca实现和这个lda实现
以便我们可以进行比较
现在，像往常一样
这个实现处于只读模式
因为你们都可以访问它
让我们通过点击文件来创建一个副本
然后保存到驱动器副本
因为确实在这个副本中，我们将重新实现实现核pca的单元格
让我们去掉这个
这样我们就可以清楚地了解三种降维技术
现在我们继续
让我们实现核PCA
但首先这次让我们先上传数据集
这样我们就可以 你知道我们可以借助谷歌协作
现在我们的笔记本正与运行时连接
我们开始 然后点击上传
我们将在线性判别分析文件夹中结束
那么我们再来走一遍整个路径
这就是整个机器学习
这是一个文件夹 让我们进去，让我们去第九部分
降维和第四五节核PCA
Python和y.csv打开
好的
现在我们已经连接上了
我们的笔记本已经连接上了
好的 现在我们要做两件事，首先
我们要删除那个单元格
你知道 把它放入垃圾桶
以便我们可以重新实现它
但是也让你知道
删除所有输出，尽量不要看他们
你知道，我希望，我希望你没有看结果
但是不管怎样
我确信你也期待一个惊人的结果
那么我们在这里删除输出
这是训练集结果的可视化
这是测试集结果的可视化
然后我们将内容表应用于核PCA
我们准备好了
我们准备好实施了
那么我们创建一个新的代码单元
现在我们想重新实现这个
你知道，从头开始实现
或者我们是否想要高效和好
当然，这在某种程度上反映了我作为程序员的精神
作为一名机器学习程序员
我总是希望高效
我的意思是
核PCA的实现几乎与PCA的实现相同
因为基本上它们会几乎相同
除了在输入中我们需要添加一个核
所以我们要做的是
在效率的精神下，我们将
使用我们的PCA实现
我们将使用那个单元格
因为你会看到它们几乎相同
所以我们粘贴那个
在这里，现在我们唯一需要更改的是类的名称
但不是模块
因为我们将要导入的类来实现
核PCA仍然属于这个分解模块
由scikit-learn库提供
这个类是
当然核PCA，就像那样
所以那是类
让我们给对象起一个不同的名称
我们不会叫它PCA
但我们可以叫它 你知道kpca，你想要什么
然后 当然，当我们调用这个类来创建一个这个对象的实例时
我们将这个变量命名为kpca，当然
我们需要调用这个类来创建核PCA对象
然后，当然，在这个类中，我们需要
选择提取的特征数量，这仍然由这个参数指定，components
但是，现在我们正在使用核
你知道，我们做核PCA，
正好就像我们从SVM切换到核SVM一样
我们只需要在这里添加一个核参数
并且我们将选择与核SVM相同的核，即RBF核
这是径向基函数核
就是这样 这是我们的第二个参数
kernel等于引号中的rbf径向基函数
现在让我们看看
看看还有什么需要更改
这一行没问题
下一行代码，同样
为了执行核PCA降维技术
我们只需要x_train的特征，而不是y_train
所以没问题 这跟PCA一样
但不同于LDA
后者需要y_train作为依赖变量
一切顺利
但是请小心
我们重命名了我们的对象
不是pca 而是kpca
所以这里也一样
kpca
现在朋友们
这个实现结束了
这就是结果
你知道的 当我们高效工作时
实现有时比预期更快完成
这是因为，正如你所看到的
核主成分分析与主成分分析非常相似
你知道，在实现方面
好的 现在我们只准备再次运行所有
我们有我们的数据集
我们的实现一切顺利
让我们这样做
点击运行这里
然后三二一运行所有，走吧，好的
所以现在所有单元格都在运行
我们的逻辑回归模型已经构建
正如预期的那样
我们得到 当然，准确率为100%
我极少见过一些情况，你知道的
非核版本的模型击败
核版本的模型
可能会发生 但是很罕见
这就是这里 当然
核主成分分析能够击败主成分模型
多亏了那个核
我们修复了那个错误的预测
我们记得在pca这里
所以这里一切顺利，我们得到100%的准确率
现在让我们看看结果
你知道的，核主成分分析如何能够分离我们的测试集类别
这些是新的观察点
模型没有训练过
看吧 这是我们的两个主成分
pc1和pc2
现在又一次在新的维度中
你知道的 因为风的观察点在这里排列的方式与pca不同
我们这里点的排列方式非常不同
我们可以看到它们比这里更分散
与我们的PCA完全正确
那是因为我们已经进入了一个新的维度
我们在不同的维度
PC1和PC2意味着不同的提取特征
所以这是完全正常的
这些是观察点
你知道 这里的葡萄酒以非常不同的方式排列
那是因为我们已经进入了一个不同的维度
逻辑回归模型完美地分类了我们的观察点
使用这三个预测区域
同样适用于LDA
观察点以不同的方式排列
因为再一次，这些是一些不同的维度
我们在这里进入了另一个维度
多亏了这些提取的特征
所以你看，这种降维技术非常令人着迷
因为它基本上允许创建一个新的维度空间
并且在一些新的维度中
嗯 确实我们可以完美地分类一些观察点
就像线性判别分析和核PCA的情况一样
现在我建议你们练习这个其他数据集
所以我建议例如
检查UCI ML仓库平台
并转到分类部分并尝试在其他数据集中使用核PCA
你会看到你会得到类似的结果
与像这样分离类的预测边界
请分享您的结果在问答部分
特别是那些我们清楚地看到与核PCA相比PCA有改进的情况
你知道也许你会找到一些数据集，Pca表现不佳
然后通过添加核与核PCA
你会得到更好的结果
所以请分享这个
我真的很感兴趣看到你得到的一切
提前感谢 现在祝贺你
这个新的章节关于降维已经完成
现在我们将进入课程的最后一章
第十部分模型选择和提升
在那里你将学习你的三个最后和非常重要的工具
首先是小心交叉验证来评估你的机器学习模型
最好的方法 然后是参数调整来找到你的超参数的最佳值
最后是这个课程的蛋糕上的樱桃
我将教你并给你XGBoost模型
这是回归或分类的最好的和最强大的机器学习模型之一
这将完成你的最好的机器学习工具包 And until then enjoy machine learning
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p37 2. Implementing Kernel PCA for Non-Linear Data Step-by-Step Guide.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p37 2. Implementing Kernel PCA for Non-Linear Data Step-by-Step Guide

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这门艺术教程
现在我们知道如何实施两种特征提取技术
它们是PCA和LDA
但这些特征提取技术适用于线性问题
那就是当数据是可分离的
在这一节中，我们将看到一种新的特征提取技术
但这次是为非线性问题设计的，数据是非线性不可分的
这种技术称为核PCA
核PCA是PCA的核化版本
我们通过核技巧将数据映射到更高维
然后从那里提取一些新的主成分
我们将看到它如何处理非线性问题
我们不会在之前的部分工作在同一问题上
使用葡萄酒数据集
但我们将使用与第三部分分类中使用的同一数据集
因为我们需要视觉
我们需要清楚地看到发生了什么
我们需要看到核PCA如何提取新的独立变量
主成分
即使问题是非线性的
那就是当数据是不可分离的
我们在第三部分使用的这个数据集
社交网络数据集
记得这是一个明显的非线性问题
因为非线性分类器表现更好
让我们使用这个数据集
并应用核PCA以查看它将如何处理非线性
所以让我们找到这个数据集到我们的工作目录文件夹
所以我们会去到我们的机器
那是文件夹
然后部分九降维
这里是这个部分的最后一节
九核PCA
那是你想要设置为工作目录的文件夹
确保你有社交网络CSV文件
如果那是情况
你将点击这里更多按钮
将文件夹设置为工作目录
现在我们要做的是取这个逻辑回归模型
因为你知道这个逻辑回归模型是一个线性分类器
因此它不适合我们的问题
因为我们的数据是不可分离的
所以我们将取这个线性分类器
但我们将应用核PCA在它里面
以查看核PCA将如何挽救情况
所以你将看到即使我们应用一个线性模型
感谢核PCA
我们设法提取了适应于这种不可分离数据的新主成分
你将看到结果会非常棒
所以现在让我们从上到下复制整个模型
让我们把它粘贴到我们的核PCA文件中，好的
现在
基本上，我们唯一要做的就是在正确的地方应用核PCA
但在我们做之前
我想让我们再次可视化
为什么这个线性模型不适合这个数据集
所以我们要做的就是从这里开始
因为你知道 这将通过绘制预测区域和预测边界来可视化训练集的结果
所以我们将从这里开始到顶部
你知道 导入数据集
应用预处理阶段
将逻辑回归拟合到训练集
最后绘制训练集的结果
让我们开始吧
让我们快速可视化
这将给我们动力去应用核主成分分析
这里一切都正确执行
所以作为提醒，点表示真实的观察值
那就是我们在社交媒体上的真实客户
代表他们的年龄和他们估计的薪水
这就是我们真正的观察点
我们的预测由这些区域表示
这里的红色区域和这里的绿色区域
基本上
这个红色区域是我们模型预测客户不会点击广告的地方
并且这里这个绿色区域是区域
在模型预测客户会点击广告并购买SUV的地方
因此，记住问题在于这条直线实际上是预测边界。
由逻辑回归模型生成
但由于逻辑回归模型是一个线性分类器
那么它必须在这里用一条直线来分离数据
因此请记住，问题是它无法在这里做出某种曲线
来捕捉这些绿色用户
这些绿色用户现在应该在绿色区域，但他们却在红色区域
因此这清楚地表明我们的数据是不可线性分离的
因为我们可以清楚地看到，这里扮演分离者角色的预测边界
并且它应该很好地分离两个类别
它不能正确地分离两个类别，因为你可以看到
这些用户不在正确的地区
所以现在我们要做的是不要做一个非线性分类器
就像我们在第三部分做的那样
你知道 当我们制作核SVM时
朴素贝叶斯 决策树或随机森林
嗯 现在我们要做的是应用核PCA
这样我们就能保持一条直线作为分隔符
线性分类器的预测边界
仍然是逻辑回归模型的预测边界
但我们将应用核PCA
这将设法应用一些技巧
这个技巧实际上是核技巧，将数据映射到更高维
然后应用PCA提取新成分
这些新成分是新维度，解释了数据的变异性
但由于这个核技巧
你将看到我们能够得到一些新维度
在这些维度中，数据将可以被线性分类
即使使用线性分类器如逻辑回归
所以现在让我们看看这一点，我等不及要展示给你看
我将关闭这个
现在让我们在正确的位置应用核PCA
你已经知道这是哪里
实际上与以前没有区别
我们需要在数据预处理阶段之后，但在将分类器如逻辑回归拟合到我们的训练集之前
所以基本上我们需要在这里应用核PCA
所以新部分在这里
应用核PCA，让我们开始
让我们这样做
首先我们需要安装一个新的包，称为kerlab
我认为我们之前没有安装过它
所以现在让我们这样做
我们使用命令install dot packages
在这里，kerlab
我已经安装了它，我认为
让我们检查一下
这就是kerlab，基于核的机器学习实验室
所以我不会安装它
但如果你想这样做
你只需选择这条线并执行
所以我会把这条线作为注释
在这里
但是既然它没有被导入 我将使用这个命令导入它
current lab
这将导入它
current lab将导入它
现在让我们开始应用核PCA
就像PCA和LDA一样
我们将首先创建一个对象
这将是我们将要使用的核PCA对象
来将我们的原始数据集转换为使用核技巧后的新数据集
所以我们将创建一个k pca对象
然后等于
我们将使用创建这个核PCA对象的函数
这个函数也是k pca
然后括号，让我们输入不同的参数
让我们检查一下
让我们在这里按f键看一下参数
第一个参数是x
实际上这是数据矩阵或描述模型的公式
我在这里给你一个小技巧，非常简单和高效地描述模型
我们可以简单地输入这里一个波浪号
并且这将足够kpca函数理解公式是什么
因为接下来我们会添加第二个参数
这是数据
实际上这是训练集
但是不要包含因变量
因为记住核主成分分析只是主成分分析技术
我们使用核技巧将数据映射到更高维
然后在这个更高维应用主成分分析，确实在这个更高维数据是线性可分的
因此，因为我们在这个更高维应用主成分分析
并且主成分分析是一个无监督技术，在这里对于数据参数
我们只需输入训练集
但是不要包含因变量
因此对于主成分分析
我们输入这里 数据等于训练集
然后括号去掉因变量，索引为3
因为我们只有两个自变量，好的
然后下一个参数是核
所以核是你要使用的核来应用核技巧
记住当我们研究核支持向量机时
我们看到有几种核可以使用核技巧
我们将使用最常见的一个
那就是高斯核
这在这里称为rbf点
所以这是我们的第三个参数
因此我们输入核等于rbf点，好的
然后下一个参数是什么
下一个参数是kbar
我们将实际上不使用这个
但是有一个非常重要的参数，那就是维度减少的核心
那就是特征
这是您想要得到的特征数量
您想要得到的主成分数量
所以这里 当然我们希望在二维中可视化训练集结果和测试结果
要在二维中这样做
我们需要保留两个新的提取的自变量
所以这里特征数量将是2
对于主成分分析
因此我们将输入这里特征等于2，好的
这就是我们的kpca对象
它已经准备好被创建
并且被用来将我们的原始数据集转换为这个新的数据集
具有从核主成分分析衍生的新提取特征
所以让我们选择这条线并创建对象，这里是kpca，已经创建
现在我们继续进行下一步
就是把我们的原始数据集转换为这个新的提取数据集
所以现在事情看起来就像我们做的主成分分析一样
但有些事情会发生变化
所以我们将一步一步来做
我们会看看哪里需要我们做一些改变
所以首先对于主成分分析
我们将使用预测函数将我们的原始训练集转换为这个新的提取训练集
这个新的带有新提取特征的训练集是从核主成分分析中衍生出来的
我们将其称为训练集下划线pca，好的，然后等于
然后我们使用预测函数来进行转换
在这个预测函数中，我们首先输入我们的k pca对象，就像我们做的pca一样
然后是训练集
原始的训练集
所以让我们做训练集第二项，好的
与pca相反
与lda一样
这将返回一个矩阵，我们需要将其转换为数据框
就像lda一样
我们将使用as.data.frame函数
所以这里打括号，在这里关闭括号，设置两个集
这变换训练集
训练集pca作为一个数据框
作为提醒，我们做这个给下一个函数使用
在下一节中
到目前为止一切都好
所以现在让我们选择这条线并执行
你将会看到发生了什么
你将会理解为什么我们称这个新的训练集为training set pca
与原始训练集的名称不同，训练集所有正确
所以让我们在这里执行
我们正确执行它
现在让我们看一下我们刚刚创建的训练集PCA
所以我要放大这个
这样我们就可以看到哪个是PCA的应力
那是其中之一，所以让我们看一下
我将点击它
这是我们的PCA训练集
正如我们所见，它只包含两列
V one和V two
所以试着猜出这两列是什么
我现在告诉你
这两列是我们通过核PCA获得的主成分
也就是说，这是我们提取的两个新特征
在所有这些映射到更高维之后
使用核技巧
然后在数据集映射到更高维后应用PCA
但现在的问题是在这个训练集中，PCA
我们没有依赖变量，我们需要它来进行接下来的部分
因为我们的代码模板中我们需要有自变量和因变量
那么接下来的步骤是什么
现在，下一步是将因变量添加到这个训练集的PCA中
所以这里要理解的是，我们失去了因变量
但我们保留了观察值
也就是说，这里对应的是我们在原始训练集中第一个观察值
所以这里的第一个观察值带有零标签
也就是说，这个第一个客户没有购买SUV
这是我们的原始自变量
然后如果我们转到我们的训练集PCA
好吧 这个第一个客户就是这个训练集的第一个客户
因此，它将在购买列中获得零标签
但是，这些都是我们新提取的特征
因此当然我们不会得到相同的值
至于我们原始训练集的自变量
所以我们现在可以做的就是简单地从这个原始的训练集中选择依赖变量列purchased
并将它添加到我们的PCA训练集。
因为这些观察结果与我们的原始训练集相同
现在我们需要做的是非常简单的事情
我们只需要对我们的训练集进行PCA
然后我们将要添加一列，我们称之为purchased
通过这样做
你知道我只是创建了一个新的列，我也称之为purchased
因为这一列是新的购买依赖变量
然后等于
现在我必须做的是从原始的训练集中获取真实的购买
依赖变量列
我们可以这样做
因为PCA训练集包含与原始训练集相同的观察值
所以，这里是来接收原始训练集的购买列
我们需要的只是我们的原始训练集
它被称为训练集
然后美元，这就是我们接收购买列的地方
通过这样做
我将添加一个新的列purchased
在这个新的列purchased中
我将包括原始训练集的购买列的值
让我们检查一下
我将选择这条线并执行
现在你可以看到
如果我回到PCA的训练
这包含原始训练集的购买列
这很好 这是下一步完成的
现在我们需要处理测试集
为了处理测试集
我们将与处理训练集做同样的事情
PCA，所以让我们复制这个，复制并粘贴到这里
当然现在我们要做的就是替换这个训练集
主成分分析测试集
同样，我们将原始测试集用于转换
然后我们将添加原始测试集的购买列
到这新的测试集
那是从核主成分分析中提取的测试集
所以这里测试和那应该没问题
所以我将选择这两行并执行，完美，我们的新测试集
主成分分析已完成
让我们快速检查一下
这是测试集
这就是我们的测试集
使用两个新提取的特征和购买列进行PCA
现在我们已经正确应用了核PCA，太好了
我们准备好进入下一节了
让我们回到核PCA的R文件
现在我们将逻辑回归拟合到训练集
现在我们需要对这段代码做任何更改吗
是的 当然，因为我们要小心
我们调用了新提取的训练集
训练集PCA
所以对于数据参数这里
我们需要指定训练集PCA
所以这是我们需要更改的唯一部分
所以我们可以选中这部分并执行所有操作
这已经准备就绪 现在让我们继续到下一个部分预测测试结果
当然这里也是一样的
我们需要将测试集替换为测试集PCA
我们将稍微放大这个部分
这就是我们准备执行这段代码来预测测试结果的步骤
让我们开始吧
我们得到了一个新的测试集的预测向量y_pred
PCA，好的
让我们制作混淆矩阵
当然我们需要将测试集更改为测试集
PCA
让我们开始
现在准备好了
现在我们可以执行这行代码来获取混淆矩阵
这就是它 我们可以通过按cm进入控制台快速查看
我们得到57加上26等于83
因为我们在测试集中有100个观察值，这意味着我们的准确率达到了83％
这相当不错
现在让我们进入令人兴奋的部分，即可视化训练集的结果，所以非常快速
我们需要改变什么
记住我们需要改变自变量的名称
在这里我们需要更改名称，这是强制性的
所以作为提醒
名字是v1和v2
那是自变量的名字
所以我们需要将h替换为v1
估计的工资替换为v2，这不是强制性的
而且我们本来就有好的名字
pc1和pc2
所以不要忘记这一点
当然我们需要更改训练集的名字
因为我们将训练集称为训练集pca
所以这里我添加了训练集pca
这完美了
这已经准备好执行以可视化训练集的结果
所以我们将只可视化训练集的结果
让我们对测试集做同样的更改
这样你可以自己看看
所以我们将h替换为v1
估计的工资替换为v2
这里我们将测试集替换为测试集_pca
好的
现在让我们看看
我很期待向你展示将要发生的事情
所以我将选择这里的所有内容到顶部
这里是整个部分以可视化训练集的结果
让我们按command和control
加enter执行
好的 计算正在进行中
好的 这些是核pca的结果
与逻辑回归模型结合在一个非线性可分离的数据集上
因此 我们可以欣赏到得到的简单结果与幕后复杂性的对比
因为确实我们在这里得到了非常简单的结果
这些类别由这条直线分开
但是
在幕后发生的事情是，我们的原始数据集在原始特征空间 被映射到一个更高的维度，使用核技巧来避免两个计算密集的计算
然后通过将我们的数据集映射到原始特征空间到更高的维度
首先创建了一些新维度，主要是创建了一个新的特征空间，在那里我们的数据变线性可分
但是，通过这样做，我们仍然需要应用到原始维度数更多的维度的pca降维技术
所以
我们仍然需要应用到原始维度数更多的维度的pca降维技术
因此，pca应用到这个新的特征空间，数据在那里线性可分
通过pca创建了一些新提取的自变量 它们只不过是pca的主成分
最终我们得到了这个新的特征空间
通过这两条新提取的主成分组成的PCA
现在数据可以被线性分离，线性分类器可以将其更好地分离
好的 这就是核PCA的全部内容
这也是本部分的结束
这是降维的部分
我们下一部分再见
第十部分：模型选择和提升
这是课程的最后一部分
我们将介绍机器学习中一个非常令人兴奋的算法，称为XGBoost 我很期待下一部分见到你，直到那时享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p38 1. Mastering Model Evaluation K-Fold Cross-Validation Techniques Explained.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p38 1. Mastering Model Evaluation K-Fold Cross-Validation Techniques Explained

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                好的 欢迎回来，今天我们要谈论的是K折交叉验证，这是一个非常重要的工具，用于评估模型在现有数据上的表现。
通常我们做的是
我们有一个数据集，通常我们将其分为训练集和测试集
好的 我们从这里开始谈论K折交叉验证
但是首先，我想快速说明一下
所以，有两种思维方式
基本上，第一种思维方式是，当你进行K折交叉验证的时候，你不需要测试集
第二种思维方式是，你还是需要测试集
并且你在训练集上进行K折交叉验证，然后稍后你还是使用测试集
这两种不同的方法 我们将在教程结束时详细讨论
在整个教程中
我们将采用第二种思维方式
因为它更通用
然后我们可以简化它，以便在最终教程中适合第一种思维方式
现在
让我们将数据集分为训练集和测试集
一旦你划分了它
接下来你将要做的就是训练模型并测试模型
你将得到一个结果
是的，模型没有见过这些数据
所以你可以告诉你它如何在测试集上表现如何
但如果你只是在测试集上幸运 如果它恰好在这个测试集上表现良好
但在未来数据上它根本不会表现良好
这就是K折交叉验证的作用
它这里是为了应对这种情况
以确保你更确定你的模型表现良好
我们将做如下操作
我们将训练集分为十折
然后我们将训练模型并测试模型
你将得到一个结果
是的，模型没有见过这些数据
所以你可以告诉你它如何在测试集上表现如何
但如果你只是在测试集上幸运
如果它恰好在这个测试集上表现良好 但在未来数据上它根本不会表现良好
这就是K折交叉验证的作用
它这里是为了应对这种情况
以确保你更确定你的模型表现良好
我们将做如下操作
我们将训练集分为十折
然后我们将训练模型并测试模型
你将得到一个结果
是的，模型没有见过这些数据
所以你可以告诉你它如何在测试集上表现如何 但如果你只是在测试集上幸运
如果它恰好在这个测试集上表现良好
实际上它是K折
但是
为了教程的简便性
我们假设K等于十
所以它被分成十折
折只是一个华丽的词，意思是
我们将其分成十部分
每一部分大约是这个大小
它们大小相当，且不重叠
嗯 那么我们要做的就是
我们将数据训练在
嗯 这九个折中训练数据，并将一个折作为未见数据用于验证
这将是我们的训练数据
这将是我们的验证数据
想象这基本上是训练数据
测试数据 但是我们将使用验证
这样我们不会混淆这种口味测试的测试数据
所以我们将在这上面训练它
这九个折的数据
然后在这上面验证或找到我们的指标
并计算我们需要计算的一切，看我们的模型在这验证集上的表现如何
设置一个验证折
因为它之前没有见过，很好
然后我们再做一次
但是现在我们将把验证折移位
验证错误成为这个错误
所以现在我们将在这九个折上对数据进行训练
您可以看到，训练数据略有变化
验证折是完全新的
或者验证错误是完全新的
再次，它在训练过程中不会被看到
所以我们将得到一个新的模型作为训练的结果
一个新的训练模型
我们将在这个折上进行验证并记录
注
每次我们做这个时，无论是为了每个故障还是为了每个故障的组合
在这里和这里，我们必须使用相同的超参数，这非常重要
所以我们已经决定了我们的超参数
现在我们只是再次训练模型，使用稍微不同的训练数据
并在验证集上进行验证，该验证集正在变化
正如你所看到的，验证集正在移动
这是我们的六次训练
所以我们在这所有数据上训练它
然后在这个故障上进行验证
这个故障在训练过程中没有看到
所以我们一直这样做
而你不断变换变换
如果我们有十个折 我们将不得不训练更多的十次训练训练十个模型
每次我们都将使用相同的超参数
模型超参数
在训练期间，模型和超参数是相同的
当然，这将导致结果略有不同
然后在验证折上进行验证
结果我们将有十组指标
记住，如果我们只使用训练集和测试集，只有两个
那么我们只能得到一组指标，我们可能会很不幸
而 here 我们将有十组指标
我们十次都走运的可能性要小得多
因此，现在我们将拥有十组指标，这将更加可靠
我们可以看看它们并进行汇总
这就是我们将要做的
所以让我们腾出一些空间
在这里我们将评估这些指标
并汇总它们
如果这些指标汇总后看起来不错
那么建模方法就是有效的
因此，您选择的模型和超参数对于这些数据是有效的
然后，我们将进行训练
我们将再次训练模型
最后一次 这次我们将使用所有训练数据进行训练
然后像往常一样在测试集上进行测试
这是我们的最后一步
另一方面
如果汇总指标看起来不佳
那么一定有问题
否则我们需要
如果他们看起来不好
我们需要调整模型的超参数
或者我们完全改变模型，并重复整个K折交叉验证过程
这就是K折交叉验证的工作原理
这就是它的工作方式 正如我们开始时讨论的
有几种学派
这是第二种学派
他们没有数字
这是一派的观点，认为应该使用训练集
在训练集上应用K折交叉验证
然后根据指标重新训练模型
然后在测试集上进行测试
另一种学派认为，让我们去掉这个测试步骤
我们已经多次运行了模型在这里
所以
我们已经在这组验证指标上进行了测试
我们将在训练集上训练模型
我们不再需要测试它
我们已经测试过它 我们知道它起作用
还有一种修改这种思想的方式
你不再需要在训练集上训练它
所以你只是说
好的 嗯 我们已经在这里训练了模型十次
我们有十个不同的模型
结果 我们已经测试了所有这些
我们不需要再进行测试
我们不再进行训练
我们只是选择一个这些模型
嗯 在我看来，这有点具有挑战性
你如何选择哪一个
你将选择所有最佳指标中的一个
这将为你选择模型创造一些额外的工作
因为它们都将是稍微不同的模型
因为底层的训练数据略有不同
嗯，这也是一个选项
然后，关于k折交叉验证的另一种思考方式
你可以这样做
首先做这部分
你知道，首先做经典部分，将数据分为训练集和测试集
在训练集上训练模型
在测试集上测试模型
如果你对这经典方法的结果满意
你可以再走一步，应用k折交叉验证
做所有这些
但在训练和测试之后
所以，一旦你做完了所有这些
如果你的汇总指标仍然看起来不错
那么你就可以确认并说
我很高兴
即使我在测试集上没有走运
基本上，它确实
事实是它在测试集上起作用并不是侥幸
实际上我们，我在后来测试了它
我使用k折交叉验证测试了它，它仍然有效
所以我将保留我原始的模型，我在第一种方法中训练的
所以，在这种情况下
k折交叉验证就像你的经典方法的一个附加组件
这与我们讨论的是同一件事
嗯 这是所谓的通用方法
最通用的小心谨慎的交叉
当你做所有事情之前
然后训练 然后测试
这基本上是相同的事情 但它只是反过来做
所以你可以做到
也 嗯
无论你喜欢什么
无论什么适合你
只要啊
你知道你为什么这样做
并且你知道
像什么结果你正在追求
并且你知道如何评估
k折交叉验证给你提供的指示
其余的细节
没有像你必须这样做的硬性规定
只要你得到结果
我们得到k折交叉验证的好处
你正在追求的 当然
你不让
验证数据泄漏到训练数据
所以你不让模型在训练期间看到验证数据
或者在训练集期间看到测试集 好的
这就是k折交叉验证
恭喜你为你的模型评估工具包添加了一个新工具 我期待下次再见到你，直到那时享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p39 2. How to Master the Bias-Variance Tradeoff in Machine Learning Models.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p39 2. How to Master the Bias-Variance Tradeoff in Machine Learning Models

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎回来今天
我们有一个非常令人兴奋的教程
偏差方差权衡
所以为了操作这些术语
让我们首先定义它们
偏差是机器学习模型本身产生的系统性错误
由于机器学习过程中的错误假设
技术上它可以被视为平均模型预测与真实值之间的误差
而方差是模型如何根据给定数据集进行调整
嗯 方差指的是模型变化
在使用不同的训练数据集部分时
现在让我们可视化这来更好地理解它
但我们首先会提到我们之前讨论过的事情
那就是K折交叉验证
所以，在K折交叉验证中
我们有这些指标
所以我们做了我们的
嗯 我们分割了我们的集
我们有一个训练集 然后我们将这个训练集分成十份
然后我们用这九份合并的训练集来训练模型
然后我们在这个剩下的一份上进行验证或测试
然后我们用这九份训练集来训练模型
然后我们用这一份来测试模型
因此，结果
每次我们稍微改变训练数据
然后我们在一个新的，嗯，数据上验证或测试结果模型
就像在不相关的数据上
在训练期间未被看到 因此我们得到了这些指标集
在十折交叉验证情况下
现在我们有十个指标
如果我们将此绘制在偏差方差曲线上
或者比喻性地说在左上角
我们会有高偏差低方差
这就是当你有高偏差低方差时会发生的情况
这就是你想要预测的
这是目标 但是你的模型是所有这些预测，这些我们刚刚看过的所有模型
它们远离目标
但它们聚集在一起，所以这意味着什么
这意味着模型过于简单，没有捕捉到数据的底层趋势
所以它远离目标
但同时它们聚集在一起
另一方面 你可能处于这种情况，低偏差和高方差
所有这些模型的平均值在目标上
但同时，正如你所看到的，每次我们稍微改变底层训练数据
模型的结果是不同的或变化的
嗯
很低 偏置低
方差高 这意味着模型过于敏感，捕捉到了噪声，就像捕捉到真实趋势一样
它过度拟合到我们的数据
这两种情况中的任何一种
正如你所想象的那样
都是不好的 所以这种情况下我们远离目标
这种情况下我们
嗯
过度拟合到数据
当然，你也可以有这样的错误
这里有高偏置和高方差
这些预测的平均值在这里
这也远离我们希望的地方
他们也分散在
这是 嗯 这可能是三种情况中最糟糕的
模型过于简单，无法捕捉数据趋势
它太敏感
它也捕捉到了噪声
所以这些都是非理想的情况
这里是理想的情况
嗯 数据聚集在一起，就像独角兽一样
所以你有低方差
它在正确的位置周围
所以平均值是我们想要预测的平均值
所以 因此它有低偏置
这是一个伟大的模型
它实际上准确地捕捉到了它
捕捉了数据的底层趋势，并能很好地推广到未见数据
现在问题是这是很罕见的
这有点像捕捉到这种情况的独角兽
大多数时候你都会在这之间交易
如果你让你的模型非常复杂
那么你确实会得到一个很好的平均分数
你会非常接近你所预测的
但你会捕捉到噪声，数据会
只要数据稍微改变
你的模型预测就会出错
从这个意义上说，这不是一个好的模型
或者如果你让它更简单
所以如果你的模型非常复杂
即使它不那么复杂，它也会在这里
它会在这里结束
嗯 当它过于简单以至于无法捕捉到这一点时，它会在这里
所有的预测都会非常接近
但它过于简单，无法捕捉到目标
因此，你将不得不在这两者之间进行权衡
要么使模型更简单，要么更复杂
并在两者之间找到平衡点
并尽量接近这种情况
这就是偏差方差权衡的工作方式
这就是我们如何将其与K折交叉验证结合使用的
以便更好地评估和理解我们的模型 我期待着在下次见到你们，直到那时，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p40 3. K-Fold Cross-Validation in Python Improve Machine Learning Model Performance.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p40 3. K-Fold Cross-Validation in Python Improve Machine Learning Model Performance

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这个Python教程
欢迎来到第十部分，模型选择和提升
在这一部分，我们将做两件事
首先 评估我们的模型性能
其次，提高我们的模型性能
然后，会有一个关于机器学习中最强大算法的附加部分
它变得越来越流行
那就是XGBoost
但是首先 我们希望能够提高所有机器学习模型的模型性能
我们在这门课程中已经构建了
提高模型性能可以通过一种称为模型选择的技术来实现
这涉及选择机器学习模型的最佳参数
因为你知道 记住每次我们构建机器学习模型时
我们有两种类型的参数
第一种是模型学习的参数
这是参数在运行模型时更改并找到最优值的参数
然后第二种类型的参数是我们自己选择的参数
例如 核参数在核SVM模型中
这些参数被称为超参数
因此，仍然有改进模型的空间，因为我们仍然可以选择这些参数的一些最优值
但由于这些参数不是模型学习的参数
那么我们需要找到另一种方法来选择这些参数的最优值
对于超参数
而这就是我们在本部分十中要做的强大之处之一
这将通过非常有效的技术称为网格搜索来实现
但在我们开始网格搜索之前
我们需要优化我们的模型评估方式
因为我们到目前为止所做的是将数据集分为训练集和测试集
你知道我们在训练集上训练了模型，并在测试集上测试了其性能
这是评估模型性能的正确方法
但这不是最好的方法，因为我们实际上有方差问题
方差问题可以通过以下事实来解释
当我们在测试集上获得准确度时，
如果我们再次运行模型并在另一个测试集上测试其性能，
我们可以得到非常不同的准确度
因此，仅凭一个测试集的准确度来判断模型性能实际上并不十分相关
这不是评估模型性能最有效的方法
因此有一种叫做k折交叉验证的技术可以大大改善这一点
因为这样可以解决方差问题
那么它是如何解决的呢
当k等于10时，它将训练集分为10折
大多数时候k等于10
我们在9折上训练模型，并在最后一折上进行测试
由于有10折
我们可以创建10种不同的9折训练模型组合
并在一种折上进行测试
这意味着我们可以训练模型
并在10种训练和测试集的组合上测试模型
这将给我们提供一个更好的模型性能的想法
因为我们可以在之后
计算这10次评估的不同准确率的平均值
并且计算标准差来查看方差
因此我们的分析将更加相关
此外，我们还将知道这四种类别中的哪一种
因为如果我们得到一个好的准确率和小的方差，我们会在左下角
如果我们得到一个高的准确率和高的方差
我们将在底部右方的模型
如果我们得到一个小的准确率和低的方差
我们将在上方左方的模型
最终如果我们得到一个低的准确率和高的方差
我们将在上方右方的模型
所以这种K折交叉验证非常有用
并且除了我们的性能分析更加相关
所以让我们开始这种K折交叉验证
我们的第一个模型选择技术
所以我们已经构建了很多模型
我们不会再建一个
我们将使用我们建造的一个模型并应用
K进行交叉验证
我们将使用的模型是这一种核SVM
我们在第三部分中制作的分类器
记得我们使用它来预测
客户是否会在社交媒体上点击广告购买
或者不 SVM
所以模型已经建成我们已经有了一切
所以我们要做的是取整个模型
我们将在它内部添加一个新的section code，它将会
当然，这将会实现k折交叉验证
在我们开始之前
让我们选择正确的文件夹作为工作目录
所以我们去文件探索机学习a到z
我们现在是这门课程的最后一部分
恭喜你达到了这里
第十部分模型选择和提升
和第四部分模型选择，好的
确保你有社交网络在CSV文件中
如果那是事实
那么你已经准备好了
所以现在 我们将如何应用k折交叉验证代码部分呢？
由于这涉及到评估模型性能
将代码放在建立我们的核SVM模型之后是最相关的
这是在我们建立模型之后
实际上在这里我们有测试集的预测结果和混淆矩阵
这实际上是评估模型的一种方式
正如教程开始时所说
这是评估模型的正确方法
但不是最好的方法
在今天的教程中，我们介绍了一种更好的方法来评估我们的模型
让我们放在这个部分之后
作为一种更先进的性能评估方法
所以我们将称这部分为应用K折交叉验证
所以现在让我们开始
当然，首先导入正确的类来完成工作
更准确地说，导入正确的函数
这个函数叫做交叉验证核心
它来自模型选择模块
这是我们在这里导入训练测试分割函数的同一模块
用于将数据集分为训练集和测试集
这是一样的
让我们做吧 导入交叉验证评分函数
所以从sk learn模型选择这里我们导入交叉验证评分
已完成
现在让我们在训练集上应用K折交叉验证
在应用它之前
我们需要理解它将返回什么
它将实际返回每个十种组合的十个准确率
你知道
由于每个组合由9个折用于训练模型 和一个折用于测试它
正如前面所说
我们将得到十个组合和因此十个准确率
首先做的是定义一个向量
我们将其称为准确率
它将是向量
将计算通过K折交叉验证创建的十个组合的十个准确率
最终，这个准确率向量将由十个元素组成
这些十个元素将是十个准确率来评估我们的模型
所以现在我们必须使用此交叉验证核心函数
非常有效地应用K折交叉验证
交叉验证评分，然后括号
然后我们输入不同的参数
让我们看看这些参数
我将按command i在这里检查此交叉验证评分函数
所以看看第一个参数是estimator
那是你的模式
那是你的分类器
我们是如何称呼我们的分类器的
我们称之为分类器
所以这里我们必须输入estimator等于分类器
所以第一个参数是我们的estimator分类器
然后第二个参数是x
拟合数据的数据
这就是实际的训练集
因为K折交叉验证是应用在训练集上
但这是训练集中的特征矩阵部分
因此x将是x_train
因为我们的训练集由x_train特征矩阵组成
和y_train的依赖变量向量
所以这里我们添加x等于x_train
下一个参数 正如你可能猜到的那样是y和y
当然它是训练集的依赖变量向量
如你所见 它是在监督学习中试图预测的目标变量
并且这仍然对应于训练集
当然这就是y_train
所以这里我们添加y等于y_train
下一个参数是groups
但这里实际上并不重要，同样对于scoring
我们不是最关心的，我们最感兴趣的是这个cv参数
因为cv参数实际上是你想要将训练集分成多少折
最常见的cv数实际上是10
大多数时候你会使用10折交叉验证
因为10折交叉验证意味着你会得到10个准确率
10个准确率实际上足够让你对模型性能有一个相关的想法
所以这里我们添加cv等于10，完美
实际上这就是我们在这里需要的所有内容
为了进行有效的K折交叉验证
如果你在处理一个非常大的数据集
你可以添加这个end jobs参数并将其值设置为-1
因为-1意味着你将使用你机器上的所有cpu
因此你的K折交叉验证将运行得更快
但这里没问题
这个教程的目的不是为了处理一个大数据集
它实际上是为了学习如何应用K折交叉验证
所以现在我们准备好得到10个准确率
因此我们将对我们的模型性能有一个更好的想法
让我们这样做
让我们从这里选择所有代码行
这将运行预处理阶段
将核SVM模型拟合到训练集
放置测试集结果
制作混淆矩阵
这就是第一个性能评估方法
这是我们更先进的性能评估方法
K折交叉验证
更准确地说是10折交叉验证
让我们看看结果
所以让我们按command + enter执行
我们开始了
我们刚刚有一个数据转换警告
因为某些整数被转换为浮点数
现在没问题了
让我们看我们的准确度向量和变量探索器
所以这里是准确度
如果我们打开它
我们可以得到交叉验证过程的十个准确度
那么我们在这里看到了什么
我们可以看到为什么这样做是有意义的
因为第一个准确度是80%
但然后第二个准确度是96%，然后是80%
然后百分之九十三
百分之八十六 百分之八十三
这显然证明了我在这个教程开始时告诉你的
当你在一个测试集上测试模型的性能时
你会得到一个准确率
但当你再在一个不同的测试集上测试它时
你可能会得到一个完全不同的准确率
因此，仅在一个测试集上评估模型的性能并不很有意义
现在，有了K折交叉验证
我们在十个测试集上测试它
因此我们将得到
并且 因此现在我们要做的就是取所有这些十个准确率的平均值
这将给我们提供一个更好的了解我们模型的平均性能
所以让我们点击确定，让我们得到这个平均值
实际上非常简单
我们只需要取我们的准确率向量这里我们走
然后只需添加一个点
然后只需添加平均函数
这就是运行
这将给我们这个准确度向量的十次准确度的平均值
我们得到90%
这意味着这十个准确度的平均值实际上是90%
因此，结论是
这个90%的准确度是我们模型性能的相关评估
它不是80%
它也不是96%
它是至少十次模型评估的平均值
这十次准确度是完美的
如果我们想要进一步分析
我们可以计算这个准确度向量的标准差
这将告诉我们是否存在高变异或低变异
这也是非常有趣的
要做到这一点，我们做同样的事情
我们取我们的准确度向量
然后我们添加一个点
然后使用std函数
这将给我们这个准确度向量的标准差
所以这就完成了
让我们运行它，我们得到一个6%的标准差
这意味着什么
这意味着当我们评估我们模型的性能时，不同准确度之间的差异的平均值是6%，而我们的平均准确度是90%
所以那并不是太高的方差
这是可以接受的
因为当我们评估我们模型的性能时，大多数时候我们会在84%和96%之间 这意味着我们在低偏差和低方差的类别中
所以这很好
现在恭喜你
你已经有了一种更先进的评估模型性能的方法，这将成为你数据科学工具包的一部分
但在接下来的教程中，你将会看到一种非常强大的技术
它将帮助我们选择任何机器学习模型构建的最佳超参数
所以我期待着在下一个教程中做这件事 直到那时，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p41 4. Optimizing SVM Models with GridSearchCV A Step-by-Step Python Tutorial.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p41 4. Optimizing SVM Models with GridSearchCV A Step-by-Step Python Tutorial

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 我的朋友们 欢迎回到这个模型选择部分
在上一个教程中
我们实现了k折交叉验证技术
这是你现在拥有的一种新工具
以便能够衡量模型性能的最相关方式
现在我将给你提供一个额外的工具
那就是网格搜索
它将允许你找到任何模型中超参数的最优值
因此可以获得比你所知道的标准模型更高的准确性 所以我们将使用完全相同的数据集
社交网络广告
所以我不会再次提醒这一点
因此让我们打开我们的网格搜索实现
无论是谷歌协作笔记本还是jupyter笔记本
实际上这个网格搜索实现与这个完全相同
我们只是再添加一个额外的单元格
这将应用网格搜索来找到最佳模型和最佳参数
最佳模型版本
实际上核SVM的版本
准备好了吗 我相信你已经准备好了
让我们立即创建一个副本
因为这个文件处于只读模式
然后我们将 你知道的再实现那个单元格
构建网格搜索技术
好的
让我们现在删除这个
因为我们将使用我们的副本工作
然后继续
让我们现在删除这个
因为我们将使用我们的副本工作 然后继续
让我们现在删除这个
因为我们将使用我们的副本工作
然后继续
让我们现在删除这个
因为我们将使用我们的副本工作
然后继续
让我们现在删除这个
因为我们将使用我们的副本工作
然后继续
让我们现在删除这个
因为我们将使用我们的副本工作
然后继续
让我们现在删除这个
因为我们将使用我们的副本工作
然后继续
那是scikit learn的网站
然后请到这里查看API
你知道如何找到所有类和函数
记住核SVM实际上在SVM部分
所以我们必须向下滚动来找到S字母
我们应该很快找到它
在那里，我们找到了支持向量机
K learn dot svm
这就是scikit learn库中的SVM模块
记住类是这个svm dot svc
正确 如果我们知道
检查我们的实现
你知道我们导入了这个svc类
来构建这个核支持向量机模型，使用径向基函数核
好的
所以k为交叉验证网格搜索
好了，回到sklearn api
我想向你展示的是，确实
核SVM模型有许多超参数
我提醒您，超参数是参数
这些参数不是在训练过程中学习的
您知道这些是与权重不同的参数
或者 您知道这些超参数有很多
您知道这些有很多
您有c参数
这是调节参数，您可以调整它
实际上可以提高训练性能，通过减少过拟合
我要提醒您，过拟合是一种情况
在这种情况下，您在训练集上的准确率很高
但在测试集上却很差
这意味着您的模型在训练集上过度训练了
您知道得太多了
我们绝对不想要这种情况
所以，这个参数实际上非常重要
我们将调整它来找到最佳值
默认值为1.0
但我们会尝试几个值
我们将尝试零点二
五点五或零点七五和一
因为正如你所看到的，重要的是要注意这一点
正则化的强度与c成反比
这意味着c越低
正则化就越强
所以你知道我们将尝试零点二五的值
这将是一个强烈的正则化
我们还将尝试零点五
仍然是相当强的正则化
0.75
更小的正则化参数，1
我们可以尝试 你知道0.2
5或0.5
你想怎么设置随意
我会稍微即兴一下
我会看看最后选择什么值作为c的值进行实验
然后我们有核函数
所以 当然，这是一个非常重要的超参数
我们将实际调整它
这意味着我们将找到最佳的核函数
在这些SVM模型中
所以我们将实际尝试线性核和rbf核
但请随意尝试
例如POI或sigmoid核
然后我也想调整这个参数gamma
这是一个你只在选择时输入的参数
当您选择 要么使用rbf核，要么使用多项式核，要么使用sigmoid核
因为我们将要对线性核和rbf核进行调优
对于rbf核
我希望调优
你知道不同的gamma值来找到最好的一个
实际上我们将尝试所有从0.1到0.9的gamma值
好的，gamma当然是在
你知道核的公式中的系数，卡尔和我已经在第三部分中向你展示了
分类
所以让我们调优这三个参数
如果你想要调得更多，他们会感觉完全自由
或者如果你想要调得更多的值
但你会看到，已经用这样的调校
我们会得到一个优秀的性能，说到性能
实际上重要的是要强调每次我们尝试这些
你知道这些超参数值的不同组合
嗯 模型的准确度会被通过仔细的交叉验证评估
而不是在一个单一的测试集
好的 所以我们会有超级相关的准确性衡量标准
对于这些参数的每种组合
因此我们将自信
你知道我们最终得到的最佳参数集确实正确
让我们这样做
让我们现在实施网格搜索
当然，一如既往
我们将从scikit开始
学习scikit learn顺便说一下上传笔记
所以我们可以 你知道如何利用谷歌协作的帮助
点击这里上传，就这样
我们已经找到了正确的文件夹
我们选择社交媒体广告
点csv
这是我们要进行网格搜索的数据集
现在我们已经准备好了
我们应该寻求谷歌实验室的帮助
我们将从scikit learn开始
然后我们将获得模型选择的访问权限
在那里我们导入模块
这次我们导入网格搜索类
Cv类
好的 现在我们已经进入了下一步
我们将输入我们想要实验的不同参数的组合
我将在这里创建一个新的变量
我将其命名为参数
我将输入这些超参数的组合
我们将将它们放入一个列表中
你知道 这个参数变量将只是
我们想要测试的不同超参数的组合列表
然后在这个列表中我将创建两个字典
为什么两个因为我想要测试两种不同的核
在一个字典中我们将使用线性核
而在另一个字典中我们将使用rbf核
而我必须将这些两个字典分开的原因是
你知道
我们想要调整的gamma参数只能适用于rbf核
而不能适用于线性核
如果它可以适用于线性核
那我就不需要创建两个字典
一个就够了
然后我将输入我们想要实验的所有参数的不同值
但这并不是事实
所以我确实需要创建这两个字典
我将把它们
你知道放在一起
就这样 现在我们已经准备好了
让我们进入第一个字典
那么我们该怎么做呢
就像字典工作一样，首先
我们需要输入键，键实际上就是参数本身
记住我们想要调整的第一个参数是C，正则化参数
然后是核
在rbf核的情况下，然后是gamma
所以在我的字典中
我将输入第一个键为'C'
这个参数c
然后我在这里添加一些collen，然后在collen之后添加一些东西
我必须输入那个键的值
那个键的值正好是我们想要实验的c的值
我们必须在新的列表里输入它们，方括号配对
正如我们所说，我们要尝试以这个正则化参数c的不同值
它们是 正如我们所说
首先 0.25
然后4.5
然后是0.75
然后是1
所以在左边我们有很强的正则化
我们越接近1
正则化就越弱
好的 这就是这个参数c
然后我们可以在这个字典中输入第二个键
并且用逗号分隔
第二个键将是
当然，那是我们想要调整的另一个参数
那就是核
然后我在这里输入引号
然后是那个键的值
它与冒号分开
嗯 这个值又将是列表
因此是一对方括号
我们想要实验的核的不同值
然而 由于我们有这两个字典
以区分线性核和rbf核的情况
因为你知道这个gamma参数
而在这里这个核列表中
我将再次输入引号
线性核
然后检查我将要做什么
我将复制所有这些
你知道的，放在这个第一个字典中
我将粘贴这些放在这个第二个字典中
然后我们将测试参数c的同一值
但我们将使用rbf核进行测试
因此现在我们正在实验rbf核，嗯
然后我们可以添加这个超参数来调整
那就是gamma参数
这是第二个字典中的新键
所以gamma和该键的值将是gamma的不同值的列表
我们想要尝试的
然后是0.1，然后是0.2
然后0.3和0.4
0.5或0.6
0.7或0.8和0.9
好的
所以你看这是怎么工作的
我们必须将我们的参数输入到一个列表中
然后在每个列表中
要么 我们不需要分开一些情况
我们可以将所的超参数及其值放入同一个字典中
或者我们必须分开一些案例
然后我们用两个分开的字典进入它们，这样所有的都是正确的，优秀
现在我们正确地准备好了我们的参数
你知道我们的超参数组合
嗯，是时候调用那个网格搜索cv类了
因为确实 正如你可以猜到的
这个参数列表将是网格搜索cv类的一个输入
或者你知道那个类的实例我们将创建
好吧，说到那个类的实例
这正是我们下一步要做的
所以我将创建一个新的对象
一个新的变量 它将是这个网格搜索cv类的对象
我将简单地将其命名为grid_search
当然，我们必须调用这个类来创建这样一个实例
好的，网格搜索
正在等待谷歌协作
然后在括号内
让我们输入参数
你可以在scikit learn api中找到它们
但我现在就给你
第一个是估计器，对吧
这将等于
当然，是你的分类器
你知道，就像交叉验证分数函数中的估计器参数
所以分类器和当然是你的核SVM分类器
那么接下来的参数是
下一个参数实际上是我们的参数
你知道 我们想要实验的超参数不同组合
并试图找到最佳值
因此那个参数的名字是param underscore grid
这将当然等于我们的参数变量
其他超参数值的组合列表
然后下一个参数
下一个参数很重要
那就是评分
那就是你希望用来评估模型性能的指标
评估模型性能
对于这些超参数值的每一种组合
既然现在我们正在做分类，那就很好
这个参数的值将在准确性中
当然，那就下一个论点，就像我告诉你的那样
你知道 这些超参数组合中的每一个都将通过仔细的评估来确定。
交叉验证而不是在一个单一的测试集上
因此，接下来的论点就是选择训练测试力量的数量
在应用k折交叉验证时，对于每种组合
并且这个参数的名字与这里一样是cv
再次我们选择非常普遍的值10个训练测试故障
最后，一个非常可选的参数
你不需要太担心
但我在这里添加它
以防你在你的机器上运行这段代码
这是一个参数，用于设置如何在你的机器上运行你的处理器
你知道，在你的机器上
我在这里添加了一个参数值-1
这意味着你所有的处理器都将被使用
你知道，在你的机器上
这将优化网格搜索过程
因为你会看到这可能是一个非常耗时的过程
你知道要测试所有这些组合
嗯 实际上可能需要一些时间
好的 这就是网格搜索cv类的全部内容
现在我们有了我们的对象
正如你可能猜到的，下一步将是将这个对象连接到我们的训练集
我提醒您，网格搜索必须仅应用于训练集
因为测试集再次是你想要分开的东西
每当你想测试你的模式
或者你知道你调整的模式
你知道在你对新观察结果的调整之后
看看它在数据集上的表现
就像在生产中
好的 所以我们现在只将网格搜索应用到训练集上
并且要做得好
我们将调用我们的对象
网格搜索，我们又要调用那个著名的方法了
你已经非常熟悉的方法
就是fit方法
当然，这个fit方法需要两个输入参数
一个是训练集的特征
即x_train
另一个是训练集的因变量向量
即y_train
就像经典的训练一样
因为我们将要进行大量的训练
你知道这些超参数组合的训练
好的 所以这基本上是多重训练
然后，多重训练完成后
我们将得到所有成果
这意味着所有这些超参数组合导致的不同准确率
因此，在所有这些准确率之后
好的 我们将得到最高的准确率
我们将得到导致最高准确率的参数集
首先让我们得到最高的准确率
我们将其放在一个新的变量中
我们将其命名为best_accuracy
为了得到这个
我们将从grid_search_cv类的一个属性中获取它
这个属性叫做best_score
提醒一下，属性就是一个值
我们可以从一个特定的对象中获得
而这个值在这里
当然是从grid_search对象中获得的最高准确率
所以我要把这个复制下来，然后在下面粘贴
我将其命名为best_score
然后我们又要再加一个下划线
这通常是我们命名属性的方式
best_score 意味着最佳准确率
因为我们选择了准确率的评分
现在我们有了最佳准确率
让我们看看哪些参数导致了最佳准确率，为了做到这一点
我们将最佳的参数组合再次赋值给一个新的变量
我们将其称为在评分参数上的最佳
好的，再次获取它们
我们将调用网格搜索cv类的另一个属性
或者你知道我们的网格搜索实例
所以我只是复制这个
我们将把这个粘贴在这里
因为这次属性的名称是最佳
参数最佳参数
好的 现在我们将以两段美丽的打印结束
这些打印的内容实际上与我们为交叉验证做的非常相似
所以我只是复制了这一部分，然后把它们粘贴在这里
现在，而不是打印你知道的准确性这个字符串
我们将打印最佳准确性
然后我们将保持相同的格式，
你知道的，浮点数后的2个小数
以及获取这个值的变量
当然，这里不会是准确率的平均值
但只是获取那个最佳准确性变量的值
这将直接给出最佳的准确性
由最佳的超参数组合产生的
那么我们就取这个
并且我们将用这些准确度点来替换那个准确度
你知道，通过这个准确度变量的平均值
然后我们必须乘以100以便得到以百分比格式显示的准确度
你知道，带有百分比格式的准确度
再次，我们在这里也有
我们不想打印标准差
但是最佳的超参数
然后我只是打印这些最佳超参数
经典的方式 你知道，打印某物的简单方式
所以我将删除这里的所有内容
你知道那个格式函数和变量
因为它将是一个不同的变量
然后，我只是这样做
这是即将打印的字符串
然后打印这个字符串的值
你知道，最佳超参数的他们自己
我只是用逗号分隔那个字符串
然后加上给我们这些最佳超参数的变量
这只是打印某物的经典方式，带有
你知道，一个表示我们正在打印的字符串
在这里，我们需要添加最佳
然后，我们就完成了 朋友们
我们已经完成了这个实现
嗯 我们几乎完成了
我们只是忘记了删除一个括号
我想是从这个格式函数来的
然后，我们就完成了网格搜索的实现
所以我们现在来实验这个
我期待着看到
这些超参数的所有组合将导致最佳准确度
当然，我们将把这个最佳准确度与相关准确度进行比较
我们在核SVM模型中得到的
你知道 带有rbf核和默认值1的regularization参数c
以及默认值gamma参数
所以，让我们看看，我们有我们的数据集
所以，我们已经准备好这样做了
重启并运行所有，所以，我们就完成了
三，二，一，开始 是的 好的
所以现在销售正在运行
我们完成了
网格搜索现在正在运行，并且我们将得到结果
我们得到了90.67%的最佳准确率
这略高于90.33%
但你将在未来的机器学习项目中看到
即使是一点点准确率的提高也可能产生差异
导致最佳准确率的最佳参数组合如下
正则化参数c为0.5
这意味着确实有必要减少一点
即减少超参数c以减少过拟合
当然，我们使用rbf核得到了最佳准确率
这意味着使用核svm模型而不是经典的线性svm
最佳的gamma参数值
你知道，当我们使用rbf核时，确实为0.6
好的 实际上测试所有成员是好的
这就是我们得到的最佳模型
所以现在请随意尝试其他值
你知道，如果你想要，也许尝试其他超参数
如果你能得到比90.67%更高的准确率
我相信你可以很容易做到
我又没有尝试所有可能的组合
请随意在问答部分分享，或者在私信中
但问答部分是最好的，这样其他学生就可以看到你是如何做到的
现在我们将进入本课程的激动人心的最后部分
你知道，附加提升部分
这将给你提供一个额外的超级强大的机器学习模型
你可以将其应用于分类和回归
所以你肯定想将其作为你庞大的机器学习工具箱的最后工具
所以我期待与你一起实现这个最终模型 在此之前，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p42 5. Evaluating ML Model Accuracy K-Fold Cross-Validation Implementation in R.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p42 5. Evaluating ML Model Accuracy K-Fold Cross-Validation Implementation in R

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这门艺术教程
尤其欢迎来到这门课程的最后一部分
第十部分：模型选择和提升
在这一部分，我们将做两件事
首先，评估我们的模型性能
其次，提高我们的模型性能
然后，会有一个关于机器学习中最强大算法的附加部分
这个算法越来越受欢迎
那就是XGBoost
但是首先 我们希望能够提高这门课程中我们构建的所有机器学习模型的性能
提高模型性能可以通过一种称为模型选择的技术来实现
这种技术涉及选择机器学习模型的最佳参数
因为你知道
每次我们构建机器学习模型时 我们总是有两种类型的参数
第一种是模型学习的参数
即参数在模型运行过程中被改变并找到最优值
第二种是我们自己选择的参数
例如，在核SVM模型中的核参数
这些参数被称为超参数 所以，我们还可以进一步提高模型性能，因为我们可以选择超参数的最优值
但是，由于这些参数不是模型学习的参数
我们需要找到另一种方法来选择这些参数的最优值
这就是本节第十部分将要介绍的强大技术的一部分
这就是网格搜索
但在我们开始网格搜索之前
我们需要优化我们的模型评估方式
因为我们到目前为止所做的是将数据集分为训练集和测试集
我们知道我们在训练集上训练模型，然后在测试集上测试其性能
这是评估模型性能的正确方法
但这不是最好的方法，因为我们实际上有方差问题
方差问题可以解释为
当我们在测试集上得到准确率时
如果我们再次运行模型并在另一个测试集上测试其性能
我们可以得到非常不同的准确率
因此，仅凭一个测试集的准确率来判断模型性能实际上并不十分相关
这不是评估模型性能的最相关方式
因此，有一种称为K折交叉验证的技术可以大大改善这一点
因为它可以解决方差问题
它是如何解决的呢
它将训练集分为K折，当K等于10时
大多数时候K等于10
并在K折训练模型并在最后一个剩余折上测试它
由于有10折
我们可以创建10种不同的9折训练模型和1折测试的组合
因此，我们可以得到10个不同的准确率
然后，我们可以取这10个准确率的平均值
这样，我们就可以得到一个更稳定的模型性能评估
这就是K折交叉验证的原理
这意味着我们可以训练模型
并在10种训练和测试集的组合上测试模型
这将给我们提供一个更好的模型性能概念
因为接下来我们可以做的事情是
对10个评估的不同准确率取平均值
并且计算标准差以查看方差
因此我们的分析将更加相关
此外，我们还将知道这四个类别中的哪一个
因为如果我们得到良好的准确率和小的方差，我们将在左下角
如果我们得到高的准确率和高的方差
我们将在右下角
如果我们得到低的准确率和低的方差
我们将在左上角
最后，如果我们得到低的准确率和高的方差
我们将在右上角
因此，K折交叉验证非常有用
并且我们的性能分析将更加相关
因此，让我们开始进行K折交叉验证
这是我们的第一个模型选择技术
因为我们已经构建了许多模型
我们不会再构建另一个模型
我们将使用我们构建的一个模型
并在其上应用K折交叉验证
我们将使用的模型是在第三部分分类中构建的核SVM
我们使用该模型来预测
客户是否在社交媒体上点击广告以购买
或者不
SVM 因此，模型已经构建完成，我们已经拥有所有内容
我们将做的只是取整个模型
并在其中添加一个新的代码部分
它将实现K折交叉验证
所以在我们开始之前
让我们选择一个正确的文件夹作为工作目录
我们进入机器学习A到Z
我们现在正在本课程的最后一部分
恭喜你到达这里
第十部分：模型选择和提升
第四部分：模型选择
确保你有社交媒体.csv文件
如果那是情况
你已准备就绪
所以现在
我们在哪里应用了交叉验证代码部分呢 由于这涉及到评估模型性能
将其放在我们构建核SVM模型的位置是最合适的
就是在我们构建模型之后
实际上，就在这里
我们有测试集的预测结果和混淆矩阵
所以，这就是我们要添加的K折交叉验证代码部分
这实际上是评估模型的第一种方法
正如在本教程开始时所说
这是评估模型的正确方法
但不是最好的方法
在今天的教程中，我们介绍了一种更好的方法来评估我们的模型
所以我们将在此部分之后进行
作为一种更先进的性能评估方法
所以我们将称此部分为应用K折交叉验证
所以现在我们需要做的第一件事是安装carrot包
因为这个包包含一个非常实用的工具来创建我们的训练集的十折
让我们从install dot packages开始
在括号内，引号中
Carrots
我的已经安装好了
我们可以检查一下
检查一下你的包列表中是否有
这里有carrot
所以我会先注释掉
但不要忘记安装它
然后别忘了使用library命令来自动导入carrot包
现在让我们开始编写小心交叉验证
首先，我们将创建一个十折，用于划分我们的训练集
要这样做非常简单
我们将使用carrot包的create false函数
来高效地创建这些十折
让我们这样做
我们将此折命名为fault 实际上会是一个包含十个测试折的列表，用于组成我们的训练集
所以让我们使用create capital f false函数
在这里是它
在括号内，我们只需要指定训练集
在这里我添加了训练集
然后，我们取我们的因变量列，根据该列我们对数据进行划分
你知道的，这与
当我们将数据集分为训练集和测试集时一样
我们需要指定因变量来进行划分
这样我们的训练集和测试集将根据因变量很好地分布
在这里，这也是同样的
我们创建了训练集的十个折
我们指定了因变量，以确保它们根据因变量很好地分布
所以这就是为什么在这里我们需要指定我们的因变量
这是我们的因变量，purchased
所以这是create false函数的第一个参数
当然 你可能已经猜到
第二个参数是你想要将训练集分成多少折
并且十是一个不错的选择
因为通过创建十个折
我们将最终得到十个准确率
而十个准确率是衡量准确率的一种有效方式
通过这十个准确性的手段
所以我们将采取十个折，我建议在实际操作中这样做
在这里我们只是添加k等于十
好的，现在我们将实现k折交叉验证
因为我们在这里所做的只是创建默认设置
但现在我们需要实现算法本身，要做得好
有几种方法可以做到这一点
但我们将使用R中一个非常实用的函数
称为l apply函数
它包括对列表中不同元素的函数应用
所以这份列表将包含我们的错误列表，包含十个测试错误
而函数是计算准确率的函数
对于这十个测试错误
让我们先创建一个新的变量，我们将其命名为cv
然后我们在这里
使用这个l apply函数
你将会理解接下来会发生什么
在这个l apply函数中我们需要输入两个参数
第一个参数是包含我们要应用的元素的列表
第二个参数是接下来要应用的函数
正如我刚才所说
这个列表是错误的
我们的十个测试折线列表
然后是函数
在R中，函数可以这样写function
在括号中我们需要输入参数，我们称之为x
这是目前的局部参数
但x实际上将是每个十个测试折线
这里x和这里的一对括号
在这些括号内我们将实现这个函数
这将计算模型在这些十个测试集上的表现
所以，基本上在这个函数中，我们将实现K折交叉验证
那么，我们需要实现K交叉验证的是什么
首先，我们需要训练集
训练集就是整个训练集
从中我们抽取测试集
所以，训练集在这里
我正在创建一个新的局部变量
实际上，我正在给它起一个名字
我正在调用训练集
正如我刚才所说
这就是整个训练集，开始吧
但我们要排除测试集
这是减去x
因为你知道x实际上是这个测试列表中的每个元素
在这里减去x，我们是在去掉训练集中的测试集
但不包括测试集
因此这实际上是训练集
然后，逗号获取所有列，好的
现在我们得到了训练集
让我们获取我们的测试故障
所以我们的测试故障
试着猜猜看 它将会是测试折叠等于训练集
在方括号内
嗯 我们需要在这里放什么
嗯，那就是x
因为你知道x代表每个测试折叠的所有观察值
所以我们得到了我们的测试折叠
然后我们现在该做什么
现在我们需要做的是在我们的训练折叠上训练我们的核SVM模型
然后我们将在测试折叠上测试其性能
所以我们现在该做什么
我们需要添加我们的模型
这是我们的核SVM分类器
现在我们可以做的就是取这段代码
因为这是我们构建模型的地方
我们需要将模型包含在函数中
这就是我们取它的原因，所以复制并粘贴
现在我们已经做好了 我们有我们的模型
但我们不是在训练这个核SVM分类器在训练集上
我们是在训练它在训练折叠上
因为这是小心交叉验证的原则
我们是在每个训练折叠上训练我们的分类器
这就是为什么我们在这里取训练折叠
这是我们在这里创建的函数中创建的
然后保留相同的参数
然后我们需要做什么
这正是我们在制作模型时做的事情
那就是预测测试集的结果，那是下一步
因为这是从这些测试集结果中我们将计算混淆矩阵
因此准确率，这正是我们需要的
这正是我们现在正在制作的函数将返回的
以实现K折交叉验证
同样
让我们复制这条线来预测测试结果
让我们复制它到这里
就这样了吗
当然没有
因为我们不是在测试我们的分类器在测试集上
但我们是在测试它在测试折叠上
因为，你知道的，我们是在训练折叠上训练我们的模型
并在测试折叠上测试其性能
现在很好
现在我们继续下一步
那就是计算混淆矩阵
仍然让我们取这条线并粘贴在它下面
就在这里 粘贴并现在当然我们需要更改测试集并将其替换为测试故障，好的
这将给我们带来这个分类器的混淆矩阵
SVM模型的这个核
SVM分类器
并且这是用训练故障训练并在测试故障上测试的
因此这行代码将给您测试故障的观察值提供混淆矩阵
好的 现在，最后一步我们需要计算准确率
因为我们正在做这一切都是为了获取所有十个测试故障的准确率
所以让我们计算准确率
我们已经多次计算过这个准确率
我们多次计算过这个准确率
因为我们计算过这个准确率
首先让我们把这一点放一边，好吧
在这里我们首先得到所有结果
数据集被良好导入
在这里我们将其分为训练集和测试集
然后我们构建我们的分类器
这是我们的核SVM分类器
当然我们有通过K折交叉验证构建的cv列表
这就是cv列表
这是来自K折交叉验证的十次准确率的列表，并且
所以让我们检查一下
让我们看一下这些十次准确率
我们将在控制台查看
所以我在这里按下cv并按下回车
现在我们开始
这就是结果
这就是十次准确率
所以折叠一
我们得到93%的准确率
这非常好 折叠二
87%的准确率，三
100%的准确率和没有错误的预测
折叠四 86%的准确率，五
96%的准确率
折叠六，90%的准确率
折叠七，90%的准确率
折叠八，93%的准确率
折叠九，90%的准确率
最后，折叠十，83%的准确率
这清楚地说明了我告诉过你们的
当多次运行模型时可能会发生的方差问题
因为确实我们会得到不同的准确率
并且有时在每次折叠之间的准确率差异很大
从一到二，那就是好的
但是这里
例如，从折叠二到四三 我们得到13%的准确率差异
所以从这里到这里，这是可以接受的
但是到这里，例如，从折叠二到四三
我们得到13%的准确率差异
因此，计算单一分割的准确率并不是那么相关
而计算十次分割的准确率则更为相关
因为这样我们就可以计算平均值
这就是我们现在将要做的
我们将计算这十次准确率的平均值
为了得到这个平均值，实际上非常简单
我们将使用mean函数
所以在括号内，并在括号内
所以括号在这里
当然输入cv
因为cv是我们在这里获得的十个准确率的列表
然而 只是为了确保我们能得到准确率的值
我们每个十个折的准确率
我们需要在这里指定点数值
在括号内我们包括c以确保我们取这些值的平均值在这里
它们是准确率
让我们将这个准确率的平均值放在一个变量中
它将出现在值这里
让我们将这个变量简单地称为accuracy
因为这些准确率的平均值就是我们正在寻找的最终相关准确率
所以accuracy等于cv列表中准确率的平均值
所以让我们计算它
我们将得到
让我们看看一个91的准确率
这是我们正在寻找的相关准确率，所以总的来说
我们可以更有说服力地说，我们的模型或核SVM分类器表现相当出色
这很好
现在祝贺你
你已经有了一个更先进的评估模型性能的数据科学工具包
但你会看到在下一个教程中
我们将看到一个非常有力的技术
它将帮助我们选择任何机器学习模型构建的最佳超参数
所以我期待着在下一个教程中做那件事 直到那时，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p43 6. Optimizing SVM Models with Grid Search A Step-by-Step R Tutorial.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p43 6. Optimizing SVM Models with Grid Search A Step-by-Step R Tutorial

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这个艺术教程
在上一个教程中，我们学习了一种非常有效的方法来评估我们的模型性能
这就是我们评估模型性能的内容
在今天的教程中
我们将学习一种技术，这将有助于提高模型的性能
我们已经构建了非常强大的模型
但我们仍然可以改进它们
那么我们该怎么做呢
那就是找到超参数的最优值
因为确实任何机器学习模型都由两种类型的参数组成
第二种参数是我们选择的参数
例如 SVM模型中的核或惩罚参数
或者甚至是回归或Lasso中的一些正则化参数
基本上在任何机器学习模型中
我们有很多参数没有被学习
到目前为止 我们在这门课程中所做的只是针对这些参数选择一个单一的值
我们从未实际体验过这些超参数
我们从未尝试过它们的多种值
因此，我们还有很大的改进空间
因为也许这些超参数的值有更好的选择
你知道，我们选择的值可能不如更好的选择
这种方法称为网格搜索
将回答您在课程中多次提出的一个问题
即我如何知道选择哪个参数
当我构建机器学习模型时
这些超参数的最优值是什么
并且网格搜索会给出答案
因为它会找到这些参数的最优值
所以让我们看看它是如何做到的
让我们实现网格搜索
所以我们将继续解决与前一个教程相同的问题
那就是 你知道这个分类问题，我们需要分类
社交媒体上的用户预测他们是否会点击
是或否购买SUV的广告
因此我们正在使用这个社会网络广告数据集
而且那是个好例子
因为核SVM模型有许多参数
你知道它有这个惩罚参数
这个伽马参数，有些人问我们应该为这些参数选择什么值
所以网格搜索会告诉我们确切答案
所以我们来做
我们在与前一个教程相同的文件夹中工作
那就是模型选择文件夹
确保你有社交网络CSV文件
如果有的话 你已经准备好了
所以我们将在数据预处理阶段之后应用网格搜索
因为我们实际上不会使用这个核SVM模型
然后在其上进行参数调整来找到最优值
我们将实际使用一个你将会看到的新包
这是一个非常实用的包，用于构建与这里相同的核SVM模型
同时对其进行网格搜索，你已经知道它是什么
它就是caret包
当我们谈论R中机器学习时
caret包是最实用的包之一
因为基本上这个包可以让你构建任何机器学习模型
你不仅可以构建任何机器学习模型
当你使用carrot包构建机器学习模型时
嗯 它会给你你想要的模型，所有最优的参数
这相当强大
因此，这是我们最强大的包之一
正如我所说的
我们可以在任何数据预处理阶段之后构建这个新的调优模型
所以让我们实际上在K折交叉验证部分之后做
你知道 保留其他有趣的代码部分
这样 例如，你可以比较两个模型
你知道 我们制作的这个模型和我们即将用胡萝卜包制作的新模型
请随意比较它们的性能结果
我们将构建这个新内核
在这里构建SVM模型
所以应用网格搜索来找到最佳参数
我在这里准备了这段代码
但实际上这不仅仅是应用网格搜索
它还构建了一个新模型
首先 我们必须要做的第一件事就是导入胡萝卜包
我们在之前的一些教程中已经安装了它
但我们确保你已经安装了它
如果你没有跟随那些之前的教程
所以我只是放回这个命令并在其中
当然胡萝卜在引号中，好的
然后我会把这个放在评论里，开始
现在让我们用库命令导入这个包，开始
导入库和胡萝卜，完美
所以现在让我们构建相同的核SVM模型
但使用胡萝卜包
你会看到这将是些新东西
好的 既然我们正在建造这个新的分类器
核SVM分类器，嗯
让我们用通常的名字称呼我们的模型
这就是正确的分类器
这就是变量，然后等于
这就是我们使用carrot包的地方
我们要使用的函数是什么
这是carrot包中最常用的函数之一
它是train函数
所以括号
现在非常有趣的是，在这里打开浏览器，这就是它
让我们输入carrot并进入，然后打开github链接
让我们点击它
在里面你需要点击这里这个链接
然后点击六个可用的模型
因为在这个部分你会得到用胡萝卜包可以构建的所有模型
有很多模型
实际上这些都是我们在课程中构建的所有模型
所以现在你们中的一些人可能会想
那么我们为什么没有使用胡萝卜包来构建所有这些模型
因为确实胡萝卜包将给我们提供具有最佳最优参数模型
嗯 那是因为我们在课程中使用的包构建所有模型都有很好的选项
有些你可以使用胡萝卜包
所以知道如何使用我们在课程中使用过的包是很好的
以及胡萝卜包
但肯定对于参数调整
你应该使用胡萝卜包，好的
所以你看到的这个列表
这里是胡萝卜包中你可以构建的所有模型的列表
并且现在我们正在构建核SVM模型
嗯，你会看到它是可用的
我是说它是这个列表的一部分
我们可以在这里的列表底部找到它
因为我们确实可以看到我们有许多支持向量机模型
我们感兴趣的是使用径向基函数核的支持向量机模型
记住，径向基函数核是高斯核
这是最常用的核来构建核支持向量机模型
所以这就是我们现在要构建的模型
使用胡萝卜包和现在我们需要的信息
这将是我们即将使用的train函数的输入之一
这里是我们需要的信息
这是train函数的一个参数的输入
方法的参数
而这个参数是训练函数需要了解要构建哪个模型
以及要调整哪个模型
所以现在我们需要做的就是取这个名称
复制它
我们将其粘贴为训练函数的方法参数的输入
所以我们回到工作室
好的 现在我们构建模型
所以我们可以实际上在这里按f1以获取参数的信息
让我们看看有什么需要输入的
我们需要输入的第一个必填参数是这个表单参数
当然，这是公式
让我们这样做
让我们输入第一个参数form等于
然后，我们需要按照构建前一个模型时那样精确输入公式
这是因变量
提醒一下，这是购买的
你知道，这是社交媒体广告
商业问题 所以我们需要输入
购买的这里我们开始
然后波浪线，然后所有不可分割的变量
记住我们不必输入所有不可分割的变量的名称
我们可以使用这个快捷方式
这就是这个点
然后逗号然后下一个参数
所以下一个参数是数据
那就是当然你的训练集
你在你的训练集上构建你的分类器
因此，你需要在这里输入
数据等于训练集，开始吧。所以，现在我们用表格形式
公式和数据
训练集，你有你所需的所有信息来训练你的模式
但是，当然我们需要指定我们要构建的模型
那就是我们需要指定我们想要制作核支持向量机模型
这就是第三参数发生的地方
这不是这些参数之一
这些不是强制性的
但这是方法参数
实际上你已经有了这个链接
我们刚刚在谷歌上浏览的链接
这个链接将给你提供胡萝卜中可用的所有模型的列表
这是为了我们需要输入的这个方法参数
我们在这个链接中复制了
这是svm radio
所以现在输入它
逗号和然后方法等于
然后引号
在这些引号中我们需要粘贴svm radio
这就是这三个参数的实际操作
公式
数据和你将要构建的核SVM模型
然后对于参数调整
你将会看到发生了什么
首先我们要做的是执行数据预处理阶段
因为我们需要先导入数据集并应用数据预处理阶段
让我们现在就做
我们不会执行这些部分
因为这部分是构建核SVM模型的另一种方式
所以我们只需要从这里开始到顶部的所有内容
开始吧 让我们这样做
数据集已导入
我们有数据集 训练集和测试集
并且数据预处理阶段已经正确应用
所以现在让我们使用carrot包构建核SVM模型
所以我们确保导入carrot包
开始吧 现在我们选择这条线并执行它
这花了一点时间，大约一秒钟
这很好 这是我们的分类器
这是核SVM模型分类器
它还没有调整
但你会看到会发生什么
因为我们现在按下回车键
然后我们简单地输入分类器并选择它并按下回车键，在那里
你会得到很多关于你使用carrot包构建的核SVM分类器的非常有趣的信息
因为你确实
你看到的 这里
确实是在这个核SVM分类器上执行的一些参数调整的结果 你刚刚构建的
而这是什么 这是结论
这是使用最大值选择的最佳模型
这意味着准确性是用于评估您模型性能的性能指标
就在下面
你看到最终用于模型的值sigma等于1.12
1.13
和c等于0.5
这就是你的参数调整结果
这是核SVM模型的超参数的最佳值
这将使你的核SVM模型性能更佳
比您使用先前方法构建的模型性能更好
当然 也许c参数的默认值是0.5
这看起来像是默认值
但肯定sigma参数的默认值肯定不是1.13
这是核SVM的另一个超参数
对于sigma参数使用1.13的值
你将获得最佳准确性
这是一个比您之前构建的核SVM模型获得的准确性更高的准确性
甚至你可以看到这样的准确性
就在这里显示
准确性为92%
并且这与无关的准确性
这不是在单个训练测试分割上测量的准确性
这是通过几个趋势测试划分测量的
你可以在这里确切地看到
这与使用两次五次重复的bootstrap信息相似
这与k折交叉验证完全遵循相同的原理
这意味着你将使用不同的训练集和测试集样本
你将在训练集上构建你的模式
并在每个这些样本上在测试集上测试其性能
最终你将测试集的准确度取平均
你将得到92%的准确度
这绝对是一个很好的准确度
并且这是你能够得到的最好的准确度
使用这些超参数的最优值
sigma等于1.13
并且c等于0.5
现在我将给你一个更快的方法
来获取这些超参数的最优值
你只需要
让我们保留这个分类器
但你只需要复制它你只需要在你的分类器上添加一个美元符号
然后你可以在这里添加best tune这里我们走你选择它
你执行它
你将直接得到超参数的最优值
sigma等于1.13并且c等于0.5
现在祝贺你
你得到了你的最佳核SVM模型
以及最佳的训练系数
并且现在选择权在你
你可以选择这个核SVM分类器
你使用carrot包构建的
或者你可以选择你使用常规方法构建的分类器
但你可以在这个SVM函数中输入
你找到的超参数的最优值
那就是sigma等于1.13并且c等于0.5
我将留给你作为练习并且你自己判断你想要选择哪种方法
我将在下一个也是最后一节中见到你
我们将要实现机器学习中最强大的模型之一boost
这将是一个非常令人兴奋的部分 我迫不及待地想见到你并且在那之前享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p44 1. How to Use XGBoost in Python for Cancer Prediction with High Accuracy.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p44 1. How to Use XGBoost in Python for Cancer Prediction with High Accuracy

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好 欢迎我的朋友们，这是我们这门课程的最后一项实际活动
是的 我必须先说，我感到既兴奋又紧张
但悲伤 这就是旅程的终点
但是别担心
我们将以一个非常非常积极的基调结束，而这个积极的基调是关于
当然，xgboost
它是一款超级强大的机器模型
这是我绝对希望你在工具箱中拥有的
因为你会看到它在大多数机器学习问题中带来了优秀的结果
实际上，这件事最酷的地方在于，它可以同时用于回归和分类
这就是我们去做 让我们在这个最后的教程中一起跨过终点线。
通过实施xgboost模型
所以那个模型在部分十被给了你
所以，在我们进入这个部分之前
确保我们在同一页面上
我给你这个文件夹的链接
在这篇教程之前
所以请确保连接它
现在让我们开始
通过进入第十部分，让我们完成这次旅程
然后这门课程的最后一部分
第四九节关于xg提升
像往常一样，我们将从python开始
它包含两个文件
首先是数据，其次是实现
现在您可能也注意到，现在我的机器上有许多打开的文件
没错，所有这些文件
这些都是 你知道
我们快速高效实现的文件
在做那个道德选择演示时
在第三部分的结尾
分类正确
我给你了这个模型选择文件夹
里面所有这些分类模型
都是在同一数据集上进行实验的
是哪个数据集
数据csv
我提醒您，这个数据集包含预测
肿瘤是良性还是恶性
这个数据集中的每一行对应一个患者
某个特定的患者
对于每个患者，我们有几个特征，如团块厚度
细胞的均匀性
细胞的形状均匀性
所有这些特征都是肿瘤的特征
我们试图预测所有这些特性
肿瘤是良性还是恶性
它是良性的 如果我们得到类二和恶性
如果我们得到类四，好的
我们构建并训练了我们的所有分类模型
这些都是模型
学习这些特性与那个依赖变量之间的相关性
告诉我们肿瘤是良性还是恶性
记住我们对这些模型有不同的准确度
在逻辑回归模型中
我们有94.7%的准确度，k最近邻
我们也有94.7%的准确度
在SVM中
我们有94.1%的准确度，核SVM
我们有更好的准确度实际上
在朴素贝叶斯中我们有95.3%的准确度
我们又得到了94.1%的准确度
在决策树分类中
那是赢家
我们获得了惊人的95.9%的准确度
那是奖牌上的第一名
紧随其后的是核SVM的准确度
不幸的是，随机森林没有做好
或者你知道的，不如别人
因为我们得到了93.5%的准确度
所以现在我想做
你可能已经猜到了
是构建XGBoost模型并训练它，使用相同的数据集
看看它是否能坐上王位
由决策树分类模型持有
换句话说 看看它是否能击败决策树分类模型获得的准确度
嗯 也许那就是我们结束这门课程旅行的好方式
你准备好了吗 让我们这样做
我们现在将使用相同的数据集构建和训练我们的XGBoost模型
看看是否能击败95.9%的准确度
我们不仅会在单个测试集上测试这一点
而且现在我们学习了小心交叉验证在上一节
我们将在10个测试四上测试这一点
以便我们可以得到准确度的相关措施
并确保XGBoost现在可能成为第一名
拥有终极机器学习王位
让我们立即检查这一点
让我们打开这个实现，使用谷歌协同或jupyter笔记本
我将放在最后
你知道的，放在所有其他分类模型旁边
现在笔记本就打开了
但它仍然处于只读模式
所以我们将立即创建一个副本，通过点击
保存副本并驱动
你可以注意到所有这些都是原始实现的副本
它们就在这里 你知道那是模型选择文件夹
然后是分类子文件夹
我在三部分的结尾给你
所以你可以再次运行这段代码，如果你愿意
但我们已经做过了
记住，决策树分类器的准确率为95.9%
现在我们来看看XGBoost是否能超越这个成绩
当然，不用担心
我们不会重新实现所有这一切
我们会迅速进入核心实现部分
并且主要是令人兴奋的部分
那就是在相同教程中的结果
因为确实所有的实现都是来自我们多样化的工具包
是的
正确 这三笔头笔销售正如你所认识到的那样，正是我们数据预处理模板的销售
正确 我们首先导入库，然后我们用完全相同的代码导入数据集
我只是在这里放了数据集的名称
然后我们将数据集分为训练集和测试集
这就是所有数据预处理阶段
然后我们在训练集上训练xgboost
当然我会立即删除这个单元格
因为这是我们将一起重新实现的单元格
然后我们有其他工具包中的其他工具
喜欢分类工具包
因为这确实这个单元格制作混淆矩阵并在同时打印
准确率我实际上已经删除输出
以确保我们在这个教程结束时得到全部惊喜
然后当然如我所说
我们将在最后应用k折交叉验证
以确保我们确实在测试集上没有走运
你知道如果我们确实可以击败所有其他算法
所以我们将不仅得到一个性能的初步估计
多亏了这个单元格，谢谢
然后我们将通过那次销售来最终衡量准确性
你准备好了吗
让我们从训练集开始，使用XGBoost训练模型
这是从数据集分为训练集和测试集得出的结果
首先，为了得到Google Collab的帮助
让我们执行将数据上传到笔记本的操作
所以我只是点击了这个文件夹按钮
接下来我们会看到上传按钮，用于上传我们的数据集
让我们点击它
现在让我们转到我们的机器学习数据集代码和数据集文件夹
因为第10部分中的这个文件夹里仍然能找到数据点CSV文件
当然可以，让我们进入这个文件夹
然后进入第10部分
然后进入第4节
9个额外的Python增强
这里有许多患者的肿瘤数据集CSV文件
我们需要预测肿瘤是良性还是恶性
打开
好的 现在数据集确实已上传到笔记本中
我们走吧
我们可以运行那个单元，然后运行整个代码
让我们创建一个新的代码单元
我们走吧
让我们构建和训练
实际上在训练集上训练Boost
你会看到这非常简单
实际上我们不会使用scikit-learn
但我们会使用一个叫做xgboost的库
我们不需要安装它
感谢谷歌协作
因为它是谷歌协作中已安装的许多包之一
你已经知道它已经预安装
所以我们不用担心
我们可以开始构建和训练这个Boost模型
但我们首先会导入构建它的类
当然，这个类属于xgboost库
我们走吧 我们从这个xgboost库开始
拼写方式就是这样
就像模型的名字xgboost一样
从这个库中
我们导入构建xgboost分类模型的类
这个类叫做xgb
我们走吧 谷歌协作找到了xgb分类器
下一步，就像往常一样，创建这个类的实例
这将包含xgboost模型
所以我们称之为classifier
我们将创建一个classifier实例
确实是xgb分类器类
好消息是
我们不需要担心这个类的太多参数
因为这个类的默认版本xgboost模型
大多数时候表现都很好
所以这里一切顺利
现在我们当然要完成将xgboost分类器连接到我们的训练集
我们可以通过调用classifier对象的fit方法
当然
这是连接的方式
这将只会在这个训练集上训练这个xgboost分类器
这是我们之前做过很多次的事情，所以，我们继续
让我们在这个整个机器学习旅程中再做一次
但我相信，在未来的机器学习生涯中，你会再做很多次
在你的未来机器学习生涯中
让我们开始吧
我们称我们的分类器
我们从中调用这个fit方法
这将在训练集上训练分类器
它由训练集的特征组成，表示为x_train
以及训练集的因变量，表示为y_train
这正是
当然，fit方法的输入
在闪电般的速度下
我们在训练集上构建并训练了这个xgboost模型
我们只需要实现这三行代码
然后，我们所有的工作都已经完成
你知道，这是混淆矩阵
你有这个代码在你的所有分类模板中
最后，当然，我们应用我们在前一节中实现的相同单元
应用k折交叉验证
我们准备好运行这段代码了
但在我们做之前
我只想向你展示如何构建一个xgb回归模型
你知道，一个用于回归的xgboost模型
实际上非常简单
你只需要在这里改变一件事
当然，分类器的名称
它不会叫xgb classifier，而是xgb
然后你会看到，xgb regressor
然后你知道，你会在这里将classifier替换为regressor
然后，就这样 这样，你将构建一个基于x boost的回归模型
但让我们回到xgb分类器类
现在我们可以保存这个实现并运行所有单元
来找出
xgboost是否会从决策树分类模型中夺走王位
对于这个特定的数据集
对决策树分类模型，我们得到了最好的准确率
你知道，最高的95.9%
现在，让我们找出我们是否能用xgboost模型超越这个
在这个相同的数据集上训练
所以，基本上，我们准备好了
我们只需要点击运行这里，然后运行所有单元
你现在准备好了吗
我相信你已经准备好了，所以
让我们开始吧，3，2，1，开始
所以，所有单元都在运行中
我们得到了令人印象深刻的97.0%的准确率
所有单元都在运行中，我们得到了令人印象深刻的97.0%的准确率
当我告诉你我们将以积极的姿态结束这段旅程时，准确率达到了百分之八
我确实非常小心地选择了我的词汇
这仅仅是一个惊人的准确性
你知道在这个如此敏感的问题上，只有三次错误的预测
你知道癌症预测
这个结果是惊人的
确实，我们用这三次错误的预测几乎达到了百分之九十八的准确性
这真是惊人的
但现在我们必须检查最后一件事
因为你知道，也许我们在这个单一的测试集上运气好
也许那个单一的测试集对实际提升其他分类模型更有利
这可能解释了为什么实际上提升是排名第一的
并且唯一检查这一点的方法是通过实际在其他测试集上计算其他准确性
这就是k折交叉验证的全部内容
而这就是这实施中的最后一个单元格的原因
而且我们也有这次结果的
正如我们所看到的那样
仍然有惊人的96点准确性
五十三点百分之
这是当然
平均准确度
通过在十个不同的测试集上测量十个不同的准确度的平均值获得的
此外，我们只有2%的标准差，这相当小
这仍然是很好的
是的 Xgboost在这里绝对是第一
这就是为什么我的朋友们
我非常高兴我们能够以这个强大的工具结束，你将在你的机器学习工具包中找到它
最终强大的工具
因为你现在可以开始你的后机器学习旅程
你对你的全职工作充满信心
关于这一点，这将是我在这门课程中的最后一句话
我希望你在未来的机器学习项目中取得巨大成功
我希望你是一个有才华的数据科学家
为你的团队和你的客户带来最强烈的洞察力和最高的价值分析
你现在完全有能力做到这一点
多亏了你的完整而强大的机器学习工具包
你完全有能力解决你未来的机器学习问题
再次，我希望你最好
我期待着在另一门课程见到你，开始新的大数据科学之旅 当然，在此之前，享受机器学习
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p45 3. XGBoost Tutorial Implementing Gradient Boosting for Classification Problems.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p45 3. XGBoost Tutorial Implementing Gradient Boosting for Classification Problems

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                你好，欢迎来到这门艺术教程
你已经学到了很多东西
但如果没有介绍机器学习中最近非常流行的算法之一，这将是一个遗憾
尽管它仍然是一个非常强大的模型，尤其是在处理大数据集时
它将提供非常高的性能，同时执行速度快
说到性能和执行速度
重要的是要记住，XGBoost是梯度提升模型中在模型性能和执行速度方面最强大的实现
因此，对你来说拥有这个工具非常重要
所以让我们实现XGBoost
这只是一个介绍
因此，我们将实现一个简单的XGBoost实现
但你需要在计算机上编码模板
你将能够尝试在你的问题上，在你的数据集上
即使使用这个简单的实现，你也会看到它肯定会给你带来一些优秀的性能
现在我们要做的是取一个我们在这门课程中处理的商业问题
这将实际上是我们在深度学习部分解决的问题
记住，这是一个我们解决的流失建模问题
我们需要预测银行的客户中谁会离开银行
所以这是一个分类问题，我们将客户分为两类
那些会离开银行的人和那些不会离开银行的人
并且我们获得了86%的准确率 但这花了很长时间，因为我们训练了一个需要多个epoch的人工神经网络
因此，它花了很长时间才能执行
所以在这个部分，我们将做同样的事情
我们将在流失建模问题上应用XGBoost
如果我记得没错，这个数据集包含13个特征
但这不是一个大数据集
重要的是要指出，即使这是一个大数据集，一个非常大的大数据集
XGBoost在性能和执行速度方面仍然是最好的模型之一
以获得良好的准确率和执行速度
例如，如果你正在处理一个大数据集
我强烈建议你测试XGBoost
现在我们将进行预处理阶段
只有第一部分，因为第二部分是实现人工神经网络
所以我们只想对这个流失建模CSV文件进行预处理
但我们不会从这个预处理阶段中取所有内容
原因是对于人工神经网络来说，我们将在预处理阶段中取一部分
我们将在预处理阶段中取一部分，而不是全部
特征缩放是完全必要的
没有疑问
深度学习必须应用特征缩放
但好消息是，对于xgboost
因为xgboost是一个基于决策树的梯度提升模型
因此特征缩放是完全不必要的
这也是xgboost的一个优点
除了其高性能和快速执行速度
它可以保持你对问题的理解
对你的数据集
以及构建模型后你将得到的结果
现在我们可以理解
为什么xgboost如此受欢迎
因为它有这三个质量
第一个质量 高性能
第二个质量
快速执行速度和第三个质量
你可以保持你对问题和模型的所有解释
所以肯定地，这是一个你应该在你的工具箱中拥有的模型
在这里特征缩放是不必要的
因此我们将从这里开始，直到顶部，像这样复制
并将它粘贴到我们的boost文件这里，好的
现在我们可以实施xgboost
所以首先让我们在训练集中引入一个新的部分，fit in xgboost
好的，首先让我们安装extra boost
正如往常一样，有一个包
它是xgboost包，它将使我们能够非常高效地实施xgboost
所以让我们在这里输入，正如往常一样
安装点包名，在里面是boost包的名称
它只是x g boost像这样
然后你选择这条线并按command和control
按回车键执行
这是在安装boost包
好的，我们可以看到它在处理 这里，我们走
下载的二进制包在这个包文件夹中
一切顺利，xgboost已经安装
让我们将这部分注释掉那里
现在让我们导入extra boost包
因为确实我们已经安装了它
但如果我们向下滚动到底部
xgboost已经安装但未导入
我们希望使其自动进行
所以正如往常一样，我们使用library命令，在里面是x g boost
这将导入包，好的，现在让我们实施xgboost
实际上这将只占用一行
因为我们只需要创建一个新的变量，我们称之为正如往常一样classifier
它本身就是xgboost分类器
因此我们只需要创建一个新的变量，我们称之为classifier，它本身就是xgboost分类器
然后等于
然后我们使用xgboost包中的boost函数
所以xgboost( )
让我们点击这里
按f1并获取关于boost函数的一些信息
所以我们感兴趣的是参数和需要哪些参数
好的 所以我们看到有一个参数参数
实际上是一个参数列表
这些参数是所有你可以看到的参数
例如asap参数控制学习率
gamma参数是最小损失减少
你有很多这些参数
但这门课程的介绍只是xgboost的介绍
所以在这门课程中我们不会对xgboost模型进行一些调整
但我确信在未来的课程中
我会对xgboost进行一些更复杂的实现
但这门课程的介绍只是boost的简单介绍
这样至少你有一些关于它的知识，并将其添加到你的工具包中
让我们不要在这上面花费太多时间
让我们继续到一些必填参数
当然第一个是数据
所以数据是 当然你的训练集
你想要在你的xgboost模型中训练的数据集
所以让我们立即输入
所以第一个参数data等于
然后训练集在这里我们走，实际上我们只需要训练集中的特征
所以我们会从训练集中移除因变量
因为这里的训练集包含特征和因变量
但数据参数期望的只是特征
所以这里我们添加一些括号并移除因变量
那么这个索引是什么，让我们做这件事
我们需要导入数据集
但在导入数据集之前
让我们快速设置正确的文件夹作为工作目录
现在，我们正在部分十
然后section four nine xgboost那是正确的文件夹
确保你有churn modeling csv文件
然后点击设置工作目录这里，然后这里我们走
我们可以导入数据集
所以让我们导入它
这就是数据集
但记住，在这个数据集中，我们不使用所有不依赖变量
因为我们不关心行号
客户ID和姓氏
我们知道这三种变量对因变量没有影响
所以我们移除了它们
这就是我们在这行做的
data set等于data set for fourteen
这意味着我们将数据集中的第四个变量的所有变量提取出来
这是信用评分到退出的最后一个变量
这是因变量，也就是我们关注的变量
所以我们选择这条线并执行
现在我们看我们的数据集
这包含了所有相关的特征和因变量
因此，挑战在于，我们有这么多自变量，我们希望预测
客户是否会离开银行还是留在银行
这就是我们用来训练模型并测试其性能的数据集
因此，我们在xgboost函数中需要移除因变量的索引
对于数据参数，这里指的是已退出列的最后索引
由于我们有11个变量
所以索引是11
所以让我们回到实际上的提升，并让我们回到函数
因此，我们必须输入-11
好的 所以我们有了整个训练集
但没有因变量，这是完美的
这正是我们所需要的
所以现在让我们回到帮助看到
如果我们需要更多关于这个第一个参数的信息
确实，这里有一些非常重要的信息我们需要考虑
那就是这个输入数据集需要是一个xgb dot d矩阵
也就是说这是一种类型的矩阵
但我们也可以看到，除了数据
数据参数也可以接受矩阵
但这不是一个矩阵
这是一个数据框
所以这不会起作用
如果我们以这种方式输入特征
所以我们可以将其转换为xgb d矩阵或简单矩阵
那么我们选择最简单的解决方案
我们将此特征数据框转换为矩阵
你知道怎么做
我们只需要使用as.matrix函数并放入一些括号
因为它是函数 这里我们输入这个特征数据框
现在变成了矩阵
这正是我们所需要的，完美
然后下一个参数
所以这里你又有很多其他论据
但这些并不是强制性的
所以我们现在不会关注它们
但下一个强制性论据是这个标签论据
因为确实在这里我们输入了特征矩阵
但当然为了训练一个分类模型
我们不仅需要特征矩阵
也需要因变量
这就是我们放在这个标签参数的地方
所以正如你可能预期的那样
自从我们将特征输入到矩阵中
我们需要将此标签参数作为向量输入
为了获取我们的因变量作为向量
我们需要输入
标签等于我们的训练集
然后美元和我们取我们的因变量的名称
这是退出
这将给我们一个向量
因此，训练集退出是我们的因变量
但以向量形式给出
这正是我们所需要的
因为，正如你所见，标签期望为向量
响应值的向量
响应值是
当然 因变量的值
好的，现在下一个参数
下一个参数是什么
嗯
这里有一个第三个必需的参数我们需要输入
实际上在上面
但我想让标签放在特征矩阵之后，这有点意义
现在，我们需要输入第三个参数
这是n rounds参数，n rounds参数是最大迭代次数
既然我们不处理太复杂的问题，嗯
最大10次迭代将足够
我们将输入这里n rounds等于10
xgboost将最多进行10次迭代，完美
现在，实际上这条代码已经准备好执行以训练boost分类器
即使extra boost是一个非常先进的机器学习问题
嗯 多亏了extra boost包
您只需这行简单的代码就可以非常高效地实现它
好的 我们现在不会执行这条代码
因为我们首先需要运行数据预处理阶段
然后，我想添加一些代码片段来评估我们的模型性能
所以我们将在最后执行整个东西
但现在让我们添加一些最后的部分来评估extra boost的性能
当然，我们将使用我们的k折交叉验证技术来评估它
因此，我在这里将使用k交叉验证部分，它就在这里
我们将使用它在我们的xgboost模型中
所以，我在这里只需要复制这个部分
回到xgboost模型并粘贴在这里，小心在里面
我们需要更改分类器
因为就在这里，这是核SVM分类器
所以我们只需要替换这个核
SVM分类器为我们的x g boost分类器
所以我只是复制这里
粘贴在这里
然后回到我的k折交叉验证部分
然后将训练集训练的boost分类器代码粘贴到这里
然后在这个部分需要添加一行代码
这涉及到xboost模型将返回预测
作为概率
你知道它会返回类一的概率
因此将概率转换为真实预测0或1的技巧
好吧 我们需要添加这行代码
为什么pred等于然后括号
为什么pred大于0.5
因此如果概率大于5
那么w为1
如果概率低于0.5
那么why bread为0
这就是我们将得到二进制结果0或1
这正是scacross validation部分期望的
最终在我们执行之前
我们还需要更改两件事
首先，由于训练集期望为矩阵
那么测试集也将相同
所以在这里我们也需要添加as.dot matrix
并在括号内输入我们的test fold
这就是第一个更改
而现在第二个更改是
当然与依赖变量的索引有关
因为3在这里是我们之前实现k折交叉验证时的依赖变量索引
在我们新的问题中，我们需要将3替换为依赖变量的索引
这不是3，而是11，同样
在这里的混淆矩阵中，索引也是11
现在万事俱备
我们可以执行整个代码
让我们这样做并看看能得到多少准确率
让我们回到顶部
我们已经导入了数据集
现在让我们将分类变量编码为因素
在这里，我们完成了
现在让我们将数据集分为训练集
和测试集
在这里，我们完成了
现在让我们将xboost拟合到训练集
extra boost包已经导入
我们只需要选择这一行并执行
我们得到了每个轮次的均方根误差信息
基本上均方根误差是错误的相关计算
你可以把这个想象成错误
当然，错误越低
你的模型越好
我们可以看到，从第一轮到最后一轮
紧张的一
错误从零点四一下降到零点二九
此外，我们可以看到，最大迭代次数为10是一个不错的选择
因为我们可以看到，它大致在4.30左右收敛
请随意尝试更多的迭代
并尝试看看它是否收敛到一个小于30的数字
如果你得到一个接近0.30的数字
那么10次迭代是一个不错的选择
所以额外的提升已经被实现并在训练集上进行了训练
现在让我们使用K折交叉验证来评估其性能
使用准确率指标
实际上我发现还需要更改一件事
这里是依赖变量的名称
祝贺那些注意到
我们需要将这里购买的名称替换为依赖变量的真实名称
在我们的问题中
不是购买的而是退出的
所以将这里购买替换为退出，现在我们开始
一切都应该没问题
让我们再做最后一次检查，训练集的矩阵，测试集的矩阵
为什么它被转换为二进制结果
零或一的索引是正确的依赖变量
一切都看起来不错
让我们选择这里的整个部分，获取我们XGBoost模型的最终准确率
这里，我们执行所有操作，非常快，我们得到一个最终准确率为88%
因此，不仅非常高效
而且我们成功地超过了ANN的准确率
此外，这是XGBoost的准确率
所以我们可以信任这个88%的准确率
所以这非常好
不仅XGBoost非常快
而且它给了我们一个惊人的准确率
可能是我们课程中实现的所有模型中最好的
所以这是一项了不起的工作
现在，是时候说再见了
因为这是这个课程的最后一个教程
所以这感觉很不错
因为这是这个机器学习旅程的结束
这是我在这个课程的第一个教程中引入的
是的
没错 这就是旅程的结束
然而，我相信这不是最后一次机器学习旅程
这是你第一次机器学习旅程
我很高兴能与你一起踏上这段旅程
我真的很享受这段旅程
我希望你也是这样
我很高兴能制作一些新的机器学习课程
开始一些新的机器学习旅程
所以我希望很快能见到你
所以，希望很快能见到你 And until then enjoy machine learning
                
```

### /content/drive/MyDrive/bilibili/UdemyMachineLearningA-ZAIPython&RChatGPTPrize2025Part4/Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p46 1. Logistic Regression Intuition.ai-zh.srt

```
# 🎬 Udemy - Machine Learning A-Z AI, Python & R + ChatGPT Prize 2025 part4 p46 1. Logistic Regression Intuition

                我有一段由 AI 机器翻译生成的文本，请你帮我处理，要求如下：

1. **纠正翻译**：将原文中怪异、不自然或错误的翻译改成通顺、自然且意思准确的中文。
2. **深入小白讲解（整体）**：用小学数学水平或零基础语言，把纠正后的内容整体重新讲解，保证小白也能理解，同时对于原文中出现的术语、公式、数字、逻辑关系等提供更详细的讲解，解释其原理和作用。
3. **生活化例子**：对公式、数字、逻辑关系或抽象概念，用生活中常见的例子说明，使理解更直观。
4. **术语高亮 + 小白注释**：对所有专业术语、概念或陌生词汇用 **粗体** 标记，并提供详细讲解和生活化例子。
5. **输出结构**：
标题
- **原文纠正版**：  
（整体纠正后的文本）

- **深入小白讲解 + 生活化例子**：  
（用通俗语言重新讲解原文内容，遇到公式、数字或抽象概念时，提供详细解释，说明原理、作用和逻辑，并配生活化例子）

- **完整术语解释（高亮 + 小白例子 + 深入讲解）**：  
  - **术语1**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - **术语2**：详细解释，说明原理/逻辑，用小白易懂的生活例子  
  - …（列出所有术语）

以下内容为AI机器翻译生成的文本:


                好的
我们来谈谈逻辑回归的直觉
你可能已经通过我的声音察觉到我很兴奋
接下来的幻灯片非常有趣
这是一个非常重要的主题
但同时也很具有挑战性
所以提前提醒一下
会有一些数学内容
我已经多次演练过这个演示文稿
我真的会尽我所能以最简单的方式传达所有内容
让我们开始吧
我们已经了解了线性回归
我们知道有简单的线性回归
它有一个非常简单的公式，只有一个自变量
我们也研究了多元线性回归
它有多个自变量
我们已经知道如何处理这类问题
当我们有一个散点图时
在横轴上我们有自变量
在纵轴上我们有因变量
这是一个我们曾经看过的例子，工资与经验
我们如何创建一个模型
我们使用简单线性回归
它在数据中画一条线
这条线模型了我们的观察结果
我们可以进行预测
并且比较我们的实际结果与模型等
所以我们知道如何处理这类问题或挑战
但你的公司聘请你作为数据科学家
他们做的事情是向客户发送电子邮件
提供购买某些产品的报价
可能是服装店
可能是杂货店
或者类似的 所以他们做的事情是
基本上他们向很多客户发送电子邮件
提供购买某些产品的报价
这里有他们最近联系的客户样本
你有他们的年龄
还有一个变量
他们是否采取了行动
他们是否执行了行动
他们是否接受了报价
他们是否购买了产品 他们是否打开了电子邮件
回复了我们的电子邮件等
他们是否采取了行动，或者没有
这是一个非常明确的，非常不同的分类
但同时
像 即使我们不知道该怎么做
我们也不知道这里发生了什么
这不符合我们的预期
但同时 直觉上我们可以看到存在某种关联
我们可以看到底部的观察值
它们稍微向左偏
顶部的观察值稍微向右偏
暗示着
可能老年人更有可能根据这个优惠采取行动
而年轻人更有可能忽视它
那么我们能否尝试建模这个呢
如何尝试我们工具箱中现有的方法
即线性回归
我们来运行一个线性回归
这就是它的样子
你可以看出这不像是最好的方法
这不像是最好的方法来解决这个问题
所以我们深入研究一下
我们将在这里画一条水平线
而不是尝试预测给定任何人的具体情况
我们将想象一个人 让我们假设我们要预测这个人的年龄
我们希望预测他们是否会接受这个优惠
但不预测他们是否会接受它
不如我们预测概率
我们将预测这个人接受该优惠的概率
如果你这样想的话
事情立刻就变得清晰了
你可以看到 好的
这个图表实际上是从零到一
我也知道概率是从零到一
哦 那很有趣
所以基本上我可以在零和一之间拟合概率
红色点
红色观察值已经是零或一
并且不在中间
那是因为我们已经知道结果
我们已经知道它们是或否
但对于我们预测的东西
这样说是有道理的
我不知道百分之百
我不知道他是否会接受或不接受
但我知道也许有80%的概率
他会接受或不接受
当你这样想的时候
线性回归线
至少中间那一部分在零和一之间
这有道理对吧
嗯，这在某种程度上有道理
因为那基本上就是在告诉你，任何在那些年龄之间的人
例如 它在第一次横穿水平线时
它可能是
它横穿水平轴的地方
它可能是二五
或者让我们说三五
我们在横穿垂直的
水平轴为一
它可能是 让我们说五十五
所以那些在三十五到五十五之间的人
他们 uh
任何在那些年龄之间的任何人
他们有接受这个提议的概率
他们的概率随着我们向右移动而增加
当我们考虑越来越多的老年人时
那个概率在增加
线性回归的中间部分似乎有道理
我们可以做一些事情
但完全不合理的部分是顶部和底部
因为概率永远不会低于零
它不会高于一
线性回归在这里试图给我们什么提示
嗯 我们可以解释它
它可能说的是
我们提到的年龄
我们假设五五岁以上的人
他们非常有可能接受
或者超过一百
所以基本上他们肯定会接受
另一边，低于三十五的人
他们肯定不会接受
所以我们说的是
如果我们采取那种方法
那么我们必须用那条线代替线性回归线
所以我们砍掉那些部分，用水平的部分代替
这是非常基本的
但这仍然是为了这个情况创建一个模型的尝试
所以我们仍然能够用这个来做一些预测和假设
嗯 这是关于
行动和人的年龄之间的相关性
这是非常基本的理解
这基本上是我们对逻辑回归直觉理解的开始
让我们看看实际的科学方法
所以我们有了我们查看的那条线
这就是这个方程描述的
这部分是即将到来的
这是最有趣的部分
所以请耐心等待
如果你将这个方程应用到一个西格莫德函数上，它将看起来像这样
所以你将y放入紫色的西格莫德函数中
然后你从紫色框中求解y
然后将y放回蓝色框中
然后你将得到绿色框
所以基本上，你的线性回归将开始看起来像这样
这就是逻辑回归的公式，它会对图表做什么
最重要的是这个视觉部分
它会将图表从顶部转换为这个新的图表
实际上这是逻辑回归函数
如果你在这个阶段问自己
发生了什么
那么你并不孤单
我第一次看到这一点
或者我学到了这一点
这就是我脸上的表情
如果你完全舒适
那真是太棒了 这意味着你将轻松完成这部分
但如果你现在感到困惑
没问题 我也是这样
所以我
让我们一步一步来 我们一步一步来看
确切发生了什么
这是我们的图表
这是我们的自变量
这是我们的结果
是或否 所以这是y
因变量
这是我们的数据集中的观察结果，基于这些观察结果，再加上使用这个公式
我们将其视为已知
这是逻辑回归的公式
使用这个公式
结合这些观察数据，我们得出这条线
这里重要的是要理解
这不是一条神奇的线
逻辑回归的这条线与线性回归的斜率或趋势线相同
所以，这条线基本上在做什么
它使用公式，遵循公式
并且它是最适合这些数据点的线
所以，我们实际上正在做与线性回归完全相同的事情
但它看起来不同
仅此而已 所以这里有许多这样的线你可以画得看起来像这样
但只有一个是最佳拟合线
所以逻辑回归的目的是找到这个最佳拟合线
这就是它
所以我们找到了最佳拟合线，它遵循这个方程，适合我们数据集中的这些变量
这些观察结果
之后我们可以忘记这个方程
我们可以忘记这些变量
我们有我们的线 这就是我们的逻辑回归函数
这与线性回归一样
我们创建了模型 我们构建了模型
你可以看到它 这就是在你面前的模型
我们可以用这个逻辑回归做什么
我们可以用它来预测概率
我们已经触及了概率
它们介于零和一之间
而不是预测某事一定会或不会发生
让我们预测概率吧
让我们看看嗯
哦 顺便说一下 概率在这里被称为p hat
所以 嗯 那是一个小p的符号
给它起了个名字p hat，你看到的任何带帽子的东西在这个部分
基本上意味着这是我们预测的
这是一个记住的方式
那就是那个p hat
我们在预测这个概率
好的 所以让我们取四个随机值给自变量x
我们说20, 30, 40, 50
看看这些变量会发生什么
让我们把它们放在x轴上
这些是点
我特意用了点
而不是x或十字架
因为它们不在水平线上并不意味着它们的概率是零
或它们是自变量是零
不
它们只是放在那里因为我们把它们画在x轴上 这与垂直轴无关
我们只是画在那里 这与垂直轴无关
现在 让我们看看你需要做什么来找到概率
你需要将这些值投影到你的曲线上
一旦你投影它们
你得到这些蓝色的
嗯，浅蓝色的
蓝色点或蓝色观察值
它们基本上被绘制出来
这些是你的拟合值
正如你所记得的 在gretel中
你有红色实际的和蓝色拟合值
这些是你的拟合值
现在如果你投影它们
如果你想要概率
你需要将它们投影到左边
像这样
让我们看看这些概率
20岁的人
接受这个提议的概率非常低
也许零点
七个百分点 接受这个提议的概率低于一个百分点
30岁的人
概率更高，大约两
三点百分点接受这个提议
40岁的人
他们的概率接受这个提议是85个百分点
根据这个模型
50岁的人
他们的概率是99点
四个百分点
这是我们可以从逻辑回归中得到的第一件事
这就是我们将要使用的 我们将非常积极地使用它
当我们谈论构建地理细分时
因为你使用这个概率作为分数
我会更多地谈论这个
所以你实际上可以按人排名
谁是最有可能接受你的电话
谁是最不可能接受你的电话
实际上比只有一或零更好
你有一个概率
所以你可以按概率对人进行排序
你可能想说
嗯 我不想要概率
我想要一个预测
因为这是一个回归
嗯 我想要一个关于y值的预测
好的
我们可以做到
我们能得到
让我们去掉那些
嗯 概率
现在 我们能得到实际的原因
好吧 显然我们不能得到实际的
因为实际是我们只能在我们的数据集中观察到的
在现实生活中我们只能对实际值进行预测
所以y hat
正如我所建议的
是因变量的预测值
你是怎么得到的 y hat 好的
方法非常任意
你必须选择这条线，让我们等待
好的 所以你必须选择一条线
在这种情况下，我们将选择50％
你可以在任何地方选择它
但通常选择50％
因为它在中间，它是
嗯 因此你有对称性，这条线以下的任何东西
所以落在这条曲线以下的任何东西都会被投影到零线上
哪个哪个有道理
所以它基本上说的是如果你的概率
你预测的概率接受这个提议低于百分之五十
假设是百分之四十或百分之二十
那么我们就说你不是
你可能不会接受这个提议
这就是正在发生的事情
那个零点
七百分 那个两个百分
七% 二 三%
它们是 嗯
预测它们的概率不为零
但它们低于50
所以你是
如果你需要一顶Y帽子
所以预测值
是的 没有价值
那么，如果一个事物的百分比低于50%，
你可能说他们不会接受提议
现在 任何在上方
哦，是的 就是这样
两者都是 Y帽子为零
现在 任何高于我们选择的水平线，即50%线
都同意那些落在曲线上的值
嗯 落在那条线之上的所有值都被向上预测
它们被投射到是线上
那条线上的人，概率为85%，被向上投射
概率为99.7%的人也被向上投射
这是有道理的
是的 如果你
如果一个人去了学校
你预测某人接受提议的概率为80%
五 如果你要说是或否
那么你可能会说是
你会说是
这个人会接受提议
如果你只能选择两者之一
这就是我们预测的Y帽子值
在这种情况下
它们都是1，这两个变量
这就是逻辑回归能给出的两件事
所以你可以得到这些概率，它们是重要的
你也可以得到预测的Y帽子值，也就是因变量的预测值
再次强调 重要的是要这样想
它与线性回归在做同样的事情
它 嗯
它在拟合这条线
尽管它不是一条直线
而且值不是散乱的
一切都看起来奇怪，结构统一
或者以它的结构方式
它的结构使它看起来非常奇怪
但是，它仍然是差不多的方式
我们同意一条线或一个曲线的公式
我们正在尝试将我们的数据拟合到最佳曲线上
一旦我们做了那件事，我们就有了
我们有一个模型 我们已经有了我们将稍后讨论的系数
我们可以从这个模型中开始得出结论或洞察力
我们可以得到一个人采取行动的概率的一些见解
或者事件发生
并且基本上答案是肯定的
所以这不是一个肯定的回答
不 这是一个概率，所以85%或20%或随便什么
这就是我们把它投影到y轴的左边的时候
我们也可以得到一个对因变量的预测值
基于我们选择的这条任意直线
五十 你可以选择任何你喜欢的地方，你可以选择更高
更低取决于你对手头问题的了解
随着你的理解
根据你选择的位置
这将显著影响你的可变数
所以我真的很希望这个解释是正确的
足够简单和
同时又足够深入让你能对逻辑回归有一个直观的理解
期待下次见到你，直到下次再见 祝你分析愉快
                
```